[
  {
    "timestamp": "2025-05-05T01:14:20.917127",
    "gpu": {
      "utilization": {
        "0": 29
      },
      "memory": {
        "0": {
          "used_mb": 9767,
          "total_mb": 10240,
          "percentage": 95.380859375
        }
      },
      "temperature": {
        "0": 52
      },
      "power": {
        "0": {
          "draw_watts": 130.01,
          "limit_watts": 370.0,
          "percentage": 35.137837837837836
        }
      },
      "clock_speeds": {
        "0": {
          "graphics_mhz": 1905,
          "memory_mhz": 9251
        }
      },
      "pcie_throughput": {
        "0": {
          "link_gen": "4",
          "link_width": "8",
          "max_bandwidth_GBps": 15.76,
          "mem_controller_util": 1.3333333333333333,
          "estimated_usage_GBps": 0.2101333333333333
        }
      },
      "idle_time": 0,
      "is_currently_idle": false
    },
    "cpu": {
      "utilization": {
        "overall": 4.7,
        "per_core": [
          0.0,
          0.0,
          10.0,
          0.0,
          0.0,
          0.0,
          0.0,
          9.1,
          11.1,
          0.0,
          27.3,
          0.0,
          18.2,
          10.0,
          10.0,
          0.0,
          0.0,
          0.0,
          0.0,
          9.1
        ],
        "logical_cores": 20,
        "physical_cores": 14
      },
      "unused_cores": {
        "unused_core_count": 8,
        "unused_core_indices": [
          3,
          5,
          7,
          9,
          11,
          13,
          16,
          19
        ],
        "threshold": 10
      },
      "memory": {
        "total_gb": 31.13628387451172,
        "used_gb": 25.071537017822266,
        "available_gb": 4.77197265625,
        "percent_used": 84.7,
        "swap_total_gb": 0.9540977478027344,
        "swap_used_gb": 0.235595703125,
        "swap_percent": 24.7
      }
    },
    "latency": {
      "inference": {
        "batch_size": 1,
        "num_runs": 10,
        "avg_latency_ms": 24.53172206878662,
        "throughput_samples_per_sec": 40.76354677409166
      },
      "training_step": {
        "error": "in user code:\n\n    File \"/home/p0wden/Downloads/mloptimizer/app/common/GpuMetrics.py\", line 588, in train_step  *\n        loss = model.loss(y, y_pred)\n\n    TypeError: 'str' object is not callable\n"
      },
      "data_pipeline": {
        "status": "no dataset provided"
      }
    },
    "framework_specific": {
      "version": "2.19.0",
      "built_with_cuda": true,
      "gpu_available": true,
      "eager_execution": true
    }
  },
  {
    "timestamp": "2025-05-05T01:15:45.917995",
    "gpu": {
      "utilization": {
        "0": 53
      },
      "memory": {
        "0": {
          "used_mb": 9767,
          "total_mb": 10240,
          "percentage": 95.380859375
        }
      },
      "temperature": {
        "0": 53
      },
      "power": {
        "0": {
          "draw_watts": 184.42,
          "limit_watts": 370.0,
          "percentage": 49.84324324324324
        }
      },
      "clock_speeds": {
        "0": {
          "graphics_mhz": 1980,
          "memory_mhz": 9251
        }
      },
      "pcie_throughput": {
        "0": {
          "link_gen": "4",
          "link_width": "8",
          "max_bandwidth_GBps": 15.76,
          "mem_controller_util": 1.0,
          "estimated_usage_GBps": 0.1576
        }
      },
      "idle_time": 0,
      "is_currently_idle": false
    },
    "cpu": {
      "utilization": {
        "overall": 12.9,
        "per_core": [
          9.1,
          0.0,
          10.0,
          0.0,
          10.0,
          0.0,
          0.0,
          0.0,
          22.2,
          10.0,
          22.2,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          10.0,
          0.0,
          0.0
        ],
        "logical_cores": 20,
        "physical_cores": 14
      },
      "unused_cores": {
        "unused_core_count": 12,
        "unused_core_indices": [
          1,
          3,
          5,
          6,
          7,
          9,
          11,
          14,
          16,
          17,
          18,
          19
        ],
        "threshold": 10
      },
      "memory": {
        "total_gb": 31.13628387451172,
        "used_gb": 25.28460693359375,
        "available_gb": 4.560493469238281,
        "percent_used": 85.4,
        "swap_total_gb": 0.9540977478027344,
        "swap_used_gb": 0.277587890625,
        "swap_percent": 29.1
      }
    },
    "latency": {
      "inference": {
        "batch_size": 1,
        "num_runs": 10,
        "avg_latency_ms": 23.189449310302734,
        "throughput_samples_per_sec": 43.12305939734906
      },
      "training_step": {
        "error": "in user code:\n\n    File \"/home/p0wden/Downloads/mloptimizer/app/common/GpuMetrics.py\", line 588, in train_step  *\n        loss = model.loss(y, y_pred)\n\n    TypeError: 'str' object is not callable\n"
      },
      "data_pipeline": {
        "status": "no dataset provided"
      }
    },
    "framework_specific": {
      "version": "2.19.0",
      "built_with_cuda": true,
      "gpu_available": true,
      "eager_execution": true
    }
  },
  {
    "timestamp": "2025-05-05T01:15:48.766200",
    "gpu": {
      "utilization": {
        "0": 31
      },
      "memory": {
        "0": {
          "used_mb": 9767,
          "total_mb": 10240,
          "percentage": 95.380859375
        }
      },
      "temperature": {
        "0": 52
      },
      "power": {
        "0": {
          "draw_watts": 130.13,
          "limit_watts": 370.0,
          "percentage": 35.17027027027027
        }
      },
      "clock_speeds": {
        "0": {
          "graphics_mhz": 1905,
          "memory_mhz": 9251
        }
      },
      "pcie_throughput": {
        "0": {
          "link_gen": "4",
          "link_width": "8",
          "max_bandwidth_GBps": 15.76,
          "mem_controller_util": 1.0,
          "estimated_usage_GBps": 0.1576
        }
      },
      "idle_time": 0,
      "is_currently_idle": false
    },
    "cpu": {
      "utilization": {
        "overall": 4.7,
        "per_core": [
          18.2,
          0.0,
          10.0,
          0.0,
          9.1,
          0.0,
          0.0,
          0.0,
          11.1,
          0.0,
          30.0,
          0.0,
          18.2,
          10.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0
        ],
        "logical_cores": 20,
        "physical_cores": 14
      },
      "unused_cores": {
        "unused_core_count": 3,
        "unused_core_indices": [
          3,
          7,
          16
        ],
        "threshold": 10
      },
      "memory": {
        "total_gb": 31.13628387451172,
        "used_gb": 25.29217529296875,
        "available_gb": 4.553215026855469,
        "percent_used": 85.4,
        "swap_total_gb": 0.9540977478027344,
        "swap_used_gb": 0.277587890625,
        "swap_percent": 29.1
      }
    },
    "latency": {
      "inference": {
        "batch_size": 1,
        "num_runs": 10,
        "avg_latency_ms": 24.282264709472656,
        "throughput_samples_per_sec": 41.182320181605384
      },
      "training_step": {
        "error": "in user code:\n\n    File \"/home/p0wden/Downloads/mloptimizer/app/common/GpuMetrics.py\", line 588, in train_step  *\n        loss = model.loss(y, y_pred)\n\n    TypeError: 'str' object is not callable\n"
      },
      "data_pipeline": {
        "status": "no dataset provided"
      }
    },
    "framework_specific": {
      "version": "2.19.0",
      "built_with_cuda": true,
      "gpu_available": true,
      "eager_execution": true
    }
  },
  {
    "timestamp": "2025-05-05T01:17:14.297840",
    "gpu": {
      "utilization": {
        "0": 49
      },
      "memory": {
        "0": {
          "used_mb": 9767,
          "total_mb": 10240,
          "percentage": 95.380859375
        }
      },
      "temperature": {
        "0": 53
      },
      "power": {
        "0": {
          "draw_watts": 183.16,
          "limit_watts": 370.0,
          "percentage": 49.5027027027027
        }
      },
      "clock_speeds": {
        "0": {
          "graphics_mhz": 1980,
          "memory_mhz": 9251
        }
      },
      "pcie_throughput": {
        "0": {
          "link_gen": "4",
          "link_width": "8",
          "max_bandwidth_GBps": 15.76,
          "mem_controller_util": 1.0,
          "estimated_usage_GBps": 0.1576
        }
      },
      "idle_time": 0,
      "is_currently_idle": false
    },
    "cpu": {
      "utilization": {
        "overall": 5.2,
        "per_core": [
          10.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          44.4,
          0.0,
          10.0,
          10.0,
          10.0,
          10.0,
          0.0,
          0.0,
          0.0,
          16.7,
          0.0,
          0.0
        ],
        "logical_cores": 20,
        "physical_cores": 14
      },
      "unused_cores": {
        "unused_core_count": 12,
        "unused_core_indices": [
          1,
          3,
          5,
          7,
          9,
          11,
          12,
          15,
          16,
          17,
          18,
          19
        ],
        "threshold": 10
      },
      "memory": {
        "total_gb": 31.13628387451172,
        "used_gb": 25.55221176147461,
        "available_gb": 4.293190002441406,
        "percent_used": 86.2,
        "swap_total_gb": 0.9540977478027344,
        "swap_used_gb": 0.31103515625,
        "swap_percent": 32.6
      }
    },
    "latency": {
      "inference": {
        "batch_size": 1,
        "num_runs": 10,
        "avg_latency_ms": 22.77195453643799,
        "throughput_samples_per_sec": 43.91366575055621
      },
      "training_step": {
        "error": "in user code:\n\n    File \"/home/p0wden/Downloads/mloptimizer/app/common/GpuMetrics.py\", line 588, in train_step  *\n        loss = model.loss(y, y_pred)\n\n    TypeError: 'str' object is not callable\n"
      },
      "data_pipeline": {
        "status": "no dataset provided"
      }
    },
    "framework_specific": {
      "version": "2.19.0",
      "built_with_cuda": true,
      "gpu_available": true,
      "eager_execution": true
    }
  },
  {
    "timestamp": "2025-05-05T01:17:17.147212",
    "gpu": {
      "utilization": {
        "0": 33
      },
      "memory": {
        "0": {
          "used_mb": 9767,
          "total_mb": 10240,
          "percentage": 95.380859375
        }
      },
      "temperature": {
        "0": 52
      },
      "power": {
        "0": {
          "draw_watts": 129.24,
          "limit_watts": 370.0,
          "percentage": 34.92972972972973
        }
      },
      "clock_speeds": {
        "0": {
          "graphics_mhz": 1905,
          "memory_mhz": 9251
        }
      },
      "pcie_throughput": {
        "0": {
          "link_gen": "4",
          "link_width": "8",
          "max_bandwidth_GBps": 15.76,
          "mem_controller_util": 1.0,
          "estimated_usage_GBps": 0.1576
        }
      },
      "idle_time": 0,
      "is_currently_idle": false
    },
    "cpu": {
      "utilization": {
        "overall": 11.9,
        "per_core": [
          10.0,
          9.1,
          0.0,
          0.0,
          10.0,
          0.0,
          10.0,
          0.0,
          33.3,
          0.0,
          0.0,
          0.0,
          9.1,
          0.0,
          0.0,
          0.0,
          0.0,
          10.0,
          0.0,
          0.0
        ],
        "logical_cores": 20,
        "physical_cores": 14
      },
      "unused_cores": {
        "unused_core_count": 11,
        "unused_core_indices": [
          0,
          1,
          3,
          4,
          5,
          7,
          9,
          11,
          16,
          18,
          19
        ],
        "threshold": 10
      },
      "memory": {
        "total_gb": 31.13628387451172,
        "used_gb": 25.555526733398438,
        "available_gb": 4.289894104003906,
        "percent_used": 86.2,
        "swap_total_gb": 0.9540977478027344,
        "swap_used_gb": 0.31103515625,
        "swap_percent": 32.6
      }
    },
    "latency": {
      "inference": {
        "batch_size": 1,
        "num_runs": 10,
        "avg_latency_ms": 24.141383171081543,
        "throughput_samples_per_sec": 41.4226472821938
      },
      "training_step": {
        "error": "in user code:\n\n    File \"/home/p0wden/Downloads/mloptimizer/app/common/GpuMetrics.py\", line 588, in train_step  *\n        loss = model.loss(y, y_pred)\n\n    TypeError: 'str' object is not callable\n"
      },
      "data_pipeline": {
        "status": "no dataset provided"
      }
    },
    "framework_specific": {
      "version": "2.19.0",
      "built_with_cuda": true,
      "gpu_available": true,
      "eager_execution": true
    }
  },
  {
    "timestamp": "2025-05-05T01:18:42.320675",
    "gpu": {
      "utilization": {
        "0": 36
      },
      "memory": {
        "0": {
          "used_mb": 9767,
          "total_mb": 10240,
          "percentage": 95.380859375
        }
      },
      "temperature": {
        "0": 53
      },
      "power": {
        "0": {
          "draw_watts": 182.16,
          "limit_watts": 370.0,
          "percentage": 49.23243243243243
        }
      },
      "clock_speeds": {
        "0": {
          "graphics_mhz": 1980,
          "memory_mhz": 9251
        }
      },
      "pcie_throughput": {
        "0": {
          "link_gen": "4",
          "link_width": "8",
          "max_bandwidth_GBps": 15.76,
          "mem_controller_util": 1.0,
          "estimated_usage_GBps": 0.1576
        }
      },
      "idle_time": 0,
      "is_currently_idle": false
    },
    "cpu": {
      "utilization": {
        "overall": 15.9,
        "per_core": [
          22.2,
          9.1,
          20.0,
          9.1,
          22.2,
          9.1,
          30.0,
          0.0,
          45.5,
          0.0,
          55.6,
          9.1,
          22.2,
          40.0,
          33.3,
          0.0,
          20.0,
          0.0,
          10.0,
          0.0
        ],
        "logical_cores": 20,
        "physical_cores": 14
      },
      "unused_cores": {
        "unused_core_count": 7,
        "unused_core_indices": [
          3,
          5,
          7,
          9,
          11,
          15,
          19
        ],
        "threshold": 10
      },
      "memory": {
        "total_gb": 31.13628387451172,
        "used_gb": 25.772850036621094,
        "available_gb": 4.073047637939453,
        "percent_used": 86.9,
        "swap_total_gb": 0.9540977478027344,
        "swap_used_gb": 0.42041015625,
        "swap_percent": 44.1
      }
    },
    "latency": {
      "inference": {
        "batch_size": 1,
        "num_runs": 10,
        "avg_latency_ms": 23.349738121032715,
        "throughput_samples_per_sec": 42.827032783688104
      },
      "training_step": {
        "error": "in user code:\n\n    File \"/home/p0wden/Downloads/mloptimizer/app/common/GpuMetrics.py\", line 588, in train_step  *\n        loss = model.loss(y, y_pred)\n\n    TypeError: 'str' object is not callable\n"
      },
      "data_pipeline": {
        "status": "no dataset provided"
      }
    },
    "framework_specific": {
      "version": "2.19.0",
      "built_with_cuda": true,
      "gpu_available": true,
      "eager_execution": true
    }
  },
  {
    "timestamp": "2025-05-05T01:18:45.166891",
    "gpu": {
      "utilization": {
        "0": 27
      },
      "memory": {
        "0": {
          "used_mb": 9767,
          "total_mb": 10240,
          "percentage": 95.380859375
        }
      },
      "temperature": {
        "0": 52
      },
      "power": {
        "0": {
          "draw_watts": 130.55,
          "limit_watts": 370.0,
          "percentage": 35.28378378378378
        }
      },
      "clock_speeds": {
        "0": {
          "graphics_mhz": 1905,
          "memory_mhz": 9251
        }
      },
      "pcie_throughput": {
        "0": {
          "link_gen": "4",
          "link_width": "8",
          "max_bandwidth_GBps": 15.76,
          "mem_controller_util": 1.0,
          "estimated_usage_GBps": 0.1576
        }
      },
      "idle_time": 0,
      "is_currently_idle": false
    },
    "cpu": {
      "utilization": {
        "overall": 6.7,
        "per_core": [
          18.2,
          18.2,
          18.2,
          0.0,
          10.0,
          0.0,
          10.0,
          9.1,
          45.5,
          0.0,
          27.3,
          9.1,
          18.2,
          10.0,
          10.0,
          0.0,
          0.0,
          18.2,
          10.0,
          10.0
        ],
        "logical_cores": 20,
        "physical_cores": 14
      },
      "unused_cores": {
        "unused_core_count": 6,
        "unused_core_indices": [
          1,
          3,
          7,
          11,
          18,
          19
        ],
        "threshold": 10
      },
      "memory": {
        "total_gb": 31.13628387451172,
        "used_gb": 25.794132232666016,
        "available_gb": 4.051982879638672,
        "percent_used": 87.0,
        "swap_total_gb": 0.9540977478027344,
        "swap_used_gb": 0.43212890625,
        "swap_percent": 45.3
      }
    },
    "latency": {
      "inference": {
        "batch_size": 1,
        "num_runs": 10,
        "avg_latency_ms": 24.12734031677246,
        "throughput_samples_per_sec": 41.44675653722329
      },
      "training_step": {
        "error": "in user code:\n\n    File \"/home/p0wden/Downloads/mloptimizer/app/common/GpuMetrics.py\", line 588, in train_step  *\n        loss = model.loss(y, y_pred)\n\n    TypeError: 'str' object is not callable\n"
      },
      "data_pipeline": {
        "status": "no dataset provided"
      }
    },
    "framework_specific": {
      "version": "2.19.0",
      "built_with_cuda": true,
      "gpu_available": true,
      "eager_execution": true
    }
  },
  {
    "timestamp": "2025-05-05T01:20:10.431419",
    "gpu": {
      "utilization": {
        "0": 54
      },
      "memory": {
        "0": {
          "used_mb": 9767,
          "total_mb": 10240,
          "percentage": 95.380859375
        }
      },
      "temperature": {
        "0": 52
      },
      "power": {
        "0": {
          "draw_watts": 182.06,
          "limit_watts": 370.0,
          "percentage": 49.20540540540541
        }
      },
      "clock_speeds": {
        "0": {
          "graphics_mhz": 1980,
          "memory_mhz": 9251
        }
      },
      "pcie_throughput": {
        "0": {
          "link_gen": "4",
          "link_width": "8",
          "max_bandwidth_GBps": 15.76,
          "mem_controller_util": 1.0,
          "estimated_usage_GBps": 0.1576
        }
      },
      "idle_time": 0,
      "is_currently_idle": false
    },
    "cpu": {
      "utilization": {
        "overall": 12.7,
        "per_core": [
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          10.0,
          0.0,
          0.0,
          27.3,
          0.0,
          30.0,
          0.0,
          10.0,
          0.0,
          0.0,
          9.1,
          0.0,
          10.0,
          10.0,
          0.0
        ],
        "logical_cores": 20,
        "physical_cores": 14
      },
      "unused_cores": {
        "unused_core_count": 7,
        "unused_core_indices": [
          3,
          5,
          7,
          11,
          16,
          17,
          18
        ],
        "threshold": 10
      },
      "memory": {
        "total_gb": 31.13628387451172,
        "used_gb": 25.978485107421875,
        "available_gb": 3.8683395385742188,
        "percent_used": 87.6,
        "swap_total_gb": 0.9540977478027344,
        "swap_used_gb": 0.516357421875,
        "swap_percent": 54.1
      }
    },
    "latency": {
      "inference": {
        "batch_size": 1,
        "num_runs": 10,
        "avg_latency_ms": 23.882722854614258,
        "throughput_samples_per_sec": 41.87127263869727
      },
      "training_step": {
        "error": "in user code:\n\n    File \"/home/p0wden/Downloads/mloptimizer/app/common/GpuMetrics.py\", line 588, in train_step  *\n        loss = model.loss(y, y_pred)\n\n    TypeError: 'str' object is not callable\n"
      },
      "data_pipeline": {
        "status": "no dataset provided"
      }
    },
    "framework_specific": {
      "version": "2.19.0",
      "built_with_cuda": true,
      "gpu_available": true,
      "eager_execution": true
    }
  }
]