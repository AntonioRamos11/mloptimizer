[
  {
    "timestamp": "2025-12-02T13:43:49.550967",
    "gpu": {
      "utilization": {
        "0": 2
      },
      "memory": {
        "0": {
          "used_mb": 9630,
          "total_mb": 10240,
          "percentage": 94.04296875
        }
      },
      "temperature": {
        "0": 46
      },
      "power": {
        "0": {
          "draw_watts": 123.2,
          "limit_watts": 370.0,
          "percentage": 33.2972972972973
        }
      },
      "clock_speeds": {
        "0": {
          "graphics_mhz": 1905,
          "memory_mhz": 9251
        }
      },
      "pcie_throughput": {
        "0": {
          "link_gen": "4",
          "link_width": "8",
          "max_bandwidth_GBps": 15.76,
          "mem_controller_util": 1.0,
          "estimated_usage_GBps": 0.1576
        }
      },
      "idle_time": 0,
      "is_currently_idle": true
    },
    "cpu": {
      "utilization": {
        "overall": 2.0,
        "per_core": [
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          9.1,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0
        ],
        "logical_cores": 20,
        "physical_cores": 14
      },
      "unused_cores": {
        "unused_core_count": 18,
        "unused_core_indices": [
          0,
          1,
          2,
          3,
          4,
          5,
          7,
          8,
          9,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19
        ],
        "threshold": 10
      },
      "memory": {
        "total_gb": 31.136207580566406,
        "used_gb": 10.654006958007812,
        "available_gb": 19.8143310546875,
        "percent_used": 36.4,
        "swap_total_gb": 0.9540977478027344,
        "swap_used_gb": 0.0,
        "swap_percent": 0.0
      }
    },
    "latency": {
      "inference": {
        "status": "no model registered"
      },
      "training_step": {
        "status": "no model available"
      },
      "data_pipeline": {
        "status": "no dataset provided"
      }
    },
    "framework_specific": {
      "version": "2.17.0",
      "built_with_cuda": true,
      "gpu_available": true,
      "eager_execution": true
    }
  },
  {
    "timestamp": "2025-12-02T13:43:53.805848",
    "gpu": {
      "utilization": {
        "0": 4
      },
      "memory": {
        "0": {
          "used_mb": 9632,
          "total_mb": 10240,
          "percentage": 94.0625
        }
      },
      "temperature": {
        "0": 46
      },
      "power": {
        "0": {
          "draw_watts": 122.55,
          "limit_watts": 370.0,
          "percentage": 33.12162162162162
        }
      },
      "clock_speeds": {
        "0": {
          "graphics_mhz": 1905,
          "memory_mhz": 9251
        }
      },
      "pcie_throughput": {
        "0": {
          "link_gen": "4",
          "link_width": "8",
          "max_bandwidth_GBps": 15.76,
          "mem_controller_util": 1.0,
          "estimated_usage_GBps": 0.1576
        }
      },
      "idle_time": 4.254392862319946,
      "is_currently_idle": true
    },
    "cpu": {
      "utilization": {
        "overall": 1.0,
        "per_core": [
          0.0,
          0.0,
          9.1,
          0.0,
          0.0,
          0.0,
          9.1,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          9.1,
          0.0,
          0.0,
          0.0
        ],
        "logical_cores": 20,
        "physical_cores": 14
      },
      "unused_cores": {
        "unused_core_count": 19,
        "unused_core_indices": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19
        ],
        "threshold": 10
      },
      "memory": {
        "total_gb": 31.136207580566406,
        "used_gb": 10.753379821777344,
        "available_gb": 19.712997436523438,
        "percent_used": 36.7,
        "swap_total_gb": 0.9540977478027344,
        "swap_used_gb": 0.0,
        "swap_percent": 0.0
      }
    },
    "latency": {
      "inference": {
        "batch_size": 1,
        "num_runs": 10,
        "avg_latency_ms": 20.44832706451416,
        "throughput_samples_per_sec": 48.903756128558356
      },
      "training_step": {
        "error": "in user code:\n\n    File \"/home/p0wden/Documents/mloptimizer/app/common/GpuMetrics.py\", line 588, in train_step  *\n        loss = model.loss(y, y_pred)\n\n    TypeError: 'str' object is not callable\n"
      },
      "data_pipeline": {
        "status": "no dataset provided"
      }
    },
    "framework_specific": {
      "version": "2.17.0",
      "built_with_cuda": true,
      "gpu_available": true,
      "eager_execution": true
    }
  },
  {
    "timestamp": "2025-12-02T13:46:16.804859",
    "gpu": {
      "utilization": {
        "0": 43
      },
      "memory": {
        "0": {
          "used_mb": 9666,
          "total_mb": 10240,
          "percentage": 94.39453125
        }
      },
      "temperature": {
        "0": 47
      },
      "power": {
        "0": {
          "draw_watts": 139.34,
          "limit_watts": 370.0,
          "percentage": 37.65945945945946
        }
      },
      "clock_speeds": {
        "0": {
          "graphics_mhz": 1965,
          "memory_mhz": 9251
        }
      },
      "pcie_throughput": {
        "0": {
          "link_gen": "4",
          "link_width": "8",
          "max_bandwidth_GBps": 15.76,
          "mem_controller_util": 1.0,
          "estimated_usage_GBps": 0.1576
        }
      },
      "idle_time": 147.25330710411072,
      "is_currently_idle": false
    },
    "cpu": {
      "utilization": {
        "overall": 1.0,
        "per_core": [
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          9.1,
          0.0,
          0.0,
          0.0,
          0.0
        ],
        "logical_cores": 20,
        "physical_cores": 14
      },
      "unused_cores": {
        "unused_core_count": 19,
        "unused_core_indices": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          14,
          15,
          16,
          17,
          18,
          19
        ],
        "threshold": 10
      },
      "memory": {
        "total_gb": 31.136207580566406,
        "used_gb": 11.730838775634766,
        "available_gb": 18.732372283935547,
        "percent_used": 39.8,
        "swap_total_gb": 0.9540977478027344,
        "swap_used_gb": 0.0,
        "swap_percent": 0.0
      }
    },
    "latency": {
      "inference": {
        "batch_size": 1,
        "num_runs": 10,
        "avg_latency_ms": 20.0777530670166,
        "throughput_samples_per_sec": 49.8063700983943
      },
      "training_step": {
        "error": "in user code:\n\n    File \"/home/p0wden/Documents/mloptimizer/app/common/GpuMetrics.py\", line 588, in train_step  *\n        loss = model.loss(y, y_pred)\n\n    TypeError: 'str' object is not callable\n"
      },
      "data_pipeline": {
        "status": "no dataset provided"
      }
    },
    "framework_specific": {
      "version": "2.17.0",
      "built_with_cuda": true,
      "gpu_available": true,
      "eager_execution": true
    }
  },
  {
    "timestamp": "2025-12-02T13:46:19.664850",
    "gpu": {
      "utilization": {
        "0": 2
      },
      "memory": {
        "0": {
          "used_mb": 9666,
          "total_mb": 10240,
          "percentage": 94.39453125
        }
      },
      "temperature": {
        "0": 46
      },
      "power": {
        "0": {
          "draw_watts": 122.57,
          "limit_watts": 370.0,
          "percentage": 33.127027027027026
        }
      },
      "clock_speeds": {
        "0": {
          "graphics_mhz": 1905,
          "memory_mhz": 9251
        }
      },
      "pcie_throughput": {
        "0": {
          "link_gen": "4",
          "link_width": "8",
          "max_bandwidth_GBps": 15.76,
          "mem_controller_util": 1.0,
          "estimated_usage_GBps": 0.1576
        }
      },
      "idle_time": 0,
      "is_currently_idle": true
    },
    "cpu": {
      "utilization": {
        "overall": 1.0,
        "per_core": [
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          9.1,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0
        ],
        "logical_cores": 20,
        "physical_cores": 14
      },
      "unused_cores": {
        "unused_core_count": 17,
        "unused_core_indices": [
          0,
          1,
          3,
          4,
          5,
          6,
          7,
          9,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19
        ],
        "threshold": 10
      },
      "memory": {
        "total_gb": 31.136207580566406,
        "used_gb": 11.709781646728516,
        "available_gb": 18.753429412841797,
        "percent_used": 39.8,
        "swap_total_gb": 0.9540977478027344,
        "swap_used_gb": 0.0,
        "swap_percent": 0.0
      }
    },
    "latency": {
      "inference": {
        "batch_size": 1,
        "num_runs": 10,
        "avg_latency_ms": 20.366430282592773,
        "throughput_samples_per_sec": 49.100406213783174
      },
      "training_step": {
        "error": "in user code:\n\n    File \"/home/p0wden/Documents/mloptimizer/app/common/GpuMetrics.py\", line 588, in train_step  *\n        loss = model.loss(y, y_pred)\n\n    TypeError: 'str' object is not callable\n"
      },
      "data_pipeline": {
        "status": "no dataset provided"
      }
    },
    "framework_specific": {
      "version": "2.17.0",
      "built_with_cuda": true,
      "gpu_available": true,
      "eager_execution": true
    }
  },
  {
    "timestamp": "2025-12-02T13:48:39.513319",
    "gpu": {
      "utilization": {
        "0": 31
      },
      "memory": {
        "0": {
          "used_mb": 9664,
          "total_mb": 10240,
          "percentage": 94.375
        }
      },
      "temperature": {
        "0": 47
      },
      "power": {
        "0": {
          "draw_watts": 140.3,
          "limit_watts": 370.0,
          "percentage": 37.91891891891892
        }
      },
      "clock_speeds": {
        "0": {
          "graphics_mhz": 1965,
          "memory_mhz": 9251
        }
      },
      "pcie_throughput": {
        "0": {
          "link_gen": "4",
          "link_width": "8",
          "max_bandwidth_GBps": 15.76,
          "mem_controller_util": 1.0,
          "estimated_usage_GBps": 0.1576
        }
      },
      "idle_time": 139.8475148677826,
      "is_currently_idle": false
    },
    "cpu": {
      "utilization": {
        "overall": 1.5,
        "per_core": [
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          10.0,
          0.0,
          9.1,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          9.1,
          0.0
        ],
        "logical_cores": 20,
        "physical_cores": 14
      },
      "unused_cores": {
        "unused_core_count": 19,
        "unused_core_indices": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19
        ],
        "threshold": 10
      },
      "memory": {
        "total_gb": 31.136207580566406,
        "used_gb": 11.824302673339844,
        "available_gb": 18.63890838623047,
        "percent_used": 40.1,
        "swap_total_gb": 0.9540977478027344,
        "swap_used_gb": 0.0,
        "swap_percent": 0.0
      }
    },
    "latency": {
      "inference": {
        "batch_size": 1,
        "num_runs": 10,
        "avg_latency_ms": 20.70467472076416,
        "throughput_samples_per_sec": 48.2982714525395
      },
      "training_step": {
        "error": "in user code:\n\n    File \"/home/p0wden/Documents/mloptimizer/app/common/GpuMetrics.py\", line 588, in train_step  *\n        loss = model.loss(y, y_pred)\n\n    TypeError: 'str' object is not callable\n"
      },
      "data_pipeline": {
        "status": "no dataset provided"
      }
    },
    "framework_specific": {
      "version": "2.17.0",
      "built_with_cuda": true,
      "gpu_available": true,
      "eager_execution": true
    }
  },
  {
    "timestamp": "2025-12-02T13:48:42.491232",
    "gpu": {
      "utilization": {
        "0": 6
      },
      "memory": {
        "0": {
          "used_mb": 9664,
          "total_mb": 10240,
          "percentage": 94.375
        }
      },
      "temperature": {
        "0": 46
      },
      "power": {
        "0": {
          "draw_watts": 123.12,
          "limit_watts": 370.0,
          "percentage": 33.27567567567568
        }
      },
      "clock_speeds": {
        "0": {
          "graphics_mhz": 1905,
          "memory_mhz": 9251
        }
      },
      "pcie_throughput": {
        "0": {
          "link_gen": "4",
          "link_width": "8",
          "max_bandwidth_GBps": 15.76,
          "mem_controller_util": 1.0,
          "estimated_usage_GBps": 0.1576
        }
      },
      "idle_time": 0,
      "is_currently_idle": false
    },
    "cpu": {
      "utilization": {
        "overall": 1.5,
        "per_core": [
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          9.1,
          0.0,
          9.1,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          9.1,
          0.0
        ],
        "logical_cores": 20,
        "physical_cores": 14
      },
      "unused_cores": {
        "unused_core_count": 19,
        "unused_core_indices": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19
        ],
        "threshold": 10
      },
      "memory": {
        "total_gb": 31.136207580566406,
        "used_gb": 11.825401306152344,
        "available_gb": 18.637802124023438,
        "percent_used": 40.1,
        "swap_total_gb": 0.9540977478027344,
        "swap_used_gb": 0.0,
        "swap_percent": 0.0
      }
    },
    "latency": {
      "inference": {
        "batch_size": 1,
        "num_runs": 10,
        "avg_latency_ms": 20.61173915863037,
        "throughput_samples_per_sec": 48.516041868368426
      },
      "training_step": {
        "error": "in user code:\n\n    File \"/home/p0wden/Documents/mloptimizer/app/common/GpuMetrics.py\", line 588, in train_step  *\n        loss = model.loss(y, y_pred)\n\n    TypeError: 'str' object is not callable\n"
      },
      "data_pipeline": {
        "status": "no dataset provided"
      }
    },
    "framework_specific": {
      "version": "2.17.0",
      "built_with_cuda": true,
      "gpu_available": true,
      "eager_execution": true
    }
  },
  {
    "timestamp": "2025-12-02T13:51:02.391116",
    "gpu": {
      "utilization": {
        "0": 34
      },
      "memory": {
        "0": {
          "used_mb": 9664,
          "total_mb": 10240,
          "percentage": 94.375
        }
      },
      "temperature": {
        "0": 47
      },
      "power": {
        "0": {
          "draw_watts": 140.13,
          "limit_watts": 370.0,
          "percentage": 37.872972972972974
        }
      },
      "clock_speeds": {
        "0": {
          "graphics_mhz": 1965,
          "memory_mhz": 9251
        }
      },
      "pcie_throughput": {
        "0": {
          "link_gen": "4",
          "link_width": "8",
          "max_bandwidth_GBps": 15.76,
          "mem_controller_util": 1.0,
          "estimated_usage_GBps": 0.1576
        }
      },
      "idle_time": 0,
      "is_currently_idle": false
    },
    "cpu": {
      "utilization": {
        "overall": 1.0,
        "per_core": [
          9.1,
          0.0,
          9.1,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          9.1,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0
        ],
        "logical_cores": 20,
        "physical_cores": 14
      },
      "unused_cores": {
        "unused_core_count": 19,
        "unused_core_indices": [
          0,
          1,
          2,
          3,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19
        ],
        "threshold": 10
      },
      "memory": {
        "total_gb": 31.136207580566406,
        "used_gb": 11.890434265136719,
        "available_gb": 18.574485778808594,
        "percent_used": 40.3,
        "swap_total_gb": 0.9540977478027344,
        "swap_used_gb": 0.0,
        "swap_percent": 0.0
      }
    },
    "latency": {
      "inference": {
        "batch_size": 1,
        "num_runs": 10,
        "avg_latency_ms": 20.72744369506836,
        "throughput_samples_per_sec": 48.24521608701453
      },
      "training_step": {
        "error": "in user code:\n\n    File \"/home/p0wden/Documents/mloptimizer/app/common/GpuMetrics.py\", line 588, in train_step  *\n        loss = model.loss(y, y_pred)\n\n    TypeError: 'str' object is not callable\n"
      },
      "data_pipeline": {
        "status": "no dataset provided"
      }
    },
    "framework_specific": {
      "version": "2.17.0",
      "built_with_cuda": true,
      "gpu_available": true,
      "eager_execution": true
    }
  }
]