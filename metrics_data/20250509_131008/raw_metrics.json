[
  {
    "timestamp": "2025-05-09T13:05:06.167578",
    "gpu": {
      "utilization": {
        "0": 1
      },
      "memory": {
        "0": {
          "used_mb": 9901,
          "total_mb": 10240,
          "percentage": 96.689453125
        }
      },
      "temperature": {
        "0": 44
      },
      "power": {
        "0": {
          "draw_watts": 123.98,
          "limit_watts": 370.0,
          "percentage": 33.50810810810811
        }
      },
      "clock_speeds": {
        "0": {
          "graphics_mhz": 1905,
          "memory_mhz": 9251
        }
      },
      "pcie_throughput": {
        "0": {
          "link_gen": "4",
          "link_width": "8",
          "max_bandwidth_GBps": 15.76,
          "mem_controller_util": 1.0,
          "estimated_usage_GBps": 0.1576
        }
      },
      "idle_time": 0,
      "is_currently_idle": true
    },
    "cpu": {
      "utilization": {
        "overall": 0.0,
        "per_core": [
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0
        ],
        "logical_cores": 20,
        "physical_cores": 14
      },
      "unused_cores": {
        "unused_core_count": 20,
        "unused_core_indices": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19
        ],
        "threshold": 10
      },
      "memory": {
        "total_gb": 31.13628387451172,
        "used_gb": 8.014835357666016,
        "available_gb": 22.612258911132812,
        "percent_used": 27.4,
        "swap_total_gb": 0.9540977478027344,
        "swap_used_gb": 0.6725654602050781,
        "swap_percent": 70.5
      }
    },
    "latency": {
      "inference": {
        "batch_size": 1,
        "num_runs": 10,
        "avg_latency_ms": 19.08695697784424,
        "throughput_samples_per_sec": 52.39179829245595
      },
      "training_step": {
        "error": "in user code:\n\n    File \"/home/p0wden/Downloads/mloptimizer/app/common/GpuMetrics.py\", line 588, in train_step  *\n        loss = model.loss(y, y_pred)\n\n    TypeError: 'str' object is not callable\n"
      },
      "data_pipeline": {
        "status": "no dataset provided"
      }
    },
    "framework_specific": {
      "version": "2.19.0",
      "built_with_cuda": true,
      "gpu_available": true,
      "eager_execution": true
    }
  },
  {
    "timestamp": "2025-05-09T13:06:05.711839",
    "gpu": {
      "utilization": {
        "0": 88
      },
      "memory": {
        "0": {
          "used_mb": 9956,
          "total_mb": 10240,
          "percentage": 97.2265625
        }
      },
      "temperature": {
        "0": 46
      },
      "power": {
        "0": {
          "draw_watts": 153.92,
          "limit_watts": 370.0,
          "percentage": 41.6
        }
      },
      "clock_speeds": {
        "0": {
          "graphics_mhz": 1965,
          "memory_mhz": 9251
        }
      },
      "pcie_throughput": {
        "0": {
          "link_gen": "4",
          "link_width": "8",
          "max_bandwidth_GBps": 15.76,
          "mem_controller_util": 0.6666666666666666,
          "estimated_usage_GBps": 0.10506666666666666
        }
      },
      "idle_time": 59.54392147064209,
      "is_currently_idle": false
    },
    "cpu": {
      "utilization": {
        "overall": 0.0,
        "per_core": [
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0
        ],
        "logical_cores": 20,
        "physical_cores": 14
      },
      "unused_cores": {
        "unused_core_count": 4,
        "unused_core_indices": [
          0,
          1,
          9,
          12
        ],
        "threshold": 10
      },
      "memory": {
        "total_gb": 31.13628387451172,
        "used_gb": 10.03989028930664,
        "available_gb": 20.573535919189453,
        "percent_used": 33.9,
        "swap_total_gb": 0.9540977478027344,
        "swap_used_gb": 0.6567001342773438,
        "swap_percent": 68.8
      }
    },
    "latency": {
      "inference": {
        "batch_size": 1,
        "num_runs": 10,
        "avg_latency_ms": 19.09627914428711,
        "throughput_samples_per_sec": 52.36622236427469
      },
      "training_step": {
        "error": "in user code:\n\n    File \"/home/p0wden/Downloads/mloptimizer/app/common/GpuMetrics.py\", line 588, in train_step  *\n        loss = model.loss(y, y_pred)\n\n    TypeError: 'str' object is not callable\n"
      },
      "data_pipeline": {
        "status": "no dataset provided"
      }
    },
    "framework_specific": {
      "version": "2.19.0",
      "built_with_cuda": true,
      "gpu_available": true,
      "eager_execution": true
    }
  },
  {
    "timestamp": "2025-05-09T13:06:08.481022",
    "gpu": {
      "utilization": {
        "0": 3
      },
      "memory": {
        "0": {
          "used_mb": 9953,
          "total_mb": 10240,
          "percentage": 97.197265625
        }
      },
      "temperature": {
        "0": 44
      },
      "power": {
        "0": {
          "draw_watts": 123.33,
          "limit_watts": 370.0,
          "percentage": 33.33243243243243
        }
      },
      "clock_speeds": {
        "0": {
          "graphics_mhz": 1905,
          "memory_mhz": 9251
        }
      },
      "pcie_throughput": {
        "0": {
          "link_gen": "4",
          "link_width": "8",
          "max_bandwidth_GBps": 15.76,
          "mem_controller_util": 0.6666666666666666,
          "estimated_usage_GBps": 0.10506666666666666
        }
      },
      "idle_time": 0,
      "is_currently_idle": true
    },
    "cpu": {
      "utilization": {
        "overall": 0.0,
        "per_core": [
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          9.1,
          0.0,
          0.0
        ],
        "logical_cores": 20,
        "physical_cores": 14
      },
      "unused_cores": {
        "unused_core_count": 20,
        "unused_core_indices": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19
        ],
        "threshold": 10
      },
      "memory": {
        "total_gb": 31.13628387451172,
        "used_gb": 10.035438537597656,
        "available_gb": 20.577987670898438,
        "percent_used": 33.9,
        "swap_total_gb": 0.9540977478027344,
        "swap_used_gb": 0.6566963195800781,
        "swap_percent": 68.8
      }
    },
    "latency": {
      "inference": {
        "batch_size": 1,
        "num_runs": 10,
        "avg_latency_ms": 19.077110290527344,
        "throughput_samples_per_sec": 52.41884042032014
      },
      "training_step": {
        "error": "in user code:\n\n    File \"/home/p0wden/Downloads/mloptimizer/app/common/GpuMetrics.py\", line 588, in train_step  *\n        loss = model.loss(y, y_pred)\n\n    TypeError: 'str' object is not callable\n"
      },
      "data_pipeline": {
        "status": "no dataset provided"
      }
    },
    "framework_specific": {
      "version": "2.19.0",
      "built_with_cuda": true,
      "gpu_available": true,
      "eager_execution": true
    }
  },
  {
    "timestamp": "2025-05-09T13:07:02.157462",
    "gpu": {
      "utilization": {
        "0": 93
      },
      "memory": {
        "0": {
          "used_mb": 9973,
          "total_mb": 10240,
          "percentage": 97.392578125
        }
      },
      "temperature": {
        "0": 46
      },
      "power": {
        "0": {
          "draw_watts": 151.27,
          "limit_watts": 370.0,
          "percentage": 40.88378378378379
        }
      },
      "clock_speeds": {
        "0": {
          "graphics_mhz": 1965,
          "memory_mhz": 9251
        }
      },
      "pcie_throughput": {
        "0": {
          "link_gen": "4",
          "link_width": "8",
          "max_bandwidth_GBps": 15.76,
          "mem_controller_util": 1.0,
          "estimated_usage_GBps": 0.1576
        }
      },
      "idle_time": 53.67285466194153,
      "is_currently_idle": false
    },
    "cpu": {
      "utilization": {
        "overall": 4.0,
        "per_core": [
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0
        ],
        "logical_cores": 20,
        "physical_cores": 14
      },
      "unused_cores": {
        "unused_core_count": 19,
        "unused_core_indices": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19
        ],
        "threshold": 10
      },
      "memory": {
        "total_gb": 31.13628387451172,
        "used_gb": 10.471725463867188,
        "available_gb": 20.141613006591797,
        "percent_used": 35.3,
        "swap_total_gb": 0.9540977478027344,
        "swap_used_gb": 0.6267318725585938,
        "swap_percent": 65.7
      }
    },
    "latency": {
      "inference": {
        "batch_size": 1,
        "num_runs": 10,
        "avg_latency_ms": 19.435429573059082,
        "throughput_samples_per_sec": 51.45242590295897
      },
      "training_step": {
        "error": "in user code:\n\n    File \"/home/p0wden/Downloads/mloptimizer/app/common/GpuMetrics.py\", line 588, in train_step  *\n        loss = model.loss(y, y_pred)\n\n    TypeError: 'str' object is not callable\n"
      },
      "data_pipeline": {
        "status": "no dataset provided"
      }
    },
    "framework_specific": {
      "version": "2.19.0",
      "built_with_cuda": true,
      "gpu_available": true,
      "eager_execution": true
    }
  },
  {
    "timestamp": "2025-05-09T13:07:04.952817",
    "gpu": {
      "utilization": {
        "0": 2
      },
      "memory": {
        "0": {
          "used_mb": 9969,
          "total_mb": 10240,
          "percentage": 97.353515625
        }
      },
      "temperature": {
        "0": 45
      },
      "power": {
        "0": {
          "draw_watts": 138.96,
          "limit_watts": 370.0,
          "percentage": 37.55675675675676
        }
      },
      "clock_speeds": {
        "0": {
          "graphics_mhz": 1965,
          "memory_mhz": 9251
        }
      },
      "pcie_throughput": {
        "0": {
          "link_gen": "4",
          "link_width": "8",
          "max_bandwidth_GBps": 15.76,
          "mem_controller_util": 1.0,
          "estimated_usage_GBps": 0.1576
        }
      },
      "idle_time": 0,
      "is_currently_idle": true
    },
    "cpu": {
      "utilization": {
        "overall": 5.0,
        "per_core": [
          9.1,
          0.0,
          10.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          10.0,
          0.0,
          25.0,
          0.0,
          0.0,
          0.0,
          0.0,
          10.0,
          0.0,
          0.0
        ],
        "logical_cores": 20,
        "physical_cores": 14
      },
      "unused_cores": {
        "unused_core_count": 19,
        "unused_core_indices": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19
        ],
        "threshold": 10
      },
      "memory": {
        "total_gb": 31.13628387451172,
        "used_gb": 10.500972747802734,
        "available_gb": 20.11236572265625,
        "percent_used": 35.4,
        "swap_total_gb": 0.9540977478027344,
        "swap_used_gb": 0.6267318725585938,
        "swap_percent": 65.7
      }
    },
    "latency": {
      "inference": {
        "batch_size": 1,
        "num_runs": 10,
        "avg_latency_ms": 20.667695999145508,
        "throughput_samples_per_sec": 48.38468690662686
      },
      "training_step": {
        "error": "in user code:\n\n    File \"/home/p0wden/Downloads/mloptimizer/app/common/GpuMetrics.py\", line 588, in train_step  *\n        loss = model.loss(y, y_pred)\n\n    TypeError: 'str' object is not callable\n"
      },
      "data_pipeline": {
        "status": "no dataset provided"
      }
    },
    "framework_specific": {
      "version": "2.19.0",
      "built_with_cuda": true,
      "gpu_available": true,
      "eager_execution": true
    }
  },
  {
    "timestamp": "2025-05-09T13:07:47.283711",
    "gpu": {
      "utilization": {
        "0": 0
      },
      "memory": {
        "0": {
          "used_mb": 9954,
          "total_mb": 10240,
          "percentage": 97.20703125
        }
      },
      "temperature": {
        "0": 45
      },
      "power": {
        "0": {
          "draw_watts": 144.82,
          "limit_watts": 370.0,
          "percentage": 39.140540540540535
        }
      },
      "clock_speeds": {
        "0": {
          "graphics_mhz": 1965,
          "memory_mhz": 9251
        }
      },
      "pcie_throughput": {
        "0": {
          "link_gen": "4",
          "link_width": "8",
          "max_bandwidth_GBps": 15.76,
          "mem_controller_util": 0.3333333333333333,
          "estimated_usage_GBps": 0.05253333333333333
        }
      },
      "idle_time": 42.32649040222168,
      "is_currently_idle": true
    },
    "cpu": {
      "utilization": {
        "overall": 0.0,
        "per_core": [
          18.2,
          0.0,
          9.1,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          10.0,
          0.0,
          30.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0
        ],
        "logical_cores": 20,
        "physical_cores": 14
      },
      "unused_cores": {
        "unused_core_count": 19,
        "unused_core_indices": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19
        ],
        "threshold": 10
      },
      "memory": {
        "total_gb": 31.13628387451172,
        "used_gb": 10.63344955444336,
        "available_gb": 19.979873657226562,
        "percent_used": 35.8,
        "swap_total_gb": 0.9540977478027344,
        "swap_used_gb": 0.6263313293457031,
        "swap_percent": 65.6
      }
    },
    "latency": {
      "inference": {
        "batch_size": 1,
        "num_runs": 10,
        "avg_latency_ms": 19.382786750793457,
        "throughput_samples_per_sec": 51.59216849760078
      },
      "training_step": {
        "error": "in user code:\n\n    File \"/home/p0wden/Downloads/mloptimizer/app/common/GpuMetrics.py\", line 588, in train_step  *\n        loss = model.loss(y, y_pred)\n\n    TypeError: 'str' object is not callable\n"
      },
      "data_pipeline": {
        "status": "no dataset provided"
      }
    },
    "framework_specific": {
      "version": "2.19.0",
      "built_with_cuda": true,
      "gpu_available": true,
      "eager_execution": true
    }
  },
  {
    "timestamp": "2025-05-09T13:07:50.104188",
    "gpu": {
      "utilization": {
        "0": 1
      },
      "memory": {
        "0": {
          "used_mb": 9954,
          "total_mb": 10240,
          "percentage": 97.20703125
        }
      },
      "temperature": {
        "0": 44
      },
      "power": {
        "0": {
          "draw_watts": 122.83,
          "limit_watts": 370.0,
          "percentage": 33.1972972972973
        }
      },
      "clock_speeds": {
        "0": {
          "graphics_mhz": 1905,
          "memory_mhz": 9251
        }
      },
      "pcie_throughput": {
        "0": {
          "link_gen": "4",
          "link_width": "8",
          "max_bandwidth_GBps": 15.76,
          "mem_controller_util": 0.6666666666666666,
          "estimated_usage_GBps": 0.10506666666666666
        }
      },
      "idle_time": 45.15148401260376,
      "is_currently_idle": true
    },
    "cpu": {
      "utilization": {
        "overall": 0.0,
        "per_core": [
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          9.1,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0
        ],
        "logical_cores": 20,
        "physical_cores": 14
      },
      "unused_cores": {
        "unused_core_count": 20,
        "unused_core_indices": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19
        ],
        "threshold": 10
      },
      "memory": {
        "total_gb": 31.13628387451172,
        "used_gb": 10.571521759033203,
        "available_gb": 20.041820526123047,
        "percent_used": 35.6,
        "swap_total_gb": 0.9540977478027344,
        "swap_used_gb": 0.6263313293457031,
        "swap_percent": 65.6
      }
    },
    "latency": {
      "inference": {
        "batch_size": 1,
        "num_runs": 10,
        "avg_latency_ms": 18.999886512756348,
        "throughput_samples_per_sec": 52.63189331834215
      },
      "training_step": {
        "error": "in user code:\n\n    File \"/home/p0wden/Downloads/mloptimizer/app/common/GpuMetrics.py\", line 588, in train_step  *\n        loss = model.loss(y, y_pred)\n\n    TypeError: 'str' object is not callable\n"
      },
      "data_pipeline": {
        "status": "no dataset provided"
      }
    },
    "framework_specific": {
      "version": "2.19.0",
      "built_with_cuda": true,
      "gpu_available": true,
      "eager_execution": true
    }
  },
  {
    "timestamp": "2025-05-09T13:08:31.531757",
    "gpu": {
      "utilization": {
        "0": 14
      },
      "memory": {
        "0": {
          "used_mb": 9946,
          "total_mb": 10240,
          "percentage": 97.12890625
        }
      },
      "temperature": {
        "0": 45
      },
      "power": {
        "0": {
          "draw_watts": 144.0,
          "limit_watts": 370.0,
          "percentage": 38.91891891891892
        }
      },
      "clock_speeds": {
        "0": {
          "graphics_mhz": 1965,
          "memory_mhz": 9251
        }
      },
      "pcie_throughput": {
        "0": {
          "link_gen": "4",
          "link_width": "8",
          "max_bandwidth_GBps": 15.76,
          "mem_controller_util": 0.3333333333333333,
          "estimated_usage_GBps": 0.05253333333333333
        }
      },
      "idle_time": 86.57907176017761,
      "is_currently_idle": false
    },
    "cpu": {
      "utilization": {
        "overall": 0.0,
        "per_core": [
          0.0,
          0.0,
          0.0,
          0.0,
          10.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          9.1,
          0.0
        ],
        "logical_cores": 20,
        "physical_cores": 14
      },
      "unused_cores": {
        "unused_core_count": 20,
        "unused_core_indices": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19
        ],
        "threshold": 10
      },
      "memory": {
        "total_gb": 31.13628387451172,
        "used_gb": 10.844978332519531,
        "available_gb": 19.768360137939453,
        "percent_used": 36.5,
        "swap_total_gb": 0.9540977478027344,
        "swap_used_gb": 0.6261749267578125,
        "swap_percent": 65.6
      }
    },
    "latency": {
      "inference": {
        "batch_size": 1,
        "num_runs": 10,
        "avg_latency_ms": 18.89486312866211,
        "throughput_samples_per_sec": 52.92443735583742
      },
      "training_step": {
        "error": "in user code:\n\n    File \"/home/p0wden/Downloads/mloptimizer/app/common/GpuMetrics.py\", line 588, in train_step  *\n        loss = model.loss(y, y_pred)\n\n    TypeError: 'str' object is not callable\n"
      },
      "data_pipeline": {
        "status": "no dataset provided"
      }
    },
    "framework_specific": {
      "version": "2.19.0",
      "built_with_cuda": true,
      "gpu_available": true,
      "eager_execution": true
    }
  },
  {
    "timestamp": "2025-05-09T13:08:34.281417",
    "gpu": {
      "utilization": {
        "0": 1
      },
      "memory": {
        "0": {
          "used_mb": 9946,
          "total_mb": 10240,
          "percentage": 97.12890625
        }
      },
      "temperature": {
        "0": 44
      },
      "power": {
        "0": {
          "draw_watts": 122.31,
          "limit_watts": 370.0,
          "percentage": 33.056756756756755
        }
      },
      "clock_speeds": {
        "0": {
          "graphics_mhz": 1905,
          "memory_mhz": 9251
        }
      },
      "pcie_throughput": {
        "0": {
          "link_gen": "4",
          "link_width": "8",
          "max_bandwidth_GBps": 15.76,
          "mem_controller_util": 0.3333333333333333,
          "estimated_usage_GBps": 0.05253333333333333
        }
      },
      "idle_time": 0,
      "is_currently_idle": true
    },
    "cpu": {
      "utilization": {
        "overall": 0.0,
        "per_core": [
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0
        ],
        "logical_cores": 20,
        "physical_cores": 14
      },
      "unused_cores": {
        "unused_core_count": 20,
        "unused_core_indices": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19
        ],
        "threshold": 10
      },
      "memory": {
        "total_gb": 31.13628387451172,
        "used_gb": 10.881511688232422,
        "available_gb": 19.731834411621094,
        "percent_used": 36.6,
        "swap_total_gb": 0.9540977478027344,
        "swap_used_gb": 0.6261749267578125,
        "swap_percent": 65.6
      }
    },
    "latency": {
      "inference": {
        "batch_size": 1,
        "num_runs": 10,
        "avg_latency_ms": 19.27359104156494,
        "throughput_samples_per_sec": 51.88446708469767
      },
      "training_step": {
        "error": "in user code:\n\n    File \"/home/p0wden/Downloads/mloptimizer/app/common/GpuMetrics.py\", line 588, in train_step  *\n        loss = model.loss(y, y_pred)\n\n    TypeError: 'str' object is not callable\n"
      },
      "data_pipeline": {
        "status": "no dataset provided"
      }
    },
    "framework_specific": {
      "version": "2.19.0",
      "built_with_cuda": true,
      "gpu_available": true,
      "eager_execution": true
    }
  },
  {
    "timestamp": "2025-05-09T13:09:14.851943",
    "gpu": {
      "utilization": {
        "0": 6
      },
      "memory": {
        "0": {
          "used_mb": 9946,
          "total_mb": 10240,
          "percentage": 97.12890625
        }
      },
      "temperature": {
        "0": 45
      },
      "power": {
        "0": {
          "draw_watts": 144.54,
          "limit_watts": 370.0,
          "percentage": 39.06486486486486
        }
      },
      "clock_speeds": {
        "0": {
          "graphics_mhz": 1965,
          "memory_mhz": 9251
        }
      },
      "pcie_throughput": {
        "0": {
          "link_gen": "4",
          "link_width": "8",
          "max_bandwidth_GBps": 15.76,
          "mem_controller_util": 0.3333333333333333,
          "estimated_usage_GBps": 0.05253333333333333
        }
      },
      "idle_time": 40.57095766067505,
      "is_currently_idle": false
    },
    "cpu": {
      "utilization": {
        "overall": 0.0,
        "per_core": [
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0
        ],
        "logical_cores": 20,
        "physical_cores": 14
      },
      "unused_cores": {
        "unused_core_count": 20,
        "unused_core_indices": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19
        ],
        "threshold": 10
      },
      "memory": {
        "total_gb": 31.13628387451172,
        "used_gb": 11.078266143798828,
        "available_gb": 19.535079956054688,
        "percent_used": 37.3,
        "swap_total_gb": 0.9540977478027344,
        "swap_used_gb": 0.6261405944824219,
        "swap_percent": 65.6
      }
    },
    "latency": {
      "inference": {
        "batch_size": 1,
        "num_runs": 10,
        "avg_latency_ms": 20.201969146728516,
        "throughput_samples_per_sec": 49.50012509854461
      },
      "training_step": {
        "error": "in user code:\n\n    File \"/home/p0wden/Downloads/mloptimizer/app/common/GpuMetrics.py\", line 588, in train_step  *\n        loss = model.loss(y, y_pred)\n\n    TypeError: 'str' object is not callable\n"
      },
      "data_pipeline": {
        "status": "no dataset provided"
      }
    },
    "framework_specific": {
      "version": "2.19.0",
      "built_with_cuda": true,
      "gpu_available": true,
      "eager_execution": true
    }
  },
  {
    "timestamp": "2025-05-09T13:09:17.621333",
    "gpu": {
      "utilization": {
        "0": 6
      },
      "memory": {
        "0": {
          "used_mb": 9948,
          "total_mb": 10240,
          "percentage": 97.1484375
        }
      },
      "temperature": {
        "0": 44
      },
      "power": {
        "0": {
          "draw_watts": 123.41,
          "limit_watts": 370.0,
          "percentage": 33.35405405405405
        }
      },
      "clock_speeds": {
        "0": {
          "graphics_mhz": 1905,
          "memory_mhz": 9251
        }
      },
      "pcie_throughput": {
        "0": {
          "link_gen": "4",
          "link_width": "8",
          "max_bandwidth_GBps": 15.76,
          "mem_controller_util": 1.0,
          "estimated_usage_GBps": 0.1576
        }
      },
      "idle_time": 0,
      "is_currently_idle": false
    },
    "cpu": {
      "utilization": {
        "overall": 1.5,
        "per_core": [
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          9.1,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0
        ],
        "logical_cores": 20,
        "physical_cores": 14
      },
      "unused_cores": {
        "unused_core_count": 17,
        "unused_core_indices": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          19
        ],
        "threshold": 10
      },
      "memory": {
        "total_gb": 31.13628387451172,
        "used_gb": 11.139225006103516,
        "available_gb": 19.47411346435547,
        "percent_used": 37.5,
        "swap_total_gb": 0.9540977478027344,
        "swap_used_gb": 0.6261405944824219,
        "swap_percent": 65.6
      }
    },
    "latency": {
      "inference": {
        "batch_size": 1,
        "num_runs": 10,
        "avg_latency_ms": 20.627236366271973,
        "throughput_samples_per_sec": 48.47959184852902
      },
      "training_step": {
        "error": "in user code:\n\n    File \"/home/p0wden/Downloads/mloptimizer/app/common/GpuMetrics.py\", line 588, in train_step  *\n        loss = model.loss(y, y_pred)\n\n    TypeError: 'str' object is not callable\n"
      },
      "data_pipeline": {
        "status": "no dataset provided"
      }
    },
    "framework_specific": {
      "version": "2.19.0",
      "built_with_cuda": true,
      "gpu_available": true,
      "eager_execution": true
    }
  },
  {
    "timestamp": "2025-05-09T13:10:05.332245",
    "gpu": {
      "utilization": {
        "0": 18
      },
      "memory": {
        "0": {
          "used_mb": 9963,
          "total_mb": 10240,
          "percentage": 97.294921875
        }
      },
      "temperature": {
        "0": 45
      },
      "power": {
        "0": {
          "draw_watts": 145.32,
          "limit_watts": 370.0,
          "percentage": 39.27567567567568
        }
      },
      "clock_speeds": {
        "0": {
          "graphics_mhz": 1965,
          "memory_mhz": 9251
        }
      },
      "pcie_throughput": {
        "0": {
          "link_gen": "4",
          "link_width": "8",
          "max_bandwidth_GBps": 15.76,
          "mem_controller_util": 0.6666666666666666,
          "estimated_usage_GBps": 0.10506666666666666
        }
      },
      "idle_time": 0,
      "is_currently_idle": false
    },
    "cpu": {
      "utilization": {
        "overall": 0.5,
        "per_core": [
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0
        ],
        "logical_cores": 20,
        "physical_cores": 14
      },
      "unused_cores": {
        "unused_core_count": 20,
        "unused_core_indices": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19
        ],
        "threshold": 10
      },
      "memory": {
        "total_gb": 31.13628387451172,
        "used_gb": 11.371955871582031,
        "available_gb": 19.24134063720703,
        "percent_used": 38.2,
        "swap_total_gb": 0.9540977478027344,
        "swap_used_gb": 0.6236686706542969,
        "swap_percent": 65.4
      }
    },
    "latency": {
      "inference": {
        "batch_size": 1,
        "num_runs": 10,
        "avg_latency_ms": 19.624710083007812,
        "throughput_samples_per_sec": 50.95616678005637
      },
      "training_step": {
        "error": "in user code:\n\n    File \"/home/p0wden/Downloads/mloptimizer/app/common/GpuMetrics.py\", line 588, in train_step  *\n        loss = model.loss(y, y_pred)\n\n    TypeError: 'str' object is not callable\n"
      },
      "data_pipeline": {
        "status": "no dataset provided"
      }
    },
    "framework_specific": {
      "version": "2.19.0",
      "built_with_cuda": true,
      "gpu_available": true,
      "eager_execution": true
    }
  }
]