[
  {
    "timestamp": "2025-12-02T16:40:25.790627",
    "gpu": {
      "utilization": {
        "0": 32
      },
      "memory": {
        "0": {
          "used_mb": 9629,
          "total_mb": 10240,
          "percentage": 94.033203125
        }
      },
      "temperature": {
        "0": 43
      },
      "power": {
        "0": {
          "draw_watts": 119.74,
          "limit_watts": 370.0,
          "percentage": 32.362162162162164
        }
      },
      "clock_speeds": {
        "0": {
          "graphics_mhz": 1905,
          "memory_mhz": 9251
        }
      },
      "pcie_throughput": {
        "0": {
          "link_gen": "4",
          "link_width": "8",
          "max_bandwidth_GBps": 15.76,
          "mem_controller_util": 1.3333333333333333,
          "estimated_usage_GBps": 0.2101333333333333
        }
      },
      "idle_time": 0,
      "is_currently_idle": false
    },
    "cpu": {
      "utilization": {
        "overall": 0.5,
        "per_core": [
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0
        ],
        "logical_cores": 20,
        "physical_cores": 14
      },
      "unused_cores": {
        "unused_core_count": 20,
        "unused_core_indices": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19
        ],
        "threshold": 10
      },
      "memory": {
        "total_gb": 31.136207580566406,
        "used_gb": 9.850200653076172,
        "available_gb": 20.593887329101562,
        "percent_used": 33.9,
        "swap_total_gb": 0.9540977478027344,
        "swap_used_gb": 0.0,
        "swap_percent": 0.0
      }
    },
    "latency": {
      "inference": {
        "status": "no model registered"
      },
      "training_step": {
        "status": "no model available"
      },
      "data_pipeline": {
        "status": "no dataset provided"
      }
    },
    "framework_specific": {
      "version": "2.17.0",
      "built_with_cuda": true,
      "gpu_available": true,
      "eager_execution": true
    }
  },
  {
    "timestamp": "2025-12-02T16:40:30.015028",
    "gpu": {
      "utilization": {
        "0": 2
      },
      "memory": {
        "0": {
          "used_mb": 9635,
          "total_mb": 10240,
          "percentage": 94.091796875
        }
      },
      "temperature": {
        "0": 43
      },
      "power": {
        "0": {
          "draw_watts": 118.28,
          "limit_watts": 370.0,
          "percentage": 31.967567567567567
        }
      },
      "clock_speeds": {
        "0": {
          "graphics_mhz": 1905,
          "memory_mhz": 9251
        }
      },
      "pcie_throughput": {
        "0": {
          "link_gen": "4",
          "link_width": "8",
          "max_bandwidth_GBps": 15.76,
          "mem_controller_util": 0.3333333333333333,
          "estimated_usage_GBps": 0.05253333333333333
        }
      },
      "idle_time": 0,
      "is_currently_idle": true
    },
    "cpu": {
      "utilization": {
        "overall": 0.0,
        "per_core": [
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0
        ],
        "logical_cores": 20,
        "physical_cores": 14
      },
      "unused_cores": {
        "unused_core_count": 20,
        "unused_core_indices": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19
        ],
        "threshold": 10
      },
      "memory": {
        "total_gb": 31.136207580566406,
        "used_gb": 9.966316223144531,
        "available_gb": 20.475872039794922,
        "percent_used": 34.2,
        "swap_total_gb": 0.9540977478027344,
        "swap_used_gb": 0.0,
        "swap_percent": 0.0
      }
    },
    "latency": {
      "inference": {
        "batch_size": 1,
        "num_runs": 10,
        "avg_latency_ms": 18.647098541259766,
        "throughput_samples_per_sec": 53.62764602693207
      },
      "training_step": {
        "error": "in user code:\n\n    File \"/home/p0wden/Documents/mloptimizer/app/common/GpuMetrics.py\", line 588, in train_step  *\n        loss = model.loss(y, y_pred)\n\n    TypeError: 'str' object is not callable\n"
      },
      "data_pipeline": {
        "status": "no dataset provided"
      }
    },
    "framework_specific": {
      "version": "2.17.0",
      "built_with_cuda": true,
      "gpu_available": true,
      "eager_execution": true
    }
  },
  {
    "timestamp": "2025-12-02T16:42:28.404032",
    "gpu": {
      "utilization": {
        "0": 20
      },
      "memory": {
        "0": {
          "used_mb": 9686,
          "total_mb": 10240,
          "percentage": 94.58984375
        }
      },
      "temperature": {
        "0": 44
      },
      "power": {
        "0": {
          "draw_watts": 122.47,
          "limit_watts": 370.0,
          "percentage": 33.1
        }
      },
      "clock_speeds": {
        "0": {
          "graphics_mhz": 1905,
          "memory_mhz": 9251
        }
      },
      "pcie_throughput": {
        "0": {
          "link_gen": "4",
          "link_width": "8",
          "max_bandwidth_GBps": 15.76,
          "mem_controller_util": 0.6666666666666666,
          "estimated_usage_GBps": 0.10506666666666666
        }
      },
      "idle_time": 118.38908863067627,
      "is_currently_idle": false
    },
    "cpu": {
      "utilization": {
        "overall": 0.0,
        "per_core": [
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0
        ],
        "logical_cores": 20,
        "physical_cores": 14
      },
      "unused_cores": {
        "unused_core_count": 20,
        "unused_core_indices": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19
        ],
        "threshold": 10
      },
      "memory": {
        "total_gb": 31.136207580566406,
        "used_gb": 11.102691650390625,
        "available_gb": 19.33884048461914,
        "percent_used": 37.9,
        "swap_total_gb": 0.9540977478027344,
        "swap_used_gb": 0.0,
        "swap_percent": 0.0
      }
    },
    "latency": {
      "inference": {
        "batch_size": 1,
        "num_runs": 10,
        "avg_latency_ms": 18.06468963623047,
        "throughput_samples_per_sec": 55.35661116448987
      },
      "training_step": {
        "error": "in user code:\n\n    File \"/home/p0wden/Documents/mloptimizer/app/common/GpuMetrics.py\", line 588, in train_step  *\n        loss = model.loss(y, y_pred)\n\n    TypeError: 'str' object is not callable\n"
      },
      "data_pipeline": {
        "status": "no dataset provided"
      }
    },
    "framework_specific": {
      "version": "2.17.0",
      "built_with_cuda": true,
      "gpu_available": true,
      "eager_execution": true
    }
  },
  {
    "timestamp": "2025-12-02T16:42:31.230589",
    "gpu": {
      "utilization": {
        "0": 0
      },
      "memory": {
        "0": {
          "used_mb": 9686,
          "total_mb": 10240,
          "percentage": 94.58984375
        }
      },
      "temperature": {
        "0": 43
      },
      "power": {
        "0": {
          "draw_watts": 117.21,
          "limit_watts": 370.0,
          "percentage": 31.678378378378376
        }
      },
      "clock_speeds": {
        "0": {
          "graphics_mhz": 1905,
          "memory_mhz": 9251
        }
      },
      "pcie_throughput": {
        "0": {
          "link_gen": "4",
          "link_width": "8",
          "max_bandwidth_GBps": 15.76,
          "mem_controller_util": 0.3333333333333333,
          "estimated_usage_GBps": 0.05253333333333333
        }
      },
      "idle_time": 0,
      "is_currently_idle": true
    },
    "cpu": {
      "utilization": {
        "overall": 0.5,
        "per_core": [
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0
        ],
        "logical_cores": 20,
        "physical_cores": 14
      },
      "unused_cores": {
        "unused_core_count": 20,
        "unused_core_indices": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19
        ],
        "threshold": 10
      },
      "memory": {
        "total_gb": 31.136207580566406,
        "used_gb": 11.040660858154297,
        "available_gb": 19.40087890625,
        "percent_used": 37.7,
        "swap_total_gb": 0.9540977478027344,
        "swap_used_gb": 0.0,
        "swap_percent": 0.0
      }
    },
    "latency": {
      "inference": {
        "batch_size": 1,
        "num_runs": 10,
        "avg_latency_ms": 18.36535930633545,
        "throughput_samples_per_sec": 54.45033681726187
      },
      "training_step": {
        "error": "in user code:\n\n    File \"/home/p0wden/Documents/mloptimizer/app/common/GpuMetrics.py\", line 588, in train_step  *\n        loss = model.loss(y, y_pred)\n\n    TypeError: 'str' object is not callable\n"
      },
      "data_pipeline": {
        "status": "no dataset provided"
      }
    },
    "framework_specific": {
      "version": "2.17.0",
      "built_with_cuda": true,
      "gpu_available": true,
      "eager_execution": true
    }
  },
  {
    "timestamp": "2025-12-02T16:44:21.343054",
    "gpu": {
      "utilization": {
        "0": 19
      },
      "memory": {
        "0": {
          "used_mb": 9686,
          "total_mb": 10240,
          "percentage": 94.58984375
        }
      },
      "temperature": {
        "0": 44
      },
      "power": {
        "0": {
          "draw_watts": 125.67,
          "limit_watts": 370.0,
          "percentage": 33.964864864864865
        }
      },
      "clock_speeds": {
        "0": {
          "graphics_mhz": 1905,
          "memory_mhz": 9251
        }
      },
      "pcie_throughput": {
        "0": {
          "link_gen": "4",
          "link_width": "8",
          "max_bandwidth_GBps": 15.76,
          "mem_controller_util": 0.3333333333333333,
          "estimated_usage_GBps": 0.05253333333333333
        }
      },
      "idle_time": 110.11291718482971,
      "is_currently_idle": false
    },
    "cpu": {
      "utilization": {
        "overall": 0.0,
        "per_core": [
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0
        ],
        "logical_cores": 20,
        "physical_cores": 14
      },
      "unused_cores": {
        "unused_core_count": 20,
        "unused_core_indices": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19
        ],
        "threshold": 10
      },
      "memory": {
        "total_gb": 31.136207580566406,
        "used_gb": 11.07181167602539,
        "available_gb": 19.36922836303711,
        "percent_used": 37.8,
        "swap_total_gb": 0.9540977478027344,
        "swap_used_gb": 0.0,
        "swap_percent": 0.0
      }
    },
    "latency": {
      "inference": {
        "batch_size": 1,
        "num_runs": 10,
        "avg_latency_ms": 18.550801277160645,
        "throughput_samples_per_sec": 53.90602729549903
      },
      "training_step": {
        "error": "in user code:\n\n    File \"/home/p0wden/Documents/mloptimizer/app/common/GpuMetrics.py\", line 588, in train_step  *\n        loss = model.loss(y, y_pred)\n\n    TypeError: 'str' object is not callable\n"
      },
      "data_pipeline": {
        "status": "no dataset provided"
      }
    },
    "framework_specific": {
      "version": "2.17.0",
      "built_with_cuda": true,
      "gpu_available": true,
      "eager_execution": true
    }
  },
  {
    "timestamp": "2025-12-02T16:44:24.284966",
    "gpu": {
      "utilization": {
        "0": 3
      },
      "memory": {
        "0": {
          "used_mb": 9686,
          "total_mb": 10240,
          "percentage": 94.58984375
        }
      },
      "temperature": {
        "0": 43
      },
      "power": {
        "0": {
          "draw_watts": 117.36,
          "limit_watts": 370.0,
          "percentage": 31.71891891891892
        }
      },
      "clock_speeds": {
        "0": {
          "graphics_mhz": 1905,
          "memory_mhz": 9251
        }
      },
      "pcie_throughput": {
        "0": {
          "link_gen": "4",
          "link_width": "8",
          "max_bandwidth_GBps": 15.76,
          "mem_controller_util": 0.6666666666666666,
          "estimated_usage_GBps": 0.10506666666666666
        }
      },
      "idle_time": 0,
      "is_currently_idle": true
    },
    "cpu": {
      "utilization": {
        "overall": 1.0,
        "per_core": [
          0.0,
          0.0,
          0.0,
          0.0,
          9.1,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0
        ],
        "logical_cores": 20,
        "physical_cores": 14
      },
      "unused_cores": {
        "unused_core_count": 20,
        "unused_core_indices": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19
        ],
        "threshold": 10
      },
      "memory": {
        "total_gb": 31.136207580566406,
        "used_gb": 11.059650421142578,
        "available_gb": 19.381404876708984,
        "percent_used": 37.8,
        "swap_total_gb": 0.9540977478027344,
        "swap_used_gb": 0.0,
        "swap_percent": 0.0
      }
    },
    "latency": {
      "inference": {
        "batch_size": 1,
        "num_runs": 10,
        "avg_latency_ms": 18.41561794281006,
        "throughput_samples_per_sec": 54.30173470722042
      },
      "training_step": {
        "error": "in user code:\n\n    File \"/home/p0wden/Documents/mloptimizer/app/common/GpuMetrics.py\", line 588, in train_step  *\n        loss = model.loss(y, y_pred)\n\n    TypeError: 'str' object is not callable\n"
      },
      "data_pipeline": {
        "status": "no dataset provided"
      }
    },
    "framework_specific": {
      "version": "2.17.0",
      "built_with_cuda": true,
      "gpu_available": true,
      "eager_execution": true
    }
  },
  {
    "timestamp": "2025-12-02T16:46:14.974803",
    "gpu": {
      "utilization": {
        "0": 3
      },
      "memory": {
        "0": {
          "used_mb": 9692,
          "total_mb": 10240,
          "percentage": 94.6484375
        }
      },
      "temperature": {
        "0": 43
      },
      "power": {
        "0": {
          "draw_watts": 123.17,
          "limit_watts": 370.0,
          "percentage": 33.28918918918919
        }
      },
      "clock_speeds": {
        "0": {
          "graphics_mhz": 1905,
          "memory_mhz": 9251
        }
      },
      "pcie_throughput": {
        "0": {
          "link_gen": "4",
          "link_width": "8",
          "max_bandwidth_GBps": 15.76,
          "mem_controller_util": 0.3333333333333333,
          "estimated_usage_GBps": 0.05253333333333333
        }
      },
      "idle_time": 110.69040131568909,
      "is_currently_idle": true
    },
    "cpu": {
      "utilization": {
        "overall": 0.0,
        "per_core": [
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0
        ],
        "logical_cores": 20,
        "physical_cores": 14
      },
      "unused_cores": {
        "unused_core_count": 20,
        "unused_core_indices": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19
        ],
        "threshold": 10
      },
      "memory": {
        "total_gb": 31.136207580566406,
        "used_gb": 11.104087829589844,
        "available_gb": 19.33530044555664,
        "percent_used": 37.9,
        "swap_total_gb": 0.9540977478027344,
        "swap_used_gb": 0.0,
        "swap_percent": 0.0
      }
    },
    "latency": {
      "inference": {
        "batch_size": 1,
        "num_runs": 10,
        "avg_latency_ms": 18.616700172424316,
        "throughput_samples_per_sec": 53.7152121878846
      },
      "training_step": {
        "error": "in user code:\n\n    File \"/home/p0wden/Documents/mloptimizer/app/common/GpuMetrics.py\", line 588, in train_step  *\n        loss = model.loss(y, y_pred)\n\n    TypeError: 'str' object is not callable\n"
      },
      "data_pipeline": {
        "status": "no dataset provided"
      }
    },
    "framework_specific": {
      "version": "2.17.0",
      "built_with_cuda": true,
      "gpu_available": true,
      "eager_execution": true
    }
  }
]