[
  {
    "timestamp": "2025-05-05T16:37:14.834373",
    "gpu": {
      "utilization": {
        "0": 24
      },
      "memory": {
        "0": {
          "used_mb": 9882,
          "total_mb": 10240,
          "percentage": 96.50390625
        }
      },
      "temperature": {
        "0": 46
      },
      "power": {
        "0": {
          "draw_watts": 136.88,
          "limit_watts": 370.0,
          "percentage": 36.994594594594595
        }
      },
      "clock_speeds": {
        "0": {
          "graphics_mhz": 1965,
          "memory_mhz": 9251
        }
      },
      "pcie_throughput": {
        "0": {
          "link_gen": "4",
          "link_width": "8",
          "max_bandwidth_GBps": 15.76,
          "mem_controller_util": 1.0,
          "estimated_usage_GBps": 0.1576
        }
      },
      "idle_time": 0,
      "is_currently_idle": false
    },
    "cpu": {
      "utilization": {
        "overall": 3.0,
        "per_core": [
          10.0,
          0.0,
          0.0,
          0.0,
          9.1,
          0.0,
          0.0,
          0.0,
          10.0,
          0.0,
          20.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          9.1,
          0.0,
          0.0,
          0.0
        ],
        "logical_cores": 20,
        "physical_cores": 14
      },
      "unused_cores": {
        "unused_core_count": 16,
        "unused_core_indices": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          9,
          11,
          12,
          13,
          14,
          16,
          17,
          18,
          19
        ],
        "threshold": 10
      },
      "memory": {
        "total_gb": 31.13628387451172,
        "used_gb": 23.509483337402344,
        "available_gb": 6.530277252197266,
        "percent_used": 79.0,
        "swap_total_gb": 0.9540977478027344,
        "swap_used_gb": 0.00146484375,
        "swap_percent": 0.2
      }
    },
    "latency": {
      "inference": {
        "batch_size": 1,
        "num_runs": 10,
        "avg_latency_ms": 21.866393089294434,
        "throughput_samples_per_sec": 45.73227948095335
      },
      "training_step": {
        "error": "in user code:\n\n    File \"/home/p0wden/Downloads/mloptimizer/app/common/GpuMetrics.py\", line 588, in train_step  *\n        loss = model.loss(y, y_pred)\n\n    TypeError: 'str' object is not callable\n"
      },
      "data_pipeline": {
        "status": "no dataset provided"
      }
    },
    "framework_specific": {
      "version": "2.19.0",
      "built_with_cuda": true,
      "gpu_available": true,
      "eager_execution": true
    }
  },
  {
    "timestamp": "2025-05-05T16:38:03.228981",
    "gpu": {
      "utilization": {
        "0": 4
      },
      "memory": {
        "0": {
          "used_mb": 9864,
          "total_mb": 10240,
          "percentage": 96.328125
        }
      },
      "temperature": {
        "0": 46
      },
      "power": {
        "0": {
          "draw_watts": 150.56,
          "limit_watts": 370.0,
          "percentage": 40.69189189189189
        }
      },
      "clock_speeds": {
        "0": {
          "graphics_mhz": 1965,
          "memory_mhz": 9251
        }
      },
      "pcie_throughput": {
        "0": {
          "link_gen": "4",
          "link_width": "8",
          "max_bandwidth_GBps": 15.76,
          "mem_controller_util": 1.0,
          "estimated_usage_GBps": 0.1576
        }
      },
      "idle_time": 0,
      "is_currently_idle": true
    },
    "cpu": {
      "utilization": {
        "overall": 1.0,
        "per_core": [
          9.1,
          0.0,
          0.0,
          0.0,
          9.1,
          0.0,
          9.1,
          0.0,
          9.1,
          0.0,
          18.2,
          0.0,
          0.0,
          9.1,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0
        ],
        "logical_cores": 20,
        "physical_cores": 14
      },
      "unused_cores": {
        "unused_core_count": 18,
        "unused_core_indices": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          19
        ],
        "threshold": 10
      },
      "memory": {
        "total_gb": 31.13628387451172,
        "used_gb": 23.80632781982422,
        "available_gb": 6.207424163818359,
        "percent_used": 80.1,
        "swap_total_gb": 0.9540977478027344,
        "swap_used_gb": 0.00146484375,
        "swap_percent": 0.2
      }
    },
    "latency": {
      "inference": {
        "batch_size": 1,
        "num_runs": 10,
        "avg_latency_ms": 21.080851554870605,
        "throughput_samples_per_sec": 47.4364139132205
      },
      "training_step": {
        "error": "in user code:\n\n    File \"/home/p0wden/Downloads/mloptimizer/app/common/GpuMetrics.py\", line 588, in train_step  *\n        loss = model.loss(y, y_pred)\n\n    TypeError: 'str' object is not callable\n"
      },
      "data_pipeline": {
        "status": "no dataset provided"
      }
    },
    "framework_specific": {
      "version": "2.19.0",
      "built_with_cuda": true,
      "gpu_available": true,
      "eager_execution": true
    }
  },
  {
    "timestamp": "2025-05-05T16:38:06.030751",
    "gpu": {
      "utilization": {
        "0": 3
      },
      "memory": {
        "0": {
          "used_mb": 9831,
          "total_mb": 10240,
          "percentage": 96.005859375
        }
      },
      "temperature": {
        "0": 45
      },
      "power": {
        "0": {
          "draw_watts": 119.07,
          "limit_watts": 370.0,
          "percentage": 32.18108108108108
        }
      },
      "clock_speeds": {
        "0": {
          "graphics_mhz": 1905,
          "memory_mhz": 9251
        }
      },
      "pcie_throughput": {
        "0": {
          "link_gen": "4",
          "link_width": "8",
          "max_bandwidth_GBps": 15.76,
          "mem_controller_util": 1.0,
          "estimated_usage_GBps": 0.1576
        }
      },
      "idle_time": 2.8016467094421387,
      "is_currently_idle": true
    },
    "cpu": {
      "utilization": {
        "overall": 5.4,
        "per_core": [
          0.0,
          0.0,
          10.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          10.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0
        ],
        "logical_cores": 20,
        "physical_cores": 14
      },
      "unused_cores": {
        "unused_core_count": 13,
        "unused_core_indices": [
          0,
          1,
          3,
          5,
          6,
          7,
          9,
          11,
          13,
          14,
          15,
          18,
          19
        ],
        "threshold": 10
      },
      "memory": {
        "total_gb": 31.13628387451172,
        "used_gb": 23.983901977539062,
        "available_gb": 6.014728546142578,
        "percent_used": 80.7,
        "swap_total_gb": 0.9540977478027344,
        "swap_used_gb": 0.00146484375,
        "swap_percent": 0.2
      }
    },
    "latency": {
      "inference": {
        "batch_size": 1,
        "num_runs": 10,
        "avg_latency_ms": 22.85916805267334,
        "throughput_samples_per_sec": 43.746123992603124
      },
      "training_step": {
        "error": "in user code:\n\n    File \"/home/p0wden/Downloads/mloptimizer/app/common/GpuMetrics.py\", line 588, in train_step  *\n        loss = model.loss(y, y_pred)\n\n    TypeError: 'str' object is not callable\n"
      },
      "data_pipeline": {
        "status": "no dataset provided"
      }
    },
    "framework_specific": {
      "version": "2.19.0",
      "built_with_cuda": true,
      "gpu_available": true,
      "eager_execution": true
    }
  },
  {
    "timestamp": "2025-05-05T16:38:57.344711",
    "gpu": {
      "utilization": {
        "0": 62
      },
      "memory": {
        "0": {
          "used_mb": 9877,
          "total_mb": 10240,
          "percentage": 96.455078125
        }
      },
      "temperature": {
        "0": 47
      },
      "power": {
        "0": {
          "draw_watts": 157.82,
          "limit_watts": 370.0,
          "percentage": 42.65405405405405
        }
      },
      "clock_speeds": {
        "0": {
          "graphics_mhz": 1965,
          "memory_mhz": 9251
        }
      },
      "pcie_throughput": {
        "0": {
          "link_gen": "4",
          "link_width": "8",
          "max_bandwidth_GBps": 15.76,
          "mem_controller_util": 1.3333333333333333,
          "estimated_usage_GBps": 0.2101333333333333
        }
      },
      "idle_time": 54.11464476585388,
      "is_currently_idle": false
    },
    "cpu": {
      "utilization": {
        "overall": 2.5,
        "per_core": [
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          9.1,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0
        ],
        "logical_cores": 20,
        "physical_cores": 14
      },
      "unused_cores": {
        "unused_core_count": 19,
        "unused_core_indices": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19
        ],
        "threshold": 10
      },
      "memory": {
        "total_gb": 31.13628387451172,
        "used_gb": 24.250106811523438,
        "available_gb": 5.768852233886719,
        "percent_used": 81.5,
        "swap_total_gb": 0.9540977478027344,
        "swap_used_gb": 0.00146484375,
        "swap_percent": 0.2
      }
    },
    "latency": {
      "inference": {
        "batch_size": 1,
        "num_runs": 10,
        "avg_latency_ms": 21.059608459472656,
        "throughput_samples_per_sec": 47.48426362837709
      },
      "training_step": {
        "error": "in user code:\n\n    File \"/home/p0wden/Downloads/mloptimizer/app/common/GpuMetrics.py\", line 588, in train_step  *\n        loss = model.loss(y, y_pred)\n\n    TypeError: 'str' object is not callable\n"
      },
      "data_pipeline": {
        "status": "no dataset provided"
      }
    },
    "framework_specific": {
      "version": "2.19.0",
      "built_with_cuda": true,
      "gpu_available": true,
      "eager_execution": true
    }
  },
  {
    "timestamp": "2025-05-05T16:39:00.154792",
    "gpu": {
      "utilization": {
        "0": 3
      },
      "memory": {
        "0": {
          "used_mb": 9875,
          "total_mb": 10240,
          "percentage": 96.435546875
        }
      },
      "temperature": {
        "0": 45
      },
      "power": {
        "0": {
          "draw_watts": 123.7,
          "limit_watts": 370.0,
          "percentage": 33.432432432432435
        }
      },
      "clock_speeds": {
        "0": {
          "graphics_mhz": 1905,
          "memory_mhz": 9251
        }
      },
      "pcie_throughput": {
        "0": {
          "link_gen": "4",
          "link_width": "8",
          "max_bandwidth_GBps": 15.76,
          "mem_controller_util": 2.0,
          "estimated_usage_GBps": 0.3152
        }
      },
      "idle_time": 0,
      "is_currently_idle": true
    },
    "cpu": {
      "utilization": {
        "overall": 22.1,
        "per_core": [
          9.1,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          18.2,
          0.0,
          0.0,
          0.0,
          10.0,
          0.0,
          0.0,
          0.0,
          0.0,
          9.1,
          0.0,
          0.0,
          0.0,
          10.0
        ],
        "logical_cores": 20,
        "physical_cores": 14
      },
      "unused_cores": {
        "unused_core_count": 18,
        "unused_core_indices": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          9,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19
        ],
        "threshold": 10
      },
      "memory": {
        "total_gb": 31.13628387451172,
        "used_gb": 24.227523803710938,
        "available_gb": 5.786899566650391,
        "percent_used": 81.4,
        "swap_total_gb": 0.9540977478027344,
        "swap_used_gb": 0.00146484375,
        "swap_percent": 0.2
      }
    },
    "latency": {
      "inference": {
        "batch_size": 1,
        "num_runs": 10,
        "avg_latency_ms": 21.194911003112793,
        "throughput_samples_per_sec": 47.18113701223538
      },
      "training_step": {
        "error": "in user code:\n\n    File \"/home/p0wden/Downloads/mloptimizer/app/common/GpuMetrics.py\", line 588, in train_step  *\n        loss = model.loss(y, y_pred)\n\n    TypeError: 'str' object is not callable\n"
      },
      "data_pipeline": {
        "status": "no dataset provided"
      }
    },
    "framework_specific": {
      "version": "2.19.0",
      "built_with_cuda": true,
      "gpu_available": true,
      "eager_execution": true
    }
  },
  {
    "timestamp": "2025-05-05T16:39:49.750043",
    "gpu": {
      "utilization": {
        "0": 17
      },
      "memory": {
        "0": {
          "used_mb": 9871,
          "total_mb": 10240,
          "percentage": 96.396484375
        }
      },
      "temperature": {
        "0": 46
      },
      "power": {
        "0": {
          "draw_watts": 151.85,
          "limit_watts": 370.0,
          "percentage": 41.04054054054054
        }
      },
      "clock_speeds": {
        "0": {
          "graphics_mhz": 1965,
          "memory_mhz": 9251
        }
      },
      "pcie_throughput": {
        "0": {
          "link_gen": "4",
          "link_width": "8",
          "max_bandwidth_GBps": 15.76,
          "mem_controller_util": 1.3333333333333333,
          "estimated_usage_GBps": 0.2101333333333333
        }
      },
      "idle_time": 49.595438957214355,
      "is_currently_idle": false
    },
    "cpu": {
      "utilization": {
        "overall": 2.0,
        "per_core": [
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          18.2,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          9.1,
          0.0
        ],
        "logical_cores": 20,
        "physical_cores": 14
      },
      "unused_cores": {
        "unused_core_count": 18,
        "unused_core_indices": [
          0,
          1,
          2,
          3,
          5,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19
        ],
        "threshold": 10
      },
      "memory": {
        "total_gb": 31.13628387451172,
        "used_gb": 24.61069107055664,
        "available_gb": 5.398567199707031,
        "percent_used": 82.7,
        "swap_total_gb": 0.9540977478027344,
        "swap_used_gb": 0.00146484375,
        "swap_percent": 0.2
      }
    },
    "latency": {
      "inference": {
        "batch_size": 1,
        "num_runs": 10,
        "avg_latency_ms": 20.875906944274902,
        "throughput_samples_per_sec": 47.902110440966695
      },
      "training_step": {
        "error": "in user code:\n\n    File \"/home/p0wden/Downloads/mloptimizer/app/common/GpuMetrics.py\", line 588, in train_step  *\n        loss = model.loss(y, y_pred)\n\n    TypeError: 'str' object is not callable\n"
      },
      "data_pipeline": {
        "status": "no dataset provided"
      }
    },
    "framework_specific": {
      "version": "2.19.0",
      "built_with_cuda": true,
      "gpu_available": true,
      "eager_execution": true
    }
  },
  {
    "timestamp": "2025-05-05T16:39:52.556697",
    "gpu": {
      "utilization": {
        "0": 1
      },
      "memory": {
        "0": {
          "used_mb": 9867,
          "total_mb": 10240,
          "percentage": 96.357421875
        }
      },
      "temperature": {
        "0": 46
      },
      "power": {
        "0": {
          "draw_watts": 135.04,
          "limit_watts": 370.0,
          "percentage": 36.497297297297294
        }
      },
      "clock_speeds": {
        "0": {
          "graphics_mhz": 1965,
          "memory_mhz": 9251
        }
      },
      "pcie_throughput": {
        "0": {
          "link_gen": "4",
          "link_width": "8",
          "max_bandwidth_GBps": 15.76,
          "mem_controller_util": 1.0,
          "estimated_usage_GBps": 0.1576
        }
      },
      "idle_time": 0,
      "is_currently_idle": true
    },
    "cpu": {
      "utilization": {
        "overall": 2.0,
        "per_core": [
          0.0,
          0.0,
          16.7,
          0.0,
          0.0,
          0.0,
          10.0,
          0.0,
          0.0,
          0.0,
          9.1,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0
        ],
        "logical_cores": 20,
        "physical_cores": 14
      },
      "unused_cores": {
        "unused_core_count": 20,
        "unused_core_indices": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19
        ],
        "threshold": 10
      },
      "memory": {
        "total_gb": 31.13628387451172,
        "used_gb": 24.61175537109375,
        "available_gb": 5.399959564208984,
        "percent_used": 82.7,
        "swap_total_gb": 0.9540977478027344,
        "swap_used_gb": 0.00146484375,
        "swap_percent": 0.2
      }
    },
    "latency": {
      "inference": {
        "batch_size": 1,
        "num_runs": 10,
        "avg_latency_ms": 23.77758026123047,
        "throughput_samples_per_sec": 42.05642411942597
      },
      "training_step": {
        "error": "in user code:\n\n    File \"/home/p0wden/Downloads/mloptimizer/app/common/GpuMetrics.py\", line 588, in train_step  *\n        loss = model.loss(y, y_pred)\n\n    TypeError: 'str' object is not callable\n"
      },
      "data_pipeline": {
        "status": "no dataset provided"
      }
    },
    "framework_specific": {
      "version": "2.19.0",
      "built_with_cuda": true,
      "gpu_available": true,
      "eager_execution": true
    }
  },
  {
    "timestamp": "2025-05-05T16:40:38.161934",
    "gpu": {
      "utilization": {
        "0": 4
      },
      "memory": {
        "0": {
          "used_mb": 9855,
          "total_mb": 10240,
          "percentage": 96.240234375
        }
      },
      "temperature": {
        "0": 46
      },
      "power": {
        "0": {
          "draw_watts": 149.99,
          "limit_watts": 370.0,
          "percentage": 40.53783783783784
        }
      },
      "clock_speeds": {
        "0": {
          "graphics_mhz": 1965,
          "memory_mhz": 9251
        }
      },
      "pcie_throughput": {
        "0": {
          "link_gen": "4",
          "link_width": "8",
          "max_bandwidth_GBps": 15.76,
          "mem_controller_util": 1.0,
          "estimated_usage_GBps": 0.1576
        }
      },
      "idle_time": 45.604820251464844,
      "is_currently_idle": true
    },
    "cpu": {
      "utilization": {
        "overall": 1.0,
        "per_core": [
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          9.1,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0
        ],
        "logical_cores": 20,
        "physical_cores": 14
      },
      "unused_cores": {
        "unused_core_count": 18,
        "unused_core_indices": [
          0,
          1,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19
        ],
        "threshold": 10
      },
      "memory": {
        "total_gb": 31.13628387451172,
        "used_gb": 24.844444274902344,
        "available_gb": 5.162654876708984,
        "percent_used": 83.4,
        "swap_total_gb": 0.9540977478027344,
        "swap_used_gb": 0.00146484375,
        "swap_percent": 0.2
      }
    },
    "latency": {
      "inference": {
        "batch_size": 1,
        "num_runs": 10,
        "avg_latency_ms": 21.519923210144043,
        "throughput_samples_per_sec": 46.468567300863825
      },
      "training_step": {
        "error": "in user code:\n\n    File \"/home/p0wden/Downloads/mloptimizer/app/common/GpuMetrics.py\", line 588, in train_step  *\n        loss = model.loss(y, y_pred)\n\n    TypeError: 'str' object is not callable\n"
      },
      "data_pipeline": {
        "status": "no dataset provided"
      }
    },
    "framework_specific": {
      "version": "2.19.0",
      "built_with_cuda": true,
      "gpu_available": true,
      "eager_execution": true
    }
  },
  {
    "timestamp": "2025-05-05T16:40:40.978043",
    "gpu": {
      "utilization": {
        "0": 6
      },
      "memory": {
        "0": {
          "used_mb": 9836,
          "total_mb": 10240,
          "percentage": 96.0546875
        }
      },
      "temperature": {
        "0": 45
      },
      "power": {
        "0": {
          "draw_watts": 120.45,
          "limit_watts": 370.0,
          "percentage": 32.554054054054056
        }
      },
      "clock_speeds": {
        "0": {
          "graphics_mhz": 1905,
          "memory_mhz": 9251
        }
      },
      "pcie_throughput": {
        "0": {
          "link_gen": "4",
          "link_width": "8",
          "max_bandwidth_GBps": 15.76,
          "mem_controller_util": 1.6666666666666667,
          "estimated_usage_GBps": 0.26266666666666666
        }
      },
      "idle_time": 48.42084789276123,
      "is_currently_idle": false
    },
    "cpu": {
      "utilization": {
        "overall": 7.8,
        "per_core": [
          0.0,
          0.0,
          10.0,
          0.0,
          0.0,
          0.0,
          10.0,
          0.0,
          12.5,
          0.0,
          20.0,
          0.0,
          10.0,
          0.0,
          18.2,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0
        ],
        "logical_cores": 20,
        "physical_cores": 14
      },
      "unused_cores": {
        "unused_core_count": 14,
        "unused_core_indices": [
          0,
          1,
          3,
          5,
          7,
          8,
          9,
          11,
          13,
          14,
          15,
          16,
          17,
          19
        ],
        "threshold": 10
      },
      "memory": {
        "total_gb": 31.13628387451172,
        "used_gb": 24.858287811279297,
        "available_gb": 5.162483215332031,
        "percent_used": 83.4,
        "swap_total_gb": 0.9540977478027344,
        "swap_used_gb": 0.00146484375,
        "swap_percent": 0.2
      }
    },
    "latency": {
      "inference": {
        "batch_size": 1,
        "num_runs": 10,
        "avg_latency_ms": 23.39639663696289,
        "throughput_samples_per_sec": 42.741624512389485
      },
      "training_step": {
        "error": "in user code:\n\n    File \"/home/p0wden/Downloads/mloptimizer/app/common/GpuMetrics.py\", line 588, in train_step  *\n        loss = model.loss(y, y_pred)\n\n    TypeError: 'str' object is not callable\n"
      },
      "data_pipeline": {
        "status": "no dataset provided"
      }
    },
    "framework_specific": {
      "version": "2.19.0",
      "built_with_cuda": true,
      "gpu_available": true,
      "eager_execution": true
    }
  },
  {
    "timestamp": "2025-05-05T16:41:31.099532",
    "gpu": {
      "utilization": {
        "0": 25
      },
      "memory": {
        "0": {
          "used_mb": 9872,
          "total_mb": 10240,
          "percentage": 96.40625
        }
      },
      "temperature": {
        "0": 46
      },
      "power": {
        "0": {
          "draw_watts": 150.05,
          "limit_watts": 370.0,
          "percentage": 40.554054054054056
        }
      },
      "clock_speeds": {
        "0": {
          "graphics_mhz": 1965,
          "memory_mhz": 9251
        }
      },
      "pcie_throughput": {
        "0": {
          "link_gen": "4",
          "link_width": "8",
          "max_bandwidth_GBps": 15.76,
          "mem_controller_util": 1.6666666666666667,
          "estimated_usage_GBps": 0.26266666666666666
        }
      },
      "idle_time": 0,
      "is_currently_idle": false
    },
    "cpu": {
      "utilization": {
        "overall": 2.5,
        "per_core": [
          10.0,
          0.0,
          10.0,
          0.0,
          10.0,
          0.0,
          10.0,
          0.0,
          0.0,
          0.0,
          9.1,
          0.0,
          0.0,
          0.0,
          10.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0
        ],
        "logical_cores": 20,
        "physical_cores": 14
      },
      "unused_cores": {
        "unused_core_count": 19,
        "unused_core_indices": [
          0,
          1,
          2,
          3,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19
        ],
        "threshold": 10
      },
      "memory": {
        "total_gb": 31.13628387451172,
        "used_gb": 25.14563751220703,
        "available_gb": 4.877525329589844,
        "percent_used": 84.3,
        "swap_total_gb": 0.9540977478027344,
        "swap_used_gb": 0.00146484375,
        "swap_percent": 0.2
      }
    },
    "latency": {
      "inference": {
        "batch_size": 1,
        "num_runs": 10,
        "avg_latency_ms": 23.362112045288086,
        "throughput_samples_per_sec": 42.80434911284874
      },
      "training_step": {
        "error": "in user code:\n\n    File \"/home/p0wden/Downloads/mloptimizer/app/common/GpuMetrics.py\", line 588, in train_step  *\n        loss = model.loss(y, y_pred)\n\n    TypeError: 'str' object is not callable\n"
      },
      "data_pipeline": {
        "status": "no dataset provided"
      }
    },
    "framework_specific": {
      "version": "2.19.0",
      "built_with_cuda": true,
      "gpu_available": true,
      "eager_execution": true
    }
  },
  {
    "timestamp": "2025-05-05T16:41:34.159611",
    "gpu": {
      "utilization": {
        "0": 58
      },
      "memory": {
        "0": {
          "used_mb": 9900,
          "total_mb": 10240,
          "percentage": 96.6796875
        }
      },
      "temperature": {
        "0": 46
      },
      "power": {
        "0": {
          "draw_watts": 140.27,
          "limit_watts": 370.0,
          "percentage": 37.910810810810815
        }
      },
      "clock_speeds": {
        "0": {
          "graphics_mhz": 1965,
          "memory_mhz": 9251
        }
      },
      "pcie_throughput": {
        "0": {
          "link_gen": "4",
          "link_width": "8",
          "max_bandwidth_GBps": 15.76,
          "mem_controller_util": 1.6666666666666667,
          "estimated_usage_GBps": 0.26266666666666666
        }
      },
      "idle_time": 0,
      "is_currently_idle": false
    },
    "cpu": {
      "utilization": {
        "overall": 1.0,
        "per_core": [
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          18.2,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0
        ],
        "logical_cores": 20,
        "physical_cores": 14
      },
      "unused_cores": {
        "unused_core_count": 20,
        "unused_core_indices": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19
        ],
        "threshold": 10
      },
      "memory": {
        "total_gb": 31.13628387451172,
        "used_gb": 25.14617919921875,
        "available_gb": 4.879962921142578,
        "percent_used": 84.3,
        "swap_total_gb": 0.9540977478027344,
        "swap_used_gb": 0.00146484375,
        "swap_percent": 0.2
      }
    },
    "latency": {
      "inference": {
        "batch_size": 1,
        "num_runs": 10,
        "avg_latency_ms": 21.43683433532715,
        "throughput_samples_per_sec": 46.648678828106405
      },
      "training_step": {
        "error": "in user code:\n\n    File \"/home/p0wden/Downloads/mloptimizer/app/common/GpuMetrics.py\", line 588, in train_step  *\n        loss = model.loss(y, y_pred)\n\n    TypeError: 'str' object is not callable\n"
      },
      "data_pipeline": {
        "status": "no dataset provided"
      }
    },
    "framework_specific": {
      "version": "2.19.0",
      "built_with_cuda": true,
      "gpu_available": true,
      "eager_execution": true
    }
  },
  {
    "timestamp": "2025-05-05T16:42:22.917011",
    "gpu": {
      "utilization": {
        "0": 10
      },
      "memory": {
        "0": {
          "used_mb": 9883,
          "total_mb": 10240,
          "percentage": 96.513671875
        }
      },
      "temperature": {
        "0": 46
      },
      "power": {
        "0": {
          "draw_watts": 149.2,
          "limit_watts": 370.0,
          "percentage": 40.32432432432432
        }
      },
      "clock_speeds": {
        "0": {
          "graphics_mhz": 1965,
          "memory_mhz": 9251
        }
      },
      "pcie_throughput": {
        "0": {
          "link_gen": "4",
          "link_width": "8",
          "max_bandwidth_GBps": 15.76,
          "mem_controller_util": 0.6666666666666666,
          "estimated_usage_GBps": 0.10506666666666666
        }
      },
      "idle_time": 0,
      "is_currently_idle": false
    },
    "cpu": {
      "utilization": {
        "overall": 6.5,
        "per_core": [
          16.7,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          90.0,
          0.0,
          20.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          9.1,
          0.0
        ],
        "logical_cores": 20,
        "physical_cores": 14
      },
      "unused_cores": {
        "unused_core_count": 16,
        "unused_core_indices": [
          0,
          1,
          2,
          3,
          5,
          6,
          7,
          9,
          11,
          13,
          14,
          15,
          16,
          17,
          18,
          19
        ],
        "threshold": 10
      },
      "memory": {
        "total_gb": 31.13628387451172,
        "used_gb": 25.413570404052734,
        "available_gb": 4.611232757568359,
        "percent_used": 85.2,
        "swap_total_gb": 0.9540977478027344,
        "swap_used_gb": 0.00146484375,
        "swap_percent": 0.2
      }
    },
    "latency": {
      "inference": {
        "batch_size": 1,
        "num_runs": 10,
        "avg_latency_ms": 20.708417892456055,
        "throughput_samples_per_sec": 48.28954124806867
      },
      "training_step": {
        "error": "in user code:\n\n    File \"/home/p0wden/Downloads/mloptimizer/app/common/GpuMetrics.py\", line 588, in train_step  *\n        loss = model.loss(y, y_pred)\n\n    TypeError: 'str' object is not callable\n"
      },
      "data_pipeline": {
        "status": "no dataset provided"
      }
    },
    "framework_specific": {
      "version": "2.19.0",
      "built_with_cuda": true,
      "gpu_available": true,
      "eager_execution": true
    }
  }
]