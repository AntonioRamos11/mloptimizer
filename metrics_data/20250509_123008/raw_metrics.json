[
  {
    "timestamp": "2025-05-09T12:24:59.577326",
    "gpu": {
      "utilization": {
        "0": 5
      },
      "memory": {
        "0": {
          "used_mb": 9851,
          "total_mb": 10240,
          "percentage": 96.201171875
        }
      },
      "temperature": {
        "0": 44
      },
      "power": {
        "0": {
          "draw_watts": 119.75,
          "limit_watts": 370.0,
          "percentage": 32.36486486486487
        }
      },
      "clock_speeds": {
        "0": {
          "graphics_mhz": 1905,
          "memory_mhz": 9251
        }
      },
      "pcie_throughput": {
        "0": {
          "link_gen": "4",
          "link_width": "8",
          "max_bandwidth_GBps": 15.76,
          "mem_controller_util": 1.0,
          "estimated_usage_GBps": 0.1576
        }
      },
      "idle_time": 0,
      "is_currently_idle": false
    },
    "cpu": {
      "utilization": {
        "overall": 0.5,
        "per_core": [
          0.0,
          0.0,
          9.1,
          0.0,
          0.0,
          0.0,
          20.0,
          0.0,
          9.1,
          0.0,
          0.0,
          0.0,
          9.1,
          0.0,
          9.1,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0
        ],
        "logical_cores": 20,
        "physical_cores": 14
      },
      "unused_cores": {
        "unused_core_count": 20,
        "unused_core_indices": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19
        ],
        "threshold": 10
      },
      "memory": {
        "total_gb": 31.13628387451172,
        "used_gb": 23.531940460205078,
        "available_gb": 7.027873992919922,
        "percent_used": 77.4,
        "swap_total_gb": 0.9540977478027344,
        "swap_used_gb": 0.0,
        "swap_percent": 0.0
      }
    },
    "latency": {
      "inference": {
        "batch_size": 1,
        "num_runs": 10,
        "avg_latency_ms": 19.25978660583496,
        "throughput_samples_per_sec": 51.92165523251639
      },
      "training_step": {
        "error": "in user code:\n\n    File \"/home/p0wden/Downloads/mloptimizer/app/common/GpuMetrics.py\", line 588, in train_step  *\n        loss = model.loss(y, y_pred)\n\n    TypeError: 'str' object is not callable\n"
      },
      "data_pipeline": {
        "status": "no dataset provided"
      }
    },
    "framework_specific": {
      "version": "2.19.0",
      "built_with_cuda": true,
      "gpu_available": true,
      "eager_execution": true
    }
  },
  {
    "timestamp": "2025-05-09T12:25:40.929148",
    "gpu": {
      "utilization": {
        "0": 12
      },
      "memory": {
        "0": {
          "used_mb": 9835,
          "total_mb": 10240,
          "percentage": 96.044921875
        }
      },
      "temperature": {
        "0": 44
      },
      "power": {
        "0": {
          "draw_watts": 143.2,
          "limit_watts": 370.0,
          "percentage": 38.7027027027027
        }
      },
      "clock_speeds": {
        "0": {
          "graphics_mhz": 1965,
          "memory_mhz": 9251
        }
      },
      "pcie_throughput": {
        "0": {
          "link_gen": "4",
          "link_width": "8",
          "max_bandwidth_GBps": 15.76,
          "mem_controller_util": 0.6666666666666666,
          "estimated_usage_GBps": 0.10506666666666666
        }
      },
      "idle_time": 0,
      "is_currently_idle": false
    },
    "cpu": {
      "utilization": {
        "overall": 0.0,
        "per_core": [
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          9.1,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0
        ],
        "logical_cores": 20,
        "physical_cores": 14
      },
      "unused_cores": {
        "unused_core_count": 20,
        "unused_core_indices": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19
        ],
        "threshold": 10
      },
      "memory": {
        "total_gb": 31.13628387451172,
        "used_gb": 23.77658462524414,
        "available_gb": 6.772434234619141,
        "percent_used": 78.2,
        "swap_total_gb": 0.9540977478027344,
        "swap_used_gb": 0.0,
        "swap_percent": 0.0
      }
    },
    "latency": {
      "inference": {
        "batch_size": 1,
        "num_runs": 10,
        "avg_latency_ms": 19.558143615722656,
        "throughput_samples_per_sec": 51.12959694171112
      },
      "training_step": {
        "error": "in user code:\n\n    File \"/home/p0wden/Downloads/mloptimizer/app/common/GpuMetrics.py\", line 588, in train_step  *\n        loss = model.loss(y, y_pred)\n\n    TypeError: 'str' object is not callable\n"
      },
      "data_pipeline": {
        "status": "no dataset provided"
      }
    },
    "framework_specific": {
      "version": "2.19.0",
      "built_with_cuda": true,
      "gpu_available": true,
      "eager_execution": true
    }
  },
  {
    "timestamp": "2025-05-09T12:25:43.695163",
    "gpu": {
      "utilization": {
        "0": 1
      },
      "memory": {
        "0": {
          "used_mb": 9851,
          "total_mb": 10240,
          "percentage": 96.201171875
        }
      },
      "temperature": {
        "0": 44
      },
      "power": {
        "0": {
          "draw_watts": 118.68,
          "limit_watts": 370.0,
          "percentage": 32.07567567567568
        }
      },
      "clock_speeds": {
        "0": {
          "graphics_mhz": 1905,
          "memory_mhz": 9251
        }
      },
      "pcie_throughput": {
        "0": {
          "link_gen": "4",
          "link_width": "8",
          "max_bandwidth_GBps": 15.76,
          "mem_controller_util": 1.0,
          "estimated_usage_GBps": 0.1576
        }
      },
      "idle_time": 0,
      "is_currently_idle": true
    },
    "cpu": {
      "utilization": {
        "overall": 3.0,
        "per_core": [
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0
        ],
        "logical_cores": 20,
        "physical_cores": 14
      },
      "unused_cores": {
        "unused_core_count": 20,
        "unused_core_indices": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19
        ],
        "threshold": 10
      },
      "memory": {
        "total_gb": 31.13628387451172,
        "used_gb": 23.7957763671875,
        "available_gb": 6.755950927734375,
        "percent_used": 78.3,
        "swap_total_gb": 0.9540977478027344,
        "swap_used_gb": 0.0,
        "swap_percent": 0.0
      }
    },
    "latency": {
      "inference": {
        "batch_size": 1,
        "num_runs": 10,
        "avg_latency_ms": 19.36783790588379,
        "throughput_samples_per_sec": 51.63198932474586
      },
      "training_step": {
        "error": "in user code:\n\n    File \"/home/p0wden/Downloads/mloptimizer/app/common/GpuMetrics.py\", line 588, in train_step  *\n        loss = model.loss(y, y_pred)\n\n    TypeError: 'str' object is not callable\n"
      },
      "data_pipeline": {
        "status": "no dataset provided"
      }
    },
    "framework_specific": {
      "version": "2.19.0",
      "built_with_cuda": true,
      "gpu_available": true,
      "eager_execution": true
    }
  },
  {
    "timestamp": "2025-05-09T12:26:25.299704",
    "gpu": {
      "utilization": {
        "0": 8
      },
      "memory": {
        "0": {
          "used_mb": 9833,
          "total_mb": 10240,
          "percentage": 96.025390625
        }
      },
      "temperature": {
        "0": 45
      },
      "power": {
        "0": {
          "draw_watts": 143.38,
          "limit_watts": 370.0,
          "percentage": 38.751351351351346
        }
      },
      "clock_speeds": {
        "0": {
          "graphics_mhz": 1965,
          "memory_mhz": 9251
        }
      },
      "pcie_throughput": {
        "0": {
          "link_gen": "4",
          "link_width": "8",
          "max_bandwidth_GBps": 15.76,
          "mem_controller_util": 1.0,
          "estimated_usage_GBps": 0.1576
        }
      },
      "idle_time": 41.60470008850098,
      "is_currently_idle": false
    },
    "cpu": {
      "utilization": {
        "overall": 0.5,
        "per_core": [
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0
        ],
        "logical_cores": 20,
        "physical_cores": 14
      },
      "unused_cores": {
        "unused_core_count": 20,
        "unused_core_indices": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19
        ],
        "threshold": 10
      },
      "memory": {
        "total_gb": 31.13628387451172,
        "used_gb": 24.087722778320312,
        "available_gb": 6.464286804199219,
        "percent_used": 79.2,
        "swap_total_gb": 0.9540977478027344,
        "swap_used_gb": 0.0,
        "swap_percent": 0.0
      }
    },
    "latency": {
      "inference": {
        "batch_size": 1,
        "num_runs": 10,
        "avg_latency_ms": 19.629597663879395,
        "throughput_samples_per_sec": 50.943479185011995
      },
      "training_step": {
        "error": "in user code:\n\n    File \"/home/p0wden/Downloads/mloptimizer/app/common/GpuMetrics.py\", line 588, in train_step  *\n        loss = model.loss(y, y_pred)\n\n    TypeError: 'str' object is not callable\n"
      },
      "data_pipeline": {
        "status": "no dataset provided"
      }
    },
    "framework_specific": {
      "version": "2.19.0",
      "built_with_cuda": true,
      "gpu_available": true,
      "eager_execution": true
    }
  },
  {
    "timestamp": "2025-05-09T12:26:28.063785",
    "gpu": {
      "utilization": {
        "0": 1
      },
      "memory": {
        "0": {
          "used_mb": 9833,
          "total_mb": 10240,
          "percentage": 96.025390625
        }
      },
      "temperature": {
        "0": 44
      },
      "power": {
        "0": {
          "draw_watts": 118.62,
          "limit_watts": 370.0,
          "percentage": 32.05945945945946
        }
      },
      "clock_speeds": {
        "0": {
          "graphics_mhz": 1905,
          "memory_mhz": 9251
        }
      },
      "pcie_throughput": {
        "0": {
          "link_gen": "4",
          "link_width": "8",
          "max_bandwidth_GBps": 15.76,
          "mem_controller_util": 1.0,
          "estimated_usage_GBps": 0.1576
        }
      },
      "idle_time": 0,
      "is_currently_idle": true
    },
    "cpu": {
      "utilization": {
        "overall": 0.0,
        "per_core": [
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0
        ],
        "logical_cores": 20,
        "physical_cores": 14
      },
      "unused_cores": {
        "unused_core_count": 18,
        "unused_core_indices": [
          0,
          1,
          2,
          3,
          5,
          6,
          7,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19
        ],
        "threshold": 10
      },
      "memory": {
        "total_gb": 31.13628387451172,
        "used_gb": 24.104698181152344,
        "available_gb": 6.4443206787109375,
        "percent_used": 79.3,
        "swap_total_gb": 0.9540977478027344,
        "swap_used_gb": 0.0,
        "swap_percent": 0.0
      }
    },
    "latency": {
      "inference": {
        "batch_size": 1,
        "num_runs": 10,
        "avg_latency_ms": 19.870400428771973,
        "throughput_samples_per_sec": 50.32611212766596
      },
      "training_step": {
        "error": "in user code:\n\n    File \"/home/p0wden/Downloads/mloptimizer/app/common/GpuMetrics.py\", line 588, in train_step  *\n        loss = model.loss(y, y_pred)\n\n    TypeError: 'str' object is not callable\n"
      },
      "data_pipeline": {
        "status": "no dataset provided"
      }
    },
    "framework_specific": {
      "version": "2.19.0",
      "built_with_cuda": true,
      "gpu_available": true,
      "eager_execution": true
    }
  },
  {
    "timestamp": "2025-05-09T12:27:10.851866",
    "gpu": {
      "utilization": {
        "0": 3
      },
      "memory": {
        "0": {
          "used_mb": 9966,
          "total_mb": 10240,
          "percentage": 97.32421875
        }
      },
      "temperature": {
        "0": 45
      },
      "power": {
        "0": {
          "draw_watts": 141.37,
          "limit_watts": 370.0,
          "percentage": 38.20810810810811
        }
      },
      "clock_speeds": {
        "0": {
          "graphics_mhz": 1965,
          "memory_mhz": 9251
        }
      },
      "pcie_throughput": {
        "0": {
          "link_gen": "4",
          "link_width": "8",
          "max_bandwidth_GBps": 15.76,
          "mem_controller_util": 0.0,
          "estimated_usage_GBps": 0.0
        }
      },
      "idle_time": 42.788235664367676,
      "is_currently_idle": true
    },
    "cpu": {
      "utilization": {
        "overall": 0.5,
        "per_core": [
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0
        ],
        "logical_cores": 20,
        "physical_cores": 14
      },
      "unused_cores": {
        "unused_core_count": 20,
        "unused_core_indices": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19
        ],
        "threshold": 10
      },
      "memory": {
        "total_gb": 31.13628387451172,
        "used_gb": 24.346752166748047,
        "available_gb": 6.2052459716796875,
        "percent_used": 80.1,
        "swap_total_gb": 0.9540977478027344,
        "swap_used_gb": 0.0,
        "swap_percent": 0.0
      }
    },
    "latency": {
      "inference": {
        "batch_size": 1,
        "num_runs": 10,
        "avg_latency_ms": 18.957114219665527,
        "throughput_samples_per_sec": 52.75064487202545
      },
      "training_step": {
        "error": "in user code:\n\n    File \"/home/p0wden/Downloads/mloptimizer/app/common/GpuMetrics.py\", line 588, in train_step  *\n        loss = model.loss(y, y_pred)\n\n    TypeError: 'str' object is not callable\n"
      },
      "data_pipeline": {
        "status": "no dataset provided"
      }
    },
    "framework_specific": {
      "version": "2.19.0",
      "built_with_cuda": true,
      "gpu_available": true,
      "eager_execution": true
    }
  },
  {
    "timestamp": "2025-05-09T12:27:13.607626",
    "gpu": {
      "utilization": {
        "0": 2
      },
      "memory": {
        "0": {
          "used_mb": 9966,
          "total_mb": 10240,
          "percentage": 97.32421875
        }
      },
      "temperature": {
        "0": 43
      },
      "power": {
        "0": {
          "draw_watts": 116.52,
          "limit_watts": 370.0,
          "percentage": 31.491891891891893
        }
      },
      "clock_speeds": {
        "0": {
          "graphics_mhz": 1905,
          "memory_mhz": 9251
        }
      },
      "pcie_throughput": {
        "0": {
          "link_gen": "4",
          "link_width": "8",
          "max_bandwidth_GBps": 15.76,
          "mem_controller_util": 0.0,
          "estimated_usage_GBps": 0.0
        }
      },
      "idle_time": 45.54401254653931,
      "is_currently_idle": true
    },
    "cpu": {
      "utilization": {
        "overall": 0.0,
        "per_core": [
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0
        ],
        "logical_cores": 20,
        "physical_cores": 14
      },
      "unused_cores": {
        "unused_core_count": 20,
        "unused_core_indices": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19
        ],
        "threshold": 10
      },
      "memory": {
        "total_gb": 31.13628387451172,
        "used_gb": 24.345077514648438,
        "available_gb": 6.222492218017578,
        "percent_used": 80.0,
        "swap_total_gb": 0.9540977478027344,
        "swap_used_gb": 0.0,
        "swap_percent": 0.0
      }
    },
    "latency": {
      "inference": {
        "batch_size": 1,
        "num_runs": 10,
        "avg_latency_ms": 18.95906925201416,
        "throughput_samples_per_sec": 52.74520530029515
      },
      "training_step": {
        "error": "in user code:\n\n    File \"/home/p0wden/Downloads/mloptimizer/app/common/GpuMetrics.py\", line 588, in train_step  *\n        loss = model.loss(y, y_pred)\n\n    TypeError: 'str' object is not callable\n"
      },
      "data_pipeline": {
        "status": "no dataset provided"
      }
    },
    "framework_specific": {
      "version": "2.19.0",
      "built_with_cuda": true,
      "gpu_available": true,
      "eager_execution": true
    }
  },
  {
    "timestamp": "2025-05-09T12:27:54.695852",
    "gpu": {
      "utilization": {
        "0": 12
      },
      "memory": {
        "0": {
          "used_mb": 9966,
          "total_mb": 10240,
          "percentage": 97.32421875
        }
      },
      "temperature": {
        "0": 45
      },
      "power": {
        "0": {
          "draw_watts": 140.55,
          "limit_watts": 370.0,
          "percentage": 37.986486486486484
        }
      },
      "clock_speeds": {
        "0": {
          "graphics_mhz": 1965,
          "memory_mhz": 9251
        }
      },
      "pcie_throughput": {
        "0": {
          "link_gen": "4",
          "link_width": "8",
          "max_bandwidth_GBps": 15.76,
          "mem_controller_util": 0.0,
          "estimated_usage_GBps": 0.0
        }
      },
      "idle_time": 86.63201189041138,
      "is_currently_idle": false
    },
    "cpu": {
      "utilization": {
        "overall": 0.0,
        "per_core": [
          0.0,
          0.0,
          0.0,
          0.0,
          9.1,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0
        ],
        "logical_cores": 20,
        "physical_cores": 14
      },
      "unused_cores": {
        "unused_core_count": 20,
        "unused_core_indices": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19
        ],
        "threshold": 10
      },
      "memory": {
        "total_gb": 31.13628387451172,
        "used_gb": 24.65018081665039,
        "available_gb": 5.925209045410156,
        "percent_used": 81.0,
        "swap_total_gb": 0.9540977478027344,
        "swap_used_gb": 0.0,
        "swap_percent": 0.0
      }
    },
    "latency": {
      "inference": {
        "batch_size": 1,
        "num_runs": 10,
        "avg_latency_ms": 19.27175521850586,
        "throughput_samples_per_sec": 51.88940958733961
      },
      "training_step": {
        "error": "in user code:\n\n    File \"/home/p0wden/Downloads/mloptimizer/app/common/GpuMetrics.py\", line 588, in train_step  *\n        loss = model.loss(y, y_pred)\n\n    TypeError: 'str' object is not callable\n"
      },
      "data_pipeline": {
        "status": "no dataset provided"
      }
    },
    "framework_specific": {
      "version": "2.19.0",
      "built_with_cuda": true,
      "gpu_available": true,
      "eager_execution": true
    }
  },
  {
    "timestamp": "2025-05-09T12:27:57.446853",
    "gpu": {
      "utilization": {
        "0": 1
      },
      "memory": {
        "0": {
          "used_mb": 9966,
          "total_mb": 10240,
          "percentage": 97.32421875
        }
      },
      "temperature": {
        "0": 44
      },
      "power": {
        "0": {
          "draw_watts": 116.14,
          "limit_watts": 370.0,
          "percentage": 31.38918918918919
        }
      },
      "clock_speeds": {
        "0": {
          "graphics_mhz": 1905,
          "memory_mhz": 9251
        }
      },
      "pcie_throughput": {
        "0": {
          "link_gen": "4",
          "link_width": "8",
          "max_bandwidth_GBps": 15.76,
          "mem_controller_util": 0.0,
          "estimated_usage_GBps": 0.0
        }
      },
      "idle_time": 0,
      "is_currently_idle": true
    },
    "cpu": {
      "utilization": {
        "overall": 0.0,
        "per_core": [
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          9.1,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0
        ],
        "logical_cores": 20,
        "physical_cores": 14
      },
      "unused_cores": {
        "unused_core_count": 20,
        "unused_core_indices": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19
        ],
        "threshold": 10
      },
      "memory": {
        "total_gb": 31.13628387451172,
        "used_gb": 24.64350128173828,
        "available_gb": 5.931896209716797,
        "percent_used": 80.9,
        "swap_total_gb": 0.9540977478027344,
        "swap_used_gb": 0.0,
        "swap_percent": 0.0
      }
    },
    "latency": {
      "inference": {
        "batch_size": 1,
        "num_runs": 10,
        "avg_latency_ms": 19.238924980163574,
        "throughput_samples_per_sec": 51.97795620238952
      },
      "training_step": {
        "error": "in user code:\n\n    File \"/home/p0wden/Downloads/mloptimizer/app/common/GpuMetrics.py\", line 588, in train_step  *\n        loss = model.loss(y, y_pred)\n\n    TypeError: 'str' object is not callable\n"
      },
      "data_pipeline": {
        "status": "no dataset provided"
      }
    },
    "framework_specific": {
      "version": "2.19.0",
      "built_with_cuda": true,
      "gpu_available": true,
      "eager_execution": true
    }
  },
  {
    "timestamp": "2025-05-09T12:28:38.497357",
    "gpu": {
      "utilization": {
        "0": 15
      },
      "memory": {
        "0": {
          "used_mb": 9966,
          "total_mb": 10240,
          "percentage": 97.32421875
        }
      },
      "temperature": {
        "0": 44
      },
      "power": {
        "0": {
          "draw_watts": 141.88,
          "limit_watts": 370.0,
          "percentage": 38.34594594594595
        }
      },
      "clock_speeds": {
        "0": {
          "graphics_mhz": 1965,
          "memory_mhz": 9251
        }
      },
      "pcie_throughput": {
        "0": {
          "link_gen": "4",
          "link_width": "8",
          "max_bandwidth_GBps": 15.76,
          "mem_controller_util": 0.0,
          "estimated_usage_GBps": 0.0
        }
      },
      "idle_time": 41.05046248435974,
      "is_currently_idle": false
    },
    "cpu": {
      "utilization": {
        "overall": 0.5,
        "per_core": [
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          8.3,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0
        ],
        "logical_cores": 20,
        "physical_cores": 14
      },
      "unused_cores": {
        "unused_core_count": 20,
        "unused_core_indices": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19
        ],
        "threshold": 10
      },
      "memory": {
        "total_gb": 31.13628387451172,
        "used_gb": 24.939186096191406,
        "available_gb": 5.636211395263672,
        "percent_used": 81.9,
        "swap_total_gb": 0.9540977478027344,
        "swap_used_gb": 0.0,
        "swap_percent": 0.0
      }
    },
    "latency": {
      "inference": {
        "batch_size": 1,
        "num_runs": 10,
        "avg_latency_ms": 19.327902793884277,
        "throughput_samples_per_sec": 51.73867080480244
      },
      "training_step": {
        "error": "in user code:\n\n    File \"/home/p0wden/Downloads/mloptimizer/app/common/GpuMetrics.py\", line 588, in train_step  *\n        loss = model.loss(y, y_pred)\n\n    TypeError: 'str' object is not callable\n"
      },
      "data_pipeline": {
        "status": "no dataset provided"
      }
    },
    "framework_specific": {
      "version": "2.19.0",
      "built_with_cuda": true,
      "gpu_available": true,
      "eager_execution": true
    }
  },
  {
    "timestamp": "2025-05-09T12:28:41.252542",
    "gpu": {
      "utilization": {
        "0": 2
      },
      "memory": {
        "0": {
          "used_mb": 9966,
          "total_mb": 10240,
          "percentage": 97.32421875
        }
      },
      "temperature": {
        "0": 43
      },
      "power": {
        "0": {
          "draw_watts": 120.64,
          "limit_watts": 370.0,
          "percentage": 32.605405405405406
        }
      },
      "clock_speeds": {
        "0": {
          "graphics_mhz": 1905,
          "memory_mhz": 9251
        }
      },
      "pcie_throughput": {
        "0": {
          "link_gen": "4",
          "link_width": "8",
          "max_bandwidth_GBps": 15.76,
          "mem_controller_util": 0.0,
          "estimated_usage_GBps": 0.0
        }
      },
      "idle_time": 0,
      "is_currently_idle": true
    },
    "cpu": {
      "utilization": {
        "overall": 0.5,
        "per_core": [
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          9.1,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0
        ],
        "logical_cores": 20,
        "physical_cores": 14
      },
      "unused_cores": {
        "unused_core_count": 20,
        "unused_core_indices": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19
        ],
        "threshold": 10
      },
      "memory": {
        "total_gb": 31.13628387451172,
        "used_gb": 24.940105438232422,
        "available_gb": 5.635292053222656,
        "percent_used": 81.9,
        "swap_total_gb": 0.9540977478027344,
        "swap_used_gb": 0.0,
        "swap_percent": 0.0
      }
    },
    "latency": {
      "inference": {
        "batch_size": 1,
        "num_runs": 10,
        "avg_latency_ms": 19.212937355041504,
        "throughput_samples_per_sec": 52.04826214340404
      },
      "training_step": {
        "error": "in user code:\n\n    File \"/home/p0wden/Downloads/mloptimizer/app/common/GpuMetrics.py\", line 588, in train_step  *\n        loss = model.loss(y, y_pred)\n\n    TypeError: 'str' object is not callable\n"
      },
      "data_pipeline": {
        "status": "no dataset provided"
      }
    },
    "framework_specific": {
      "version": "2.19.0",
      "built_with_cuda": true,
      "gpu_available": true,
      "eager_execution": true
    }
  },
  {
    "timestamp": "2025-05-09T12:29:22.376011",
    "gpu": {
      "utilization": {
        "0": 0
      },
      "memory": {
        "0": {
          "used_mb": 9956,
          "total_mb": 10240,
          "percentage": 97.2265625
        }
      },
      "temperature": {
        "0": 44
      },
      "power": {
        "0": {
          "draw_watts": 140.7,
          "limit_watts": 370.0,
          "percentage": 38.027027027027025
        }
      },
      "clock_speeds": {
        "0": {
          "graphics_mhz": 1965,
          "memory_mhz": 9251
        }
      },
      "pcie_throughput": {
        "0": {
          "link_gen": "4",
          "link_width": "8",
          "max_bandwidth_GBps": 15.76,
          "mem_controller_util": 0.0,
          "estimated_usage_GBps": 0.0
        }
      },
      "idle_time": 41.12349605560303,
      "is_currently_idle": true
    },
    "cpu": {
      "utilization": {
        "overall": 0.5,
        "per_core": [
          0.0,
          0.0,
          0.0,
          0.0,
          9.1,
          0.0,
          0.0,
          0.0,
          9.1,
          0.0,
          0.0,
          0.0,
          9.1,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0
        ],
        "logical_cores": 20,
        "physical_cores": 14
      },
      "unused_cores": {
        "unused_core_count": 20,
        "unused_core_indices": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19
        ],
        "threshold": 10
      },
      "memory": {
        "total_gb": 31.13628387451172,
        "used_gb": 25.258590698242188,
        "available_gb": 5.316783905029297,
        "percent_used": 82.9,
        "swap_total_gb": 0.9540977478027344,
        "swap_used_gb": 0.0,
        "swap_percent": 0.0
      }
    },
    "latency": {
      "inference": {
        "batch_size": 1,
        "num_runs": 10,
        "avg_latency_ms": 19.537043571472168,
        "throughput_samples_per_sec": 51.18481700374522
      },
      "training_step": {
        "error": "in user code:\n\n    File \"/home/p0wden/Downloads/mloptimizer/app/common/GpuMetrics.py\", line 588, in train_step  *\n        loss = model.loss(y, y_pred)\n\n    TypeError: 'str' object is not callable\n"
      },
      "data_pipeline": {
        "status": "no dataset provided"
      }
    },
    "framework_specific": {
      "version": "2.19.0",
      "built_with_cuda": true,
      "gpu_available": true,
      "eager_execution": true
    }
  },
  {
    "timestamp": "2025-05-09T12:29:25.138791",
    "gpu": {
      "utilization": {
        "0": 3
      },
      "memory": {
        "0": {
          "used_mb": 9956,
          "total_mb": 10240,
          "percentage": 97.2265625
        }
      },
      "temperature": {
        "0": 43
      },
      "power": {
        "0": {
          "draw_watts": 116.19,
          "limit_watts": 370.0,
          "percentage": 31.4027027027027
        }
      },
      "clock_speeds": {
        "0": {
          "graphics_mhz": 1905,
          "memory_mhz": 9251
        }
      },
      "pcie_throughput": {
        "0": {
          "link_gen": "4",
          "link_width": "8",
          "max_bandwidth_GBps": 15.76,
          "mem_controller_util": 0.0,
          "estimated_usage_GBps": 0.0
        }
      },
      "idle_time": 43.886364221572876,
      "is_currently_idle": true
    },
    "cpu": {
      "utilization": {
        "overall": 0.5,
        "per_core": [
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          10.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0
        ],
        "logical_cores": 20,
        "physical_cores": 14
      },
      "unused_cores": {
        "unused_core_count": 20,
        "unused_core_indices": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19
        ],
        "threshold": 10
      },
      "memory": {
        "total_gb": 31.13628387451172,
        "used_gb": 25.256412506103516,
        "available_gb": 5.3189849853515625,
        "percent_used": 82.9,
        "swap_total_gb": 0.9540977478027344,
        "swap_used_gb": 0.0,
        "swap_percent": 0.0
      }
    },
    "latency": {
      "inference": {
        "batch_size": 1,
        "num_runs": 10,
        "avg_latency_ms": 19.069576263427734,
        "throughput_samples_per_sec": 52.43955010777209
      },
      "training_step": {
        "error": "in user code:\n\n    File \"/home/p0wden/Downloads/mloptimizer/app/common/GpuMetrics.py\", line 588, in train_step  *\n        loss = model.loss(y, y_pred)\n\n    TypeError: 'str' object is not callable\n"
      },
      "data_pipeline": {
        "status": "no dataset provided"
      }
    },
    "framework_specific": {
      "version": "2.19.0",
      "built_with_cuda": true,
      "gpu_available": true,
      "eager_execution": true
    }
  },
  {
    "timestamp": "2025-05-09T12:30:05.986137",
    "gpu": {
      "utilization": {
        "0": 2
      },
      "memory": {
        "0": {
          "used_mb": 9956,
          "total_mb": 10240,
          "percentage": 97.2265625
        }
      },
      "temperature": {
        "0": 44
      },
      "power": {
        "0": {
          "draw_watts": 140.99,
          "limit_watts": 370.0,
          "percentage": 38.105405405405406
        }
      },
      "clock_speeds": {
        "0": {
          "graphics_mhz": 1965,
          "memory_mhz": 9251
        }
      },
      "pcie_throughput": {
        "0": {
          "link_gen": "4",
          "link_width": "8",
          "max_bandwidth_GBps": 15.76,
          "mem_controller_util": 0.0,
          "estimated_usage_GBps": 0.0
        }
      },
      "idle_time": 84.7339026927948,
      "is_currently_idle": true
    },
    "cpu": {
      "utilization": {
        "overall": 0.0,
        "per_core": [
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          9.1,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0
        ],
        "logical_cores": 20,
        "physical_cores": 14
      },
      "unused_cores": {
        "unused_core_count": 20,
        "unused_core_indices": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19
        ],
        "threshold": 10
      },
      "memory": {
        "total_gb": 31.13628387451172,
        "used_gb": 25.527263641357422,
        "available_gb": 5.0483856201171875,
        "percent_used": 83.8,
        "swap_total_gb": 0.9540977478027344,
        "swap_used_gb": 0.0009765625,
        "swap_percent": 0.1
      }
    },
    "latency": {
      "inference": {
        "batch_size": 1,
        "num_runs": 10,
        "avg_latency_ms": 19.24450397491455,
        "throughput_samples_per_sec": 51.96288775764303
      },
      "training_step": {
        "error": "in user code:\n\n    File \"/home/p0wden/Downloads/mloptimizer/app/common/GpuMetrics.py\", line 588, in train_step  *\n        loss = model.loss(y, y_pred)\n\n    TypeError: 'str' object is not callable\n"
      },
      "data_pipeline": {
        "status": "no dataset provided"
      }
    },
    "framework_specific": {
      "version": "2.19.0",
      "built_with_cuda": true,
      "gpu_available": true,
      "eager_execution": true
    }
  }
]