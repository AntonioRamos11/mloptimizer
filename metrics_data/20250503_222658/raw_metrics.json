[
  {
    "timestamp": "2025-05-03T22:21:31.499176",
    "gpu": {
      "utilization": {
        "0": 1
      },
      "memory": {
        "0": {
          "used_mb": 9938,
          "total_mb": 10240,
          "percentage": 97.05078125
        }
      },
      "temperature": {
        "0": 52
      },
      "power": {
        "0": {
          "draw_watts": 127.98,
          "limit_watts": 370.0,
          "percentage": 34.58918918918919
        }
      },
      "clock_speeds": {
        "0": {
          "graphics_mhz": 1905,
          "memory_mhz": 9251
        }
      },
      "pcie_throughput": {
        "0": {
          "link_gen": "4",
          "link_width": "8",
          "max_bandwidth_GBps": 15.76,
          "mem_controller_util": 0.0,
          "estimated_usage_GBps": 0.0
        }
      },
      "idle_time": 0,
      "is_currently_idle": true
    },
    "cpu": {
      "utilization": {
        "overall": 0.0,
        "per_core": [
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0
        ],
        "logical_cores": 20,
        "physical_cores": 14
      },
      "unused_cores": {
        "unused_core_count": 17,
        "unused_core_indices": [
          0,
          1,
          3,
          4,
          5,
          6,
          7,
          9,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19
        ],
        "threshold": 10
      },
      "memory": {
        "total_gb": 31.13628387451172,
        "used_gb": 17.640819549560547,
        "available_gb": 12.716114044189453,
        "percent_used": 59.2,
        "swap_total_gb": 0.9540977478027344,
        "swap_used_gb": 0.158935546875,
        "swap_percent": 16.7
      }
    },
    "latency": {
      "inference": {
        "batch_size": 1,
        "num_runs": 10,
        "avg_latency_ms": 18.44933032989502,
        "throughput_samples_per_sec": 54.2025093658611
      },
      "training_step": {
        "error": "in user code:\n\n    File \"/home/p0wden/Downloads/mloptimizer/app/common/GpuMetrics.py\", line 579, in train_step  *\n        loss = model.loss(y, y_pred)\n\n    TypeError: 'str' object is not callable\n"
      },
      "data_pipeline": {
        "status": "no dataset provided"
      }
    },
    "framework_specific": {
      "version": "2.19.0",
      "built_with_cuda": true,
      "gpu_available": true,
      "eager_execution": true
    }
  },
  {
    "timestamp": "2025-05-03T22:22:23.228986",
    "gpu": {
      "utilization": {
        "0": 33
      },
      "memory": {
        "0": {
          "used_mb": 9938,
          "total_mb": 10240,
          "percentage": 97.05078125
        }
      },
      "temperature": {
        "0": 54
      },
      "power": {
        "0": {
          "draw_watts": 213.23,
          "limit_watts": 370.0,
          "percentage": 57.62972972972973
        }
      },
      "clock_speeds": {
        "0": {
          "graphics_mhz": 1965,
          "memory_mhz": 9251
        }
      },
      "pcie_throughput": {
        "0": {
          "link_gen": "4",
          "link_width": "8",
          "max_bandwidth_GBps": 15.76,
          "mem_controller_util": 0.0,
          "estimated_usage_GBps": 0.0
        }
      },
      "idle_time": 51.729798793792725,
      "is_currently_idle": false
    },
    "cpu": {
      "utilization": {
        "overall": 0.5,
        "per_core": [
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0
        ],
        "logical_cores": 20,
        "physical_cores": 14
      },
      "unused_cores": {
        "unused_core_count": 20,
        "unused_core_indices": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19
        ],
        "threshold": 10
      },
      "memory": {
        "total_gb": 31.13628387451172,
        "used_gb": 17.92214584350586,
        "available_gb": 12.436870574951172,
        "percent_used": 60.1,
        "swap_total_gb": 0.9540977478027344,
        "swap_used_gb": 0.158935546875,
        "swap_percent": 16.7
      }
    },
    "latency": {
      "inference": {
        "batch_size": 1,
        "num_runs": 10,
        "avg_latency_ms": 18.569159507751465,
        "throughput_samples_per_sec": 53.8527335920919
      },
      "training_step": {
        "error": "in user code:\n\n    File \"/home/p0wden/Downloads/mloptimizer/app/common/GpuMetrics.py\", line 579, in train_step  *\n        loss = model.loss(y, y_pred)\n\n    TypeError: 'str' object is not callable\n"
      },
      "data_pipeline": {
        "status": "no dataset provided"
      }
    },
    "framework_specific": {
      "version": "2.19.0",
      "built_with_cuda": true,
      "gpu_available": true,
      "eager_execution": true
    }
  },
  {
    "timestamp": "2025-05-03T22:22:25.970607",
    "gpu": {
      "utilization": {
        "0": 3
      },
      "memory": {
        "0": {
          "used_mb": 9938,
          "total_mb": 10240,
          "percentage": 97.05078125
        }
      },
      "temperature": {
        "0": 52
      },
      "power": {
        "0": {
          "draw_watts": 124.66,
          "limit_watts": 370.0,
          "percentage": 33.69189189189189
        }
      },
      "clock_speeds": {
        "0": {
          "graphics_mhz": 1905,
          "memory_mhz": 9251
        }
      },
      "pcie_throughput": {
        "0": {
          "link_gen": "4",
          "link_width": "8",
          "max_bandwidth_GBps": 15.76,
          "mem_controller_util": 0.0,
          "estimated_usage_GBps": 0.0
        }
      },
      "idle_time": 0,
      "is_currently_idle": true
    },
    "cpu": {
      "utilization": {
        "overall": 0.0,
        "per_core": [
          10.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0
        ],
        "logical_cores": 20,
        "physical_cores": 14
      },
      "unused_cores": {
        "unused_core_count": 20,
        "unused_core_indices": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19
        ],
        "threshold": 10
      },
      "memory": {
        "total_gb": 31.13628387451172,
        "used_gb": 17.927806854248047,
        "available_gb": 12.431209564208984,
        "percent_used": 60.1,
        "swap_total_gb": 0.9540977478027344,
        "swap_used_gb": 0.158935546875,
        "swap_percent": 16.7
      }
    },
    "latency": {
      "inference": {
        "batch_size": 1,
        "num_runs": 10,
        "avg_latency_ms": 18.064165115356445,
        "throughput_samples_per_sec": 55.35821852900882
      },
      "training_step": {
        "error": "in user code:\n\n    File \"/home/p0wden/Downloads/mloptimizer/app/common/GpuMetrics.py\", line 579, in train_step  *\n        loss = model.loss(y, y_pred)\n\n    TypeError: 'str' object is not callable\n"
      },
      "data_pipeline": {
        "status": "no dataset provided"
      }
    },
    "framework_specific": {
      "version": "2.19.0",
      "built_with_cuda": true,
      "gpu_available": true,
      "eager_execution": true
    }
  },
  {
    "timestamp": "2025-05-03T22:23:17.881406",
    "gpu": {
      "utilization": {
        "0": 0
      },
      "memory": {
        "0": {
          "used_mb": 9938,
          "total_mb": 10240,
          "percentage": 97.05078125
        }
      },
      "temperature": {
        "0": 54
      },
      "power": {
        "0": {
          "draw_watts": 212.3,
          "limit_watts": 370.0,
          "percentage": 57.37837837837838
        }
      },
      "clock_speeds": {
        "0": {
          "graphics_mhz": 1965,
          "memory_mhz": 9251
        }
      },
      "pcie_throughput": {
        "0": {
          "link_gen": "4",
          "link_width": "8",
          "max_bandwidth_GBps": 15.76,
          "mem_controller_util": 0.0,
          "estimated_usage_GBps": 0.0
        }
      },
      "idle_time": 51.911344051361084,
      "is_currently_idle": true
    },
    "cpu": {
      "utilization": {
        "overall": 0.0,
        "per_core": [
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0
        ],
        "logical_cores": 20,
        "physical_cores": 14
      },
      "unused_cores": {
        "unused_core_count": 20,
        "unused_core_indices": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19
        ],
        "threshold": 10
      },
      "memory": {
        "total_gb": 31.13628387451172,
        "used_gb": 18.213077545166016,
        "available_gb": 12.145915985107422,
        "percent_used": 61.0,
        "swap_total_gb": 0.9540977478027344,
        "swap_used_gb": 0.158935546875,
        "swap_percent": 16.7
      }
    },
    "latency": {
      "inference": {
        "batch_size": 1,
        "num_runs": 10,
        "avg_latency_ms": 18.063664436340332,
        "throughput_samples_per_sec": 55.35975291858324
      },
      "training_step": {
        "error": "in user code:\n\n    File \"/home/p0wden/Downloads/mloptimizer/app/common/GpuMetrics.py\", line 579, in train_step  *\n        loss = model.loss(y, y_pred)\n\n    TypeError: 'str' object is not callable\n"
      },
      "data_pipeline": {
        "status": "no dataset provided"
      }
    },
    "framework_specific": {
      "version": "2.19.0",
      "built_with_cuda": true,
      "gpu_available": true,
      "eager_execution": true
    }
  },
  {
    "timestamp": "2025-05-03T22:23:20.621111",
    "gpu": {
      "utilization": {
        "0": 3
      },
      "memory": {
        "0": {
          "used_mb": 9938,
          "total_mb": 10240,
          "percentage": 97.05078125
        }
      },
      "temperature": {
        "0": 52
      },
      "power": {
        "0": {
          "draw_watts": 127.87,
          "limit_watts": 370.0,
          "percentage": 34.55945945945946
        }
      },
      "clock_speeds": {
        "0": {
          "graphics_mhz": 1905,
          "memory_mhz": 9251
        }
      },
      "pcie_throughput": {
        "0": {
          "link_gen": "4",
          "link_width": "8",
          "max_bandwidth_GBps": 15.76,
          "mem_controller_util": 0.0,
          "estimated_usage_GBps": 0.0
        }
      },
      "idle_time": 54.650755882263184,
      "is_currently_idle": true
    },
    "cpu": {
      "utilization": {
        "overall": 0.0,
        "per_core": [
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0
        ],
        "logical_cores": 20,
        "physical_cores": 14
      },
      "unused_cores": {
        "unused_core_count": 20,
        "unused_core_indices": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19
        ],
        "threshold": 10
      },
      "memory": {
        "total_gb": 31.13628387451172,
        "used_gb": 18.22195053100586,
        "available_gb": 12.137065887451172,
        "percent_used": 61.0,
        "swap_total_gb": 0.9540977478027344,
        "swap_used_gb": 0.158935546875,
        "swap_percent": 16.7
      }
    },
    "latency": {
      "inference": {
        "batch_size": 1,
        "num_runs": 10,
        "avg_latency_ms": 18.006181716918945,
        "throughput_samples_per_sec": 55.5364827325041
      },
      "training_step": {
        "error": "in user code:\n\n    File \"/home/p0wden/Downloads/mloptimizer/app/common/GpuMetrics.py\", line 579, in train_step  *\n        loss = model.loss(y, y_pred)\n\n    TypeError: 'str' object is not callable\n"
      },
      "data_pipeline": {
        "status": "no dataset provided"
      }
    },
    "framework_specific": {
      "version": "2.19.0",
      "built_with_cuda": true,
      "gpu_available": true,
      "eager_execution": true
    }
  },
  {
    "timestamp": "2025-05-03T22:24:12.433513",
    "gpu": {
      "utilization": {
        "0": 48
      },
      "memory": {
        "0": {
          "used_mb": 9938,
          "total_mb": 10240,
          "percentage": 97.05078125
        }
      },
      "temperature": {
        "0": 54
      },
      "power": {
        "0": {
          "draw_watts": 208.75,
          "limit_watts": 370.0,
          "percentage": 56.41891891891891
        }
      },
      "clock_speeds": {
        "0": {
          "graphics_mhz": 1965,
          "memory_mhz": 9251
        }
      },
      "pcie_throughput": {
        "0": {
          "link_gen": "4",
          "link_width": "8",
          "max_bandwidth_GBps": 15.76,
          "mem_controller_util": 0.0,
          "estimated_usage_GBps": 0.0
        }
      },
      "idle_time": 106.46332049369812,
      "is_currently_idle": false
    },
    "cpu": {
      "utilization": {
        "overall": 0.0,
        "per_core": [
          0.0,
          0.0,
          9.1,
          0.0,
          0.0,
          0.0,
          9.1,
          0.0,
          0.0,
          0.0,
          16.7,
          9.1,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0
        ],
        "logical_cores": 20,
        "physical_cores": 14
      },
      "unused_cores": {
        "unused_core_count": 20,
        "unused_core_indices": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19
        ],
        "threshold": 10
      },
      "memory": {
        "total_gb": 31.13628387451172,
        "used_gb": 18.514904022216797,
        "available_gb": 11.844100952148438,
        "percent_used": 62.0,
        "swap_total_gb": 0.9540977478027344,
        "swap_used_gb": 0.158935546875,
        "swap_percent": 16.7
      }
    },
    "latency": {
      "inference": {
        "batch_size": 1,
        "num_runs": 10,
        "avg_latency_ms": 17.9581880569458,
        "throughput_samples_per_sec": 55.68490522701836
      },
      "training_step": {
        "error": "in user code:\n\n    File \"/home/p0wden/Downloads/mloptimizer/app/common/GpuMetrics.py\", line 579, in train_step  *\n        loss = model.loss(y, y_pred)\n\n    TypeError: 'str' object is not callable\n"
      },
      "data_pipeline": {
        "status": "no dataset provided"
      }
    },
    "framework_specific": {
      "version": "2.19.0",
      "built_with_cuda": true,
      "gpu_available": true,
      "eager_execution": true
    }
  },
  {
    "timestamp": "2025-05-03T22:24:15.170061",
    "gpu": {
      "utilization": {
        "0": 3
      },
      "memory": {
        "0": {
          "used_mb": 9938,
          "total_mb": 10240,
          "percentage": 97.05078125
        }
      },
      "temperature": {
        "0": 52
      },
      "power": {
        "0": {
          "draw_watts": 127.98,
          "limit_watts": 370.0,
          "percentage": 34.58918918918919
        }
      },
      "clock_speeds": {
        "0": {
          "graphics_mhz": 1905,
          "memory_mhz": 9251
        }
      },
      "pcie_throughput": {
        "0": {
          "link_gen": "4",
          "link_width": "8",
          "max_bandwidth_GBps": 15.76,
          "mem_controller_util": 0.0,
          "estimated_usage_GBps": 0.0
        }
      },
      "idle_time": 0,
      "is_currently_idle": true
    },
    "cpu": {
      "utilization": {
        "overall": 1.5,
        "per_core": [
          0.0,
          0.0,
          0.0,
          0.0,
          10.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0
        ],
        "logical_cores": 20,
        "physical_cores": 14
      },
      "unused_cores": {
        "unused_core_count": 20,
        "unused_core_indices": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19
        ],
        "threshold": 10
      },
      "memory": {
        "total_gb": 31.13628387451172,
        "used_gb": 18.511390686035156,
        "available_gb": 11.847625732421875,
        "percent_used": 61.9,
        "swap_total_gb": 0.9540977478027344,
        "swap_used_gb": 0.158935546875,
        "swap_percent": 16.7
      }
    },
    "latency": {
      "inference": {
        "batch_size": 1,
        "num_runs": 10,
        "avg_latency_ms": 18.3013916015625,
        "throughput_samples_per_sec": 54.640653660163416
      },
      "training_step": {
        "error": "in user code:\n\n    File \"/home/p0wden/Downloads/mloptimizer/app/common/GpuMetrics.py\", line 579, in train_step  *\n        loss = model.loss(y, y_pred)\n\n    TypeError: 'str' object is not callable\n"
      },
      "data_pipeline": {
        "status": "no dataset provided"
      }
    },
    "framework_specific": {
      "version": "2.19.0",
      "built_with_cuda": true,
      "gpu_available": true,
      "eager_execution": true
    }
  },
  {
    "timestamp": "2025-05-03T22:25:07.047164",
    "gpu": {
      "utilization": {
        "0": 0
      },
      "memory": {
        "0": {
          "used_mb": 9938,
          "total_mb": 10240,
          "percentage": 97.05078125
        }
      },
      "temperature": {
        "0": 53
      },
      "power": {
        "0": {
          "draw_watts": 212.43,
          "limit_watts": 370.0,
          "percentage": 57.413513513513514
        }
      },
      "clock_speeds": {
        "0": {
          "graphics_mhz": 1965,
          "memory_mhz": 9251
        }
      },
      "pcie_throughput": {
        "0": {
          "link_gen": "4",
          "link_width": "8",
          "max_bandwidth_GBps": 15.76,
          "mem_controller_util": 0.0,
          "estimated_usage_GBps": 0.0
        }
      },
      "idle_time": 51.87726712226868,
      "is_currently_idle": true
    },
    "cpu": {
      "utilization": {
        "overall": 0.5,
        "per_core": [
          0.0,
          0.0,
          9.1,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0
        ],
        "logical_cores": 20,
        "physical_cores": 14
      },
      "unused_cores": {
        "unused_core_count": 20,
        "unused_core_indices": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19
        ],
        "threshold": 10
      },
      "memory": {
        "total_gb": 31.13628387451172,
        "used_gb": 18.77593994140625,
        "available_gb": 11.583076477050781,
        "percent_used": 62.8,
        "swap_total_gb": 0.9540977478027344,
        "swap_used_gb": 0.158935546875,
        "swap_percent": 16.7
      }
    },
    "latency": {
      "inference": {
        "batch_size": 1,
        "num_runs": 10,
        "avg_latency_ms": 17.933273315429688,
        "throughput_samples_per_sec": 55.76226840526685
      },
      "training_step": {
        "error": "in user code:\n\n    File \"/home/p0wden/Downloads/mloptimizer/app/common/GpuMetrics.py\", line 579, in train_step  *\n        loss = model.loss(y, y_pred)\n\n    TypeError: 'str' object is not callable\n"
      },
      "data_pipeline": {
        "status": "no dataset provided"
      }
    },
    "framework_specific": {
      "version": "2.19.0",
      "built_with_cuda": true,
      "gpu_available": true,
      "eager_execution": true
    }
  },
  {
    "timestamp": "2025-05-03T22:25:09.830165",
    "gpu": {
      "utilization": {
        "0": 0
      },
      "memory": {
        "0": {
          "used_mb": 9938,
          "total_mb": 10240,
          "percentage": 97.05078125
        }
      },
      "temperature": {
        "0": 52
      },
      "power": {
        "0": {
          "draw_watts": 127.36,
          "limit_watts": 370.0,
          "percentage": 34.421621621621625
        }
      },
      "clock_speeds": {
        "0": {
          "graphics_mhz": 1905,
          "memory_mhz": 9251
        }
      },
      "pcie_throughput": {
        "0": {
          "link_gen": "4",
          "link_width": "8",
          "max_bandwidth_GBps": 15.76,
          "mem_controller_util": 0.0,
          "estimated_usage_GBps": 0.0
        }
      },
      "idle_time": 54.65983605384827,
      "is_currently_idle": true
    },
    "cpu": {
      "utilization": {
        "overall": 1.5,
        "per_core": [
          16.7,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          9.1,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0
        ],
        "logical_cores": 20,
        "physical_cores": 14
      },
      "unused_cores": {
        "unused_core_count": 20,
        "unused_core_indices": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19
        ],
        "threshold": 10
      },
      "memory": {
        "total_gb": 31.13628387451172,
        "used_gb": 18.783424377441406,
        "available_gb": 11.575569152832031,
        "percent_used": 62.8,
        "swap_total_gb": 0.9540977478027344,
        "swap_used_gb": 0.158935546875,
        "swap_percent": 16.7
      }
    },
    "latency": {
      "inference": {
        "batch_size": 1,
        "num_runs": 10,
        "avg_latency_ms": 17.97511577606201,
        "throughput_samples_per_sec": 55.63246503990418
      },
      "training_step": {
        "error": "in user code:\n\n    File \"/home/p0wden/Downloads/mloptimizer/app/common/GpuMetrics.py\", line 579, in train_step  *\n        loss = model.loss(y, y_pred)\n\n    TypeError: 'str' object is not callable\n"
      },
      "data_pipeline": {
        "status": "no dataset provided"
      }
    },
    "framework_specific": {
      "version": "2.19.0",
      "built_with_cuda": true,
      "gpu_available": true,
      "eager_execution": true
    }
  },
  {
    "timestamp": "2025-05-03T22:26:01.536615",
    "gpu": {
      "utilization": {
        "0": 25
      },
      "memory": {
        "0": {
          "used_mb": 9938,
          "total_mb": 10240,
          "percentage": 97.05078125
        }
      },
      "temperature": {
        "0": 53
      },
      "power": {
        "0": {
          "draw_watts": 214.02,
          "limit_watts": 370.0,
          "percentage": 57.84324324324325
        }
      },
      "clock_speeds": {
        "0": {
          "graphics_mhz": 1980,
          "memory_mhz": 9251
        }
      },
      "pcie_throughput": {
        "0": {
          "link_gen": "4",
          "link_width": "8",
          "max_bandwidth_GBps": 15.76,
          "mem_controller_util": 5.0,
          "estimated_usage_GBps": 0.788
        }
      },
      "idle_time": 106.36672902107239,
      "is_currently_idle": false
    },
    "cpu": {
      "utilization": {
        "overall": 0.5,
        "per_core": [
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0
        ],
        "logical_cores": 20,
        "physical_cores": 14
      },
      "unused_cores": {
        "unused_core_count": 20,
        "unused_core_indices": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19
        ],
        "threshold": 10
      },
      "memory": {
        "total_gb": 31.13628387451172,
        "used_gb": 19.087993621826172,
        "available_gb": 11.270980834960938,
        "percent_used": 63.8,
        "swap_total_gb": 0.9540977478027344,
        "swap_used_gb": 0.158935546875,
        "swap_percent": 16.7
      }
    },
    "latency": {
      "inference": {
        "batch_size": 1,
        "num_runs": 10,
        "avg_latency_ms": 18.044567108154297,
        "throughput_samples_per_sec": 55.41834248537347
      },
      "training_step": {
        "error": "in user code:\n\n    File \"/home/p0wden/Downloads/mloptimizer/app/common/GpuMetrics.py\", line 579, in train_step  *\n        loss = model.loss(y, y_pred)\n\n    TypeError: 'str' object is not callable\n"
      },
      "data_pipeline": {
        "status": "no dataset provided"
      }
    },
    "framework_specific": {
      "version": "2.19.0",
      "built_with_cuda": true,
      "gpu_available": true,
      "eager_execution": true
    }
  },
  {
    "timestamp": "2025-05-03T22:26:04.422992",
    "gpu": {
      "utilization": {
        "0": 0
      },
      "memory": {
        "0": {
          "used_mb": 9938,
          "total_mb": 10240,
          "percentage": 97.05078125
        }
      },
      "temperature": {
        "0": 51
      },
      "power": {
        "0": {
          "draw_watts": 126.15,
          "limit_watts": 370.0,
          "percentage": 34.0945945945946
        }
      },
      "clock_speeds": {
        "0": {
          "graphics_mhz": 1905,
          "memory_mhz": 9251
        }
      },
      "pcie_throughput": {
        "0": {
          "link_gen": "4",
          "link_width": "8",
          "max_bandwidth_GBps": 15.76,
          "mem_controller_util": 0.0,
          "estimated_usage_GBps": 0.0
        }
      },
      "idle_time": 0,
      "is_currently_idle": true
    },
    "cpu": {
      "utilization": {
        "overall": 0.0,
        "per_core": [
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          10.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0
        ],
        "logical_cores": 20,
        "physical_cores": 14
      },
      "unused_cores": {
        "unused_core_count": 19,
        "unused_core_indices": [
          0,
          1,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19
        ],
        "threshold": 10
      },
      "memory": {
        "total_gb": 31.13628387451172,
        "used_gb": 19.088298797607422,
        "available_gb": 11.270706176757812,
        "percent_used": 63.8,
        "swap_total_gb": 0.9540977478027344,
        "swap_used_gb": 0.158935546875,
        "swap_percent": 16.7
      }
    },
    "latency": {
      "inference": {
        "batch_size": 1,
        "num_runs": 10,
        "avg_latency_ms": 17.73698329925537,
        "throughput_samples_per_sec": 56.3793731509
      },
      "training_step": {
        "error": "in user code:\n\n    File \"/home/p0wden/Downloads/mloptimizer/app/common/GpuMetrics.py\", line 579, in train_step  *\n        loss = model.loss(y, y_pred)\n\n    TypeError: 'str' object is not callable\n"
      },
      "data_pipeline": {
        "status": "no dataset provided"
      }
    },
    "framework_specific": {
      "version": "2.19.0",
      "built_with_cuda": true,
      "gpu_available": true,
      "eager_execution": true
    }
  },
  {
    "timestamp": "2025-05-03T22:26:56.123203",
    "gpu": {
      "utilization": {
        "0": 28
      },
      "memory": {
        "0": {
          "used_mb": 9932,
          "total_mb": 10240,
          "percentage": 96.9921875
        }
      },
      "temperature": {
        "0": 53
      },
      "power": {
        "0": {
          "draw_watts": 212.21,
          "limit_watts": 370.0,
          "percentage": 57.35405405405406
        }
      },
      "clock_speeds": {
        "0": {
          "graphics_mhz": 1980,
          "memory_mhz": 9251
        }
      },
      "pcie_throughput": {
        "0": {
          "link_gen": "4",
          "link_width": "8",
          "max_bandwidth_GBps": 15.76,
          "mem_controller_util": 5.666666666666667,
          "estimated_usage_GBps": 0.8930666666666667
        }
      },
      "idle_time": 51.70054531097412,
      "is_currently_idle": false
    },
    "cpu": {
      "utilization": {
        "overall": 0.0,
        "per_core": [
          0.0,
          0.0,
          0.0,
          0.0,
          11.1,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0
        ],
        "logical_cores": 20,
        "physical_cores": 14
      },
      "unused_cores": {
        "unused_core_count": 20,
        "unused_core_indices": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19
        ],
        "threshold": 10
      },
      "memory": {
        "total_gb": 31.13628387451172,
        "used_gb": 19.375057220458984,
        "available_gb": 10.983951568603516,
        "percent_used": 64.7,
        "swap_total_gb": 0.9540977478027344,
        "swap_used_gb": 0.158935546875,
        "swap_percent": 16.7
      }
    },
    "latency": {
      "inference": {
        "batch_size": 1,
        "num_runs": 10,
        "avg_latency_ms": 18.125200271606445,
        "throughput_samples_per_sec": 55.171804174021936
      },
      "training_step": {
        "error": "in user code:\n\n    File \"/home/p0wden/Downloads/mloptimizer/app/common/GpuMetrics.py\", line 579, in train_step  *\n        loss = model.loss(y, y_pred)\n\n    TypeError: 'str' object is not callable\n"
      },
      "data_pipeline": {
        "status": "no dataset provided"
      }
    },
    "framework_specific": {
      "version": "2.19.0",
      "built_with_cuda": true,
      "gpu_available": true,
      "eager_execution": true
    }
  }
]