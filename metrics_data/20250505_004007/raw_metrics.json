[
  {
    "timestamp": "2025-05-05T00:34:54.220691",
    "gpu": {
      "utilization": {
        "0": 16
      },
      "memory": {
        "0": {
          "used_mb": 9789,
          "total_mb": 10240,
          "percentage": 95.595703125
        }
      },
      "temperature": {
        "0": 49
      },
      "power": {
        "0": {
          "draw_watts": 126.82,
          "limit_watts": 370.0,
          "percentage": 34.27567567567568
        }
      },
      "clock_speeds": {
        "0": {
          "graphics_mhz": 1905,
          "memory_mhz": 9251
        }
      },
      "pcie_throughput": {
        "0": {
          "link_gen": "4",
          "link_width": "8",
          "max_bandwidth_GBps": 15.76,
          "mem_controller_util": 1.0,
          "estimated_usage_GBps": 0.1576
        }
      },
      "idle_time": 0,
      "is_currently_idle": false
    },
    "cpu": {
      "utilization": {
        "overall": 8.2,
        "per_core": [
          18.2,
          0.0,
          18.2,
          0.0,
          11.1,
          0.0,
          20.0,
          0.0,
          10.0,
          0.0,
          36.4,
          10.0,
          9.1,
          10.0,
          9.1,
          10.0,
          9.1,
          10.0,
          9.1,
          0.0
        ],
        "logical_cores": 20,
        "physical_cores": 14
      },
      "unused_cores": {
        "unused_core_count": 10,
        "unused_core_indices": [
          0,
          1,
          6,
          7,
          9,
          11,
          12,
          13,
          16,
          18
        ],
        "threshold": 10
      },
      "memory": {
        "total_gb": 31.13628387451172,
        "used_gb": 16.32571792602539,
        "available_gb": 13.464363098144531,
        "percent_used": 56.8,
        "swap_total_gb": 0.9540977478027344,
        "swap_used_gb": 0.0,
        "swap_percent": 0.0
      }
    },
    "latency": {
      "inference": {
        "batch_size": 1,
        "num_runs": 10,
        "avg_latency_ms": 24.025774002075195,
        "throughput_samples_per_sec": 41.621968137785124
      },
      "training_step": {
        "error": "in user code:\n\n    File \"/home/p0wden/Downloads/mloptimizer/app/common/GpuMetrics.py\", line 588, in train_step  *\n        loss = model.loss(y, y_pred)\n\n    TypeError: 'str' object is not callable\n"
      },
      "data_pipeline": {
        "status": "no dataset provided"
      }
    },
    "framework_specific": {
      "version": "2.19.0",
      "built_with_cuda": true,
      "gpu_available": true,
      "eager_execution": true
    }
  },
  {
    "timestamp": "2025-05-05T00:36:09.518371",
    "gpu": {
      "utilization": {
        "0": 18
      },
      "memory": {
        "0": {
          "used_mb": 9789,
          "total_mb": 10240,
          "percentage": 95.595703125
        }
      },
      "temperature": {
        "0": 51
      },
      "power": {
        "0": {
          "draw_watts": 180.31,
          "limit_watts": 370.0,
          "percentage": 48.73243243243243
        }
      },
      "clock_speeds": {
        "0": {
          "graphics_mhz": 1980,
          "memory_mhz": 9251
        }
      },
      "pcie_throughput": {
        "0": {
          "link_gen": "4",
          "link_width": "8",
          "max_bandwidth_GBps": 15.76,
          "mem_controller_util": 1.0,
          "estimated_usage_GBps": 0.1576
        }
      },
      "idle_time": 0,
      "is_currently_idle": false
    },
    "cpu": {
      "utilization": {
        "overall": 5.7,
        "per_core": [
          18.2,
          0.0,
          11.1,
          0.0,
          18.2,
          0.0,
          18.2,
          0.0,
          11.1,
          0.0,
          40.0,
          0.0,
          10.0,
          0.0,
          10.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0
        ],
        "logical_cores": 20,
        "physical_cores": 14
      },
      "unused_cores": {
        "unused_core_count": 12,
        "unused_core_indices": [
          1,
          2,
          3,
          5,
          7,
          9,
          11,
          13,
          14,
          15,
          16,
          18
        ],
        "threshold": 10
      },
      "memory": {
        "total_gb": 31.13628387451172,
        "used_gb": 16.661270141601562,
        "available_gb": 13.12875747680664,
        "percent_used": 57.8,
        "swap_total_gb": 0.9540977478027344,
        "swap_used_gb": 0.0,
        "swap_percent": 0.0
      }
    },
    "latency": {
      "inference": {
        "batch_size": 1,
        "num_runs": 10,
        "avg_latency_ms": 23.733139038085938,
        "throughput_samples_per_sec": 42.135176404404085
      },
      "training_step": {
        "error": "in user code:\n\n    File \"/home/p0wden/Downloads/mloptimizer/app/common/GpuMetrics.py\", line 588, in train_step  *\n        loss = model.loss(y, y_pred)\n\n    TypeError: 'str' object is not callable\n"
      },
      "data_pipeline": {
        "status": "no dataset provided"
      }
    },
    "framework_specific": {
      "version": "2.19.0",
      "built_with_cuda": true,
      "gpu_available": true,
      "eager_execution": true
    }
  },
  {
    "timestamp": "2025-05-05T00:36:12.373487",
    "gpu": {
      "utilization": {
        "0": 17
      },
      "memory": {
        "0": {
          "used_mb": 9789,
          "total_mb": 10240,
          "percentage": 95.595703125
        }
      },
      "temperature": {
        "0": 49
      },
      "power": {
        "0": {
          "draw_watts": 127.32,
          "limit_watts": 370.0,
          "percentage": 34.41081081081081
        }
      },
      "clock_speeds": {
        "0": {
          "graphics_mhz": 1905,
          "memory_mhz": 9251
        }
      },
      "pcie_throughput": {
        "0": {
          "link_gen": "4",
          "link_width": "8",
          "max_bandwidth_GBps": 15.76,
          "mem_controller_util": 1.0,
          "estimated_usage_GBps": 0.1576
        }
      },
      "idle_time": 0,
      "is_currently_idle": false
    },
    "cpu": {
      "utilization": {
        "overall": 11.8,
        "per_core": [
          0.0,
          0.0,
          20.0,
          0.0,
          10.0,
          9.1,
          10.0,
          0.0,
          11.1,
          0.0,
          60.0,
          10.0,
          10.0,
          0.0,
          10.0,
          0.0,
          0.0,
          0.0,
          10.0,
          0.0
        ],
        "logical_cores": 20,
        "physical_cores": 14
      },
      "unused_cores": {
        "unused_core_count": 14,
        "unused_core_indices": [
          0,
          1,
          2,
          3,
          4,
          5,
          7,
          11,
          13,
          14,
          15,
          16,
          18,
          19
        ],
        "threshold": 10
      },
      "memory": {
        "total_gb": 31.13628387451172,
        "used_gb": 16.634765625,
        "available_gb": 13.155284881591797,
        "percent_used": 57.7,
        "swap_total_gb": 0.9540977478027344,
        "swap_used_gb": 0.0,
        "swap_percent": 0.0
      }
    },
    "latency": {
      "inference": {
        "batch_size": 1,
        "num_runs": 10,
        "avg_latency_ms": 24.285101890563965,
        "throughput_samples_per_sec": 41.177508931455314
      },
      "training_step": {
        "error": "in user code:\n\n    File \"/home/p0wden/Downloads/mloptimizer/app/common/GpuMetrics.py\", line 588, in train_step  *\n        loss = model.loss(y, y_pred)\n\n    TypeError: 'str' object is not callable\n"
      },
      "data_pipeline": {
        "status": "no dataset provided"
      }
    },
    "framework_specific": {
      "version": "2.19.0",
      "built_with_cuda": true,
      "gpu_available": true,
      "eager_execution": true
    }
  },
  {
    "timestamp": "2025-05-05T00:37:29.056109",
    "gpu": {
      "utilization": {
        "0": 24
      },
      "memory": {
        "0": {
          "used_mb": 9825,
          "total_mb": 10240,
          "percentage": 95.947265625
        }
      },
      "temperature": {
        "0": 51
      },
      "power": {
        "0": {
          "draw_watts": 187.85,
          "limit_watts": 370.0,
          "percentage": 50.77027027027027
        }
      },
      "clock_speeds": {
        "0": {
          "graphics_mhz": 1980,
          "memory_mhz": 9251
        }
      },
      "pcie_throughput": {
        "0": {
          "link_gen": "4",
          "link_width": "8",
          "max_bandwidth_GBps": 15.76,
          "mem_controller_util": 1.0,
          "estimated_usage_GBps": 0.1576
        }
      },
      "idle_time": 0,
      "is_currently_idle": false
    },
    "cpu": {
      "utilization": {
        "overall": 8.5,
        "per_core": [
          10.0,
          0.0,
          20.0,
          0.0,
          20.0,
          0.0,
          27.3,
          0.0,
          66.7,
          10.0,
          33.3,
          9.1,
          10.0,
          10.0,
          10.0,
          25.0,
          9.1,
          0.0,
          10.0,
          10.0
        ],
        "logical_cores": 20,
        "physical_cores": 14
      },
      "unused_cores": {
        "unused_core_count": 12,
        "unused_core_indices": [
          1,
          3,
          4,
          5,
          9,
          11,
          13,
          14,
          15,
          16,
          18,
          19
        ],
        "threshold": 10
      },
      "memory": {
        "total_gb": 31.13628387451172,
        "used_gb": 16.981399536132812,
        "available_gb": 12.80868148803711,
        "percent_used": 58.9,
        "swap_total_gb": 0.9540977478027344,
        "swap_used_gb": 0.0,
        "swap_percent": 0.0
      }
    },
    "latency": {
      "inference": {
        "batch_size": 1,
        "num_runs": 10,
        "avg_latency_ms": 23.273110389709473,
        "throughput_samples_per_sec": 42.968042657596975
      },
      "training_step": {
        "error": "in user code:\n\n    File \"/home/p0wden/Downloads/mloptimizer/app/common/GpuMetrics.py\", line 588, in train_step  *\n        loss = model.loss(y, y_pred)\n\n    TypeError: 'str' object is not callable\n"
      },
      "data_pipeline": {
        "status": "no dataset provided"
      }
    },
    "framework_specific": {
      "version": "2.19.0",
      "built_with_cuda": true,
      "gpu_available": true,
      "eager_execution": true
    }
  },
  {
    "timestamp": "2025-05-05T00:37:31.903953",
    "gpu": {
      "utilization": {
        "0": 21
      },
      "memory": {
        "0": {
          "used_mb": 9825,
          "total_mb": 10240,
          "percentage": 95.947265625
        }
      },
      "temperature": {
        "0": 50
      },
      "power": {
        "0": {
          "draw_watts": 126.66,
          "limit_watts": 370.0,
          "percentage": 34.23243243243243
        }
      },
      "clock_speeds": {
        "0": {
          "graphics_mhz": 1905,
          "memory_mhz": 9251
        }
      },
      "pcie_throughput": {
        "0": {
          "link_gen": "4",
          "link_width": "8",
          "max_bandwidth_GBps": 15.76,
          "mem_controller_util": 1.0,
          "estimated_usage_GBps": 0.1576
        }
      },
      "idle_time": 0,
      "is_currently_idle": false
    },
    "cpu": {
      "utilization": {
        "overall": 6.3,
        "per_core": [
          0.0,
          0.0,
          16.7,
          0.0,
          11.1,
          0.0,
          10.0,
          0.0,
          27.3,
          0.0,
          60.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0
        ],
        "logical_cores": 20,
        "physical_cores": 14
      },
      "unused_cores": {
        "unused_core_count": 10,
        "unused_core_indices": [
          3,
          5,
          7,
          9,
          11,
          13,
          14,
          15,
          16,
          19
        ],
        "threshold": 10
      },
      "memory": {
        "total_gb": 31.13628387451172,
        "used_gb": 16.975143432617188,
        "available_gb": 12.814937591552734,
        "percent_used": 58.8,
        "swap_total_gb": 0.9540977478027344,
        "swap_used_gb": 0.0,
        "swap_percent": 0.0
      }
    },
    "latency": {
      "inference": {
        "batch_size": 1,
        "num_runs": 10,
        "avg_latency_ms": 23.779869079589844,
        "throughput_samples_per_sec": 42.052376178062964
      },
      "training_step": {
        "error": "in user code:\n\n    File \"/home/p0wden/Downloads/mloptimizer/app/common/GpuMetrics.py\", line 588, in train_step  *\n        loss = model.loss(y, y_pred)\n\n    TypeError: 'str' object is not callable\n"
      },
      "data_pipeline": {
        "status": "no dataset provided"
      }
    },
    "framework_specific": {
      "version": "2.19.0",
      "built_with_cuda": true,
      "gpu_available": true,
      "eager_execution": true
    }
  },
  {
    "timestamp": "2025-05-05T00:38:47.106856",
    "gpu": {
      "utilization": {
        "0": 31
      },
      "memory": {
        "0": {
          "used_mb": 9825,
          "total_mb": 10240,
          "percentage": 95.947265625
        }
      },
      "temperature": {
        "0": 53
      },
      "power": {
        "0": {
          "draw_watts": 181.19,
          "limit_watts": 370.0,
          "percentage": 48.97027027027027
        }
      },
      "clock_speeds": {
        "0": {
          "graphics_mhz": 1980,
          "memory_mhz": 9251
        }
      },
      "pcie_throughput": {
        "0": {
          "link_gen": "4",
          "link_width": "8",
          "max_bandwidth_GBps": 15.76,
          "mem_controller_util": 1.0,
          "estimated_usage_GBps": 0.1576
        }
      },
      "idle_time": 0,
      "is_currently_idle": false
    },
    "cpu": {
      "utilization": {
        "overall": 11.3,
        "per_core": [
          10.0,
          10.0,
          18.2,
          9.1,
          10.0,
          0.0,
          11.1,
          0.0,
          80.0,
          0.0,
          18.2,
          0.0,
          9.1,
          9.1,
          9.1,
          9.1,
          10.0,
          10.0,
          10.0,
          0.0
        ],
        "logical_cores": 20,
        "physical_cores": 14
      },
      "unused_cores": {
        "unused_core_count": 14,
        "unused_core_indices": [
          0,
          1,
          2,
          3,
          5,
          6,
          7,
          9,
          13,
          14,
          15,
          16,
          17,
          18
        ],
        "threshold": 10
      },
      "memory": {
        "total_gb": 31.13628387451172,
        "used_gb": 17.356746673583984,
        "available_gb": 12.432842254638672,
        "percent_used": 60.1,
        "swap_total_gb": 0.9540977478027344,
        "swap_used_gb": 0.0,
        "swap_percent": 0.0
      }
    },
    "latency": {
      "inference": {
        "batch_size": 1,
        "num_runs": 10,
        "avg_latency_ms": 23.47438335418701,
        "throughput_samples_per_sec": 42.59962806740288
      },
      "training_step": {
        "error": "in user code:\n\n    File \"/home/p0wden/Downloads/mloptimizer/app/common/GpuMetrics.py\", line 588, in train_step  *\n        loss = model.loss(y, y_pred)\n\n    TypeError: 'str' object is not callable\n"
      },
      "data_pipeline": {
        "status": "no dataset provided"
      }
    },
    "framework_specific": {
      "version": "2.19.0",
      "built_with_cuda": true,
      "gpu_available": true,
      "eager_execution": true
    }
  },
  {
    "timestamp": "2025-05-05T00:38:49.950197",
    "gpu": {
      "utilization": {
        "0": 17
      },
      "memory": {
        "0": {
          "used_mb": 9825,
          "total_mb": 10240,
          "percentage": 95.947265625
        }
      },
      "temperature": {
        "0": 51
      },
      "power": {
        "0": {
          "draw_watts": 127.72,
          "limit_watts": 370.0,
          "percentage": 34.518918918918914
        }
      },
      "clock_speeds": {
        "0": {
          "graphics_mhz": 1905,
          "memory_mhz": 9251
        }
      },
      "pcie_throughput": {
        "0": {
          "link_gen": "4",
          "link_width": "8",
          "max_bandwidth_GBps": 15.76,
          "mem_controller_util": 1.3333333333333333,
          "estimated_usage_GBps": 0.2101333333333333
        }
      },
      "idle_time": 0,
      "is_currently_idle": false
    },
    "cpu": {
      "utilization": {
        "overall": 4.8,
        "per_core": [
          10.0,
          9.1,
          10.0,
          0.0,
          11.1,
          0.0,
          25.0,
          0.0,
          22.2,
          0.0,
          30.0,
          0.0,
          18.2,
          0.0,
          10.0,
          0.0,
          9.1,
          0.0,
          10.0,
          9.1
        ],
        "logical_cores": 20,
        "physical_cores": 14
      },
      "unused_cores": {
        "unused_core_count": 9,
        "unused_core_indices": [
          1,
          3,
          5,
          9,
          11,
          12,
          15,
          18,
          19
        ],
        "threshold": 10
      },
      "memory": {
        "total_gb": 31.13628387451172,
        "used_gb": 17.37657928466797,
        "available_gb": 12.413013458251953,
        "percent_used": 60.1,
        "swap_total_gb": 0.9540977478027344,
        "swap_used_gb": 0.0,
        "swap_percent": 0.0
      }
    },
    "latency": {
      "inference": {
        "batch_size": 1,
        "num_runs": 10,
        "avg_latency_ms": 23.46508502960205,
        "throughput_samples_per_sec": 42.61650868677714
      },
      "training_step": {
        "error": "in user code:\n\n    File \"/home/p0wden/Downloads/mloptimizer/app/common/GpuMetrics.py\", line 588, in train_step  *\n        loss = model.loss(y, y_pred)\n\n    TypeError: 'str' object is not callable\n"
      },
      "data_pipeline": {
        "status": "no dataset provided"
      }
    },
    "framework_specific": {
      "version": "2.19.0",
      "built_with_cuda": true,
      "gpu_available": true,
      "eager_execution": true
    }
  },
  {
    "timestamp": "2025-05-05T00:40:04.863261",
    "gpu": {
      "utilization": {
        "0": 27
      },
      "memory": {
        "0": {
          "used_mb": 9825,
          "total_mb": 10240,
          "percentage": 95.947265625
        }
      },
      "temperature": {
        "0": 52
      },
      "power": {
        "0": {
          "draw_watts": 187.57,
          "limit_watts": 370.0,
          "percentage": 50.69459459459459
        }
      },
      "clock_speeds": {
        "0": {
          "graphics_mhz": 1980,
          "memory_mhz": 9251
        }
      },
      "pcie_throughput": {
        "0": {
          "link_gen": "4",
          "link_width": "8",
          "max_bandwidth_GBps": 15.76,
          "mem_controller_util": 1.0,
          "estimated_usage_GBps": 0.1576
        }
      },
      "idle_time": 0,
      "is_currently_idle": false
    },
    "cpu": {
      "utilization": {
        "overall": 5.2,
        "per_core": [
          0.0,
          0.0,
          18.2,
          0.0,
          10.0,
          0.0,
          11.1,
          0.0,
          20.0,
          9.1,
          33.3,
          0.0,
          0.0,
          10.0,
          0.0,
          10.0,
          0.0,
          0.0,
          10.0,
          0.0
        ],
        "logical_cores": 20,
        "physical_cores": 14
      },
      "unused_cores": {
        "unused_core_count": 11,
        "unused_core_indices": [
          1,
          3,
          5,
          7,
          9,
          11,
          12,
          13,
          14,
          16,
          19
        ],
        "threshold": 10
      },
      "memory": {
        "total_gb": 31.13628387451172,
        "used_gb": 17.682079315185547,
        "available_gb": 12.107513427734375,
        "percent_used": 61.1,
        "swap_total_gb": 0.9540977478027344,
        "swap_used_gb": 0.0,
        "swap_percent": 0.0
      }
    },
    "latency": {
      "inference": {
        "batch_size": 1,
        "num_runs": 10,
        "avg_latency_ms": 22.937774658203125,
        "throughput_samples_per_sec": 43.59620821553301
      },
      "training_step": {
        "error": "in user code:\n\n    File \"/home/p0wden/Downloads/mloptimizer/app/common/GpuMetrics.py\", line 588, in train_step  *\n        loss = model.loss(y, y_pred)\n\n    TypeError: 'str' object is not callable\n"
      },
      "data_pipeline": {
        "status": "no dataset provided"
      }
    },
    "framework_specific": {
      "version": "2.19.0",
      "built_with_cuda": true,
      "gpu_available": true,
      "eager_execution": true
    }
  }
]