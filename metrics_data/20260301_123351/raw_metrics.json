[
  {
    "timestamp": "2026-03-01T12:27:45.244474",
    "gpu": {
      "utilization": {
        "0": 5
      },
      "memory": {
        "0": {
          "used_mb": 8319,
          "total_mb": 10240,
          "percentage": 81.240234375
        }
      },
      "temperature": {
        "0": 40
      },
      "power": {
        "0": {
          "draw_watts": 106.88,
          "limit_watts": 370.0,
          "percentage": 28.886486486486483
        }
      },
      "clock_speeds": {
        "0": {
          "graphics_mhz": 1905,
          "memory_mhz": 9251
        }
      },
      "pcie_throughput": {
        "0": {
          "link_gen": "4",
          "link_width": "8",
          "max_bandwidth_GBps": 15.76,
          "mem_controller_util": 1.0,
          "estimated_usage_GBps": 0.1576
        }
      },
      "idle_time": 0,
      "is_currently_idle": false
    },
    "cpu": {
      "utilization": {
        "overall": 5.9,
        "per_core": [
          0.0,
          0.0,
          10.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          9.1,
          0.0,
          100.0,
          0.0,
          10.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0
        ],
        "logical_cores": 20,
        "physical_cores": 14
      },
      "unused_cores": {
        "unused_core_count": 0,
        "unused_core_indices": [],
        "threshold": 10
      },
      "memory": {
        "total_gb": 31.130718231201172,
        "used_gb": 8.479896545410156,
        "available_gb": 22.650821685791016,
        "percent_used": 27.2,
        "swap_total_gb": 3.9999961853027344,
        "swap_used_gb": 0.0,
        "swap_percent": 0.0
      }
    },
    "latency": {
      "inference": {
        "status": "no model registered"
      },
      "training_step": {
        "status": "no model available"
      },
      "data_pipeline": {
        "status": "no dataset provided"
      }
    },
    "framework_specific": {
      "version": "2.20.0",
      "built_with_cuda": true,
      "gpu_available": true,
      "eager_execution": true
    }
  },
  {
    "timestamp": "2026-03-01T12:27:49.990709",
    "gpu": {
      "utilization": {
        "0": 2
      },
      "memory": {
        "0": {
          "used_mb": 9623,
          "total_mb": 10240,
          "percentage": 93.974609375
        }
      },
      "temperature": {
        "0": 41
      },
      "power": {
        "0": {
          "draw_watts": 120.01,
          "limit_watts": 370.0,
          "percentage": 32.435135135135134
        }
      },
      "clock_speeds": {
        "0": {
          "graphics_mhz": 1905,
          "memory_mhz": 9251
        }
      },
      "pcie_throughput": {
        "0": {
          "link_gen": "4",
          "link_width": "8",
          "max_bandwidth_GBps": 15.76,
          "mem_controller_util": 1.6666666666666667,
          "estimated_usage_GBps": 0.26266666666666666
        }
      },
      "idle_time": 0,
      "is_currently_idle": true
    },
    "cpu": {
      "utilization": {
        "overall": 3.0,
        "per_core": [
          0.0,
          0.0,
          0.0,
          0.0,
          9.1,
          0.0,
          0.0,
          0.0,
          9.1,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          9.1,
          0.0,
          0.0,
          0.0,
          0.0
        ],
        "logical_cores": 20,
        "physical_cores": 14
      },
      "unused_cores": {
        "unused_core_count": 19,
        "unused_core_indices": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19
        ],
        "threshold": 10
      },
      "memory": {
        "total_gb": 31.130718231201172,
        "used_gb": 8.881336212158203,
        "available_gb": 22.24938201904297,
        "percent_used": 28.5,
        "swap_total_gb": 3.9999961853027344,
        "swap_used_gb": 0.0,
        "swap_percent": 0.0
      }
    },
    "latency": {
      "inference": {
        "batch_size": 1,
        "num_runs": 10,
        "avg_latency_ms": 23.636841773986816,
        "throughput_samples_per_sec": 42.3068364869513
      },
      "training_step": {
        "error": "in user code:\n\n    File \"/home/pwn/mloptimizer/app/common/GpuMetrics.py\", line 588, in train_step  *\n        loss = model.loss(y, y_pred)\n\n    TypeError: 'str' object is not callable\n"
      },
      "data_pipeline": {
        "status": "no dataset provided"
      }
    },
    "framework_specific": {
      "version": "2.20.0",
      "built_with_cuda": true,
      "gpu_available": true,
      "eager_execution": true
    }
  },
  {
    "timestamp": "2026-03-01T12:29:10.129833",
    "gpu": {
      "utilization": {
        "0": 1
      },
      "memory": {
        "0": {
          "used_mb": 9587,
          "total_mb": 10240,
          "percentage": 93.623046875
        }
      },
      "temperature": {
        "0": 43
      },
      "power": {
        "0": {
          "draw_watts": 126.95,
          "limit_watts": 370.0,
          "percentage": 34.31081081081081
        }
      },
      "clock_speeds": {
        "0": {
          "graphics_mhz": 1905,
          "memory_mhz": 9251
        }
      },
      "pcie_throughput": {
        "0": {
          "link_gen": "4",
          "link_width": "8",
          "max_bandwidth_GBps": 15.76,
          "mem_controller_util": 1.0,
          "estimated_usage_GBps": 0.1576
        }
      },
      "idle_time": 80.1392650604248,
      "is_currently_idle": true
    },
    "cpu": {
      "utilization": {
        "overall": 7.0,
        "per_core": [
          9.1,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          100.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0
        ],
        "logical_cores": 20,
        "physical_cores": 14
      },
      "unused_cores": {
        "unused_core_count": 19,
        "unused_core_indices": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19
        ],
        "threshold": 10
      },
      "memory": {
        "total_gb": 31.130718231201172,
        "used_gb": 12.424331665039062,
        "available_gb": 18.70638656616211,
        "percent_used": 39.9,
        "swap_total_gb": 3.9999961853027344,
        "swap_used_gb": 0.0,
        "swap_percent": 0.0
      }
    },
    "latency": {
      "inference": {
        "batch_size": 1,
        "num_runs": 10,
        "avg_latency_ms": 21.828365325927734,
        "throughput_samples_per_sec": 45.81195087532276
      },
      "training_step": {
        "error": "in user code:\n\n    File \"/home/pwn/mloptimizer/app/common/GpuMetrics.py\", line 588, in train_step  *\n        loss = model.loss(y, y_pred)\n\n    TypeError: 'str' object is not callable\n"
      },
      "data_pipeline": {
        "status": "no dataset provided"
      }
    },
    "framework_specific": {
      "version": "2.20.0",
      "built_with_cuda": true,
      "gpu_available": true,
      "eager_execution": true
    }
  },
  {
    "timestamp": "2026-03-01T12:29:12.993109",
    "gpu": {
      "utilization": {
        "0": 0
      },
      "memory": {
        "0": {
          "used_mb": 9606,
          "total_mb": 10240,
          "percentage": 93.80859375
        }
      },
      "temperature": {
        "0": 43
      },
      "power": {
        "0": {
          "draw_watts": 117.43,
          "limit_watts": 370.0,
          "percentage": 31.73783783783784
        }
      },
      "clock_speeds": {
        "0": {
          "graphics_mhz": 1905,
          "memory_mhz": 9251
        }
      },
      "pcie_throughput": {
        "0": {
          "link_gen": "4",
          "link_width": "8",
          "max_bandwidth_GBps": 15.76,
          "mem_controller_util": 1.0,
          "estimated_usage_GBps": 0.1576
        }
      },
      "idle_time": 83.00393843650818,
      "is_currently_idle": true
    },
    "cpu": {
      "utilization": {
        "overall": 5.0,
        "per_core": [
          9.1,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          18.2,
          0.0,
          33.3,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0
        ],
        "logical_cores": 20,
        "physical_cores": 14
      },
      "unused_cores": {
        "unused_core_count": 14,
        "unused_core_indices": [
          0,
          1,
          3,
          5,
          6,
          7,
          9,
          10,
          13,
          15,
          16,
          17,
          18,
          19
        ],
        "threshold": 10
      },
      "memory": {
        "total_gb": 31.130718231201172,
        "used_gb": 12.797355651855469,
        "available_gb": 18.333362579345703,
        "percent_used": 41.1,
        "swap_total_gb": 3.9999961853027344,
        "swap_used_gb": 0.0,
        "swap_percent": 0.0
      }
    },
    "latency": {
      "inference": {
        "batch_size": 1,
        "num_runs": 10,
        "avg_latency_ms": 21.25093936920166,
        "throughput_samples_per_sec": 47.05674335739104
      },
      "training_step": {
        "error": "in user code:\n\n    File \"/home/pwn/mloptimizer/app/common/GpuMetrics.py\", line 588, in train_step  *\n        loss = model.loss(y, y_pred)\n\n    TypeError: 'str' object is not callable\n"
      },
      "data_pipeline": {
        "status": "no dataset provided"
      }
    },
    "framework_specific": {
      "version": "2.20.0",
      "built_with_cuda": true,
      "gpu_available": true,
      "eager_execution": true
    }
  },
  {
    "timestamp": "2026-03-01T12:30:21.204245",
    "gpu": {
      "utilization": {
        "0": 1
      },
      "memory": {
        "0": {
          "used_mb": 9612,
          "total_mb": 10240,
          "percentage": 93.8671875
        }
      },
      "temperature": {
        "0": 44
      },
      "power": {
        "0": {
          "draw_watts": 131.15,
          "limit_watts": 370.0,
          "percentage": 35.445945945945944
        }
      },
      "clock_speeds": {
        "0": {
          "graphics_mhz": 1905,
          "memory_mhz": 9251
        }
      },
      "pcie_throughput": {
        "0": {
          "link_gen": "4",
          "link_width": "8",
          "max_bandwidth_GBps": 15.76,
          "mem_controller_util": 0.3333333333333333,
          "estimated_usage_GBps": 0.05253333333333333
        }
      },
      "idle_time": 151.21319794654846,
      "is_currently_idle": true
    },
    "cpu": {
      "utilization": {
        "overall": 6.0,
        "per_core": [
          0.0,
          0.0,
          0.0,
          0.0,
          10.0,
          0.0,
          9.1,
          0.0,
          100.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          10.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0
        ],
        "logical_cores": 20,
        "physical_cores": 14
      },
      "unused_cores": {
        "unused_core_count": 18,
        "unused_core_indices": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          9,
          10,
          11,
          12,
          14,
          15,
          16,
          17,
          18,
          19
        ],
        "threshold": 10
      },
      "memory": {
        "total_gb": 31.130718231201172,
        "used_gb": 12.741077423095703,
        "available_gb": 18.38964080810547,
        "percent_used": 40.9,
        "swap_total_gb": 3.9999961853027344,
        "swap_used_gb": 0.0,
        "swap_percent": 0.0
      }
    },
    "latency": {
      "inference": {
        "batch_size": 1,
        "num_runs": 10,
        "avg_latency_ms": 21.82900905609131,
        "throughput_samples_per_sec": 45.81059989624007
      },
      "training_step": {
        "error": "in user code:\n\n    File \"/home/pwn/mloptimizer/app/common/GpuMetrics.py\", line 588, in train_step  *\n        loss = model.loss(y, y_pred)\n\n    TypeError: 'str' object is not callable\n"
      },
      "data_pipeline": {
        "status": "no dataset provided"
      }
    },
    "framework_specific": {
      "version": "2.20.0",
      "built_with_cuda": true,
      "gpu_available": true,
      "eager_execution": true
    }
  },
  {
    "timestamp": "2026-03-01T12:30:24.048788",
    "gpu": {
      "utilization": {
        "0": 0
      },
      "memory": {
        "0": {
          "used_mb": 9612,
          "total_mb": 10240,
          "percentage": 93.8671875
        }
      },
      "temperature": {
        "0": 44
      },
      "power": {
        "0": {
          "draw_watts": 122.25,
          "limit_watts": 370.0,
          "percentage": 33.04054054054054
        }
      },
      "clock_speeds": {
        "0": {
          "graphics_mhz": 1905,
          "memory_mhz": 9251
        }
      },
      "pcie_throughput": {
        "0": {
          "link_gen": "4",
          "link_width": "8",
          "max_bandwidth_GBps": 15.76,
          "mem_controller_util": 0.6666666666666666,
          "estimated_usage_GBps": 0.10506666666666666
        }
      },
      "idle_time": 154.05945944786072,
      "is_currently_idle": true
    },
    "cpu": {
      "utilization": {
        "overall": 6.5,
        "per_core": [
          0.0,
          0.0,
          18.2,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          100.0,
          0.0,
          10.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          9.1,
          0.0
        ],
        "logical_cores": 20,
        "physical_cores": 14
      },
      "unused_cores": {
        "unused_core_count": 16,
        "unused_core_indices": [
          1,
          2,
          3,
          5,
          6,
          7,
          9,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19
        ],
        "threshold": 10
      },
      "memory": {
        "total_gb": 31.130718231201172,
        "used_gb": 12.748249053955078,
        "available_gb": 18.382469177246094,
        "percent_used": 41.0,
        "swap_total_gb": 3.9999961853027344,
        "swap_used_gb": 0.0,
        "swap_percent": 0.0
      }
    },
    "latency": {
      "inference": {
        "batch_size": 1,
        "num_runs": 10,
        "avg_latency_ms": 21.789884567260742,
        "throughput_samples_per_sec": 45.89285440742986
      },
      "training_step": {
        "error": "in user code:\n\n    File \"/home/pwn/mloptimizer/app/common/GpuMetrics.py\", line 588, in train_step  *\n        loss = model.loss(y, y_pred)\n\n    TypeError: 'str' object is not callable\n"
      },
      "data_pipeline": {
        "status": "no dataset provided"
      }
    },
    "framework_specific": {
      "version": "2.20.0",
      "built_with_cuda": true,
      "gpu_available": true,
      "eager_execution": true
    }
  },
  {
    "timestamp": "2026-03-01T12:31:33.197244",
    "gpu": {
      "utilization": {
        "0": 0
      },
      "memory": {
        "0": {
          "used_mb": 9667,
          "total_mb": 10240,
          "percentage": 94.404296875
        }
      },
      "temperature": {
        "0": 46
      },
      "power": {
        "0": {
          "draw_watts": 136.27,
          "limit_watts": 370.0,
          "percentage": 36.829729729729735
        }
      },
      "clock_speeds": {
        "0": {
          "graphics_mhz": 1905,
          "memory_mhz": 9251
        }
      },
      "pcie_throughput": {
        "0": {
          "link_gen": "4",
          "link_width": "8",
          "max_bandwidth_GBps": 15.76,
          "mem_controller_util": 1.6666666666666667,
          "estimated_usage_GBps": 0.26266666666666666
        }
      },
      "idle_time": 223.20747303962708,
      "is_currently_idle": true
    },
    "cpu": {
      "utilization": {
        "overall": 4.5,
        "per_core": [
          0.0,
          9.1,
          0.0,
          0.0,
          0.0,
          9.1,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0
        ],
        "logical_cores": 20,
        "physical_cores": 14
      },
      "unused_cores": {
        "unused_core_count": 20,
        "unused_core_indices": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19
        ],
        "threshold": 10
      },
      "memory": {
        "total_gb": 31.130718231201172,
        "used_gb": 12.815071105957031,
        "available_gb": 18.31564712524414,
        "percent_used": 41.2,
        "swap_total_gb": 3.9999961853027344,
        "swap_used_gb": 0.0,
        "swap_percent": 0.0
      }
    },
    "latency": {
      "inference": {
        "batch_size": 1,
        "num_runs": 10,
        "avg_latency_ms": 20.6712007522583,
        "throughput_samples_per_sec": 48.37648339759611
      },
      "training_step": {
        "error": "in user code:\n\n    File \"/home/pwn/mloptimizer/app/common/GpuMetrics.py\", line 588, in train_step  *\n        loss = model.loss(y, y_pred)\n\n    TypeError: 'str' object is not callable\n"
      },
      "data_pipeline": {
        "status": "no dataset provided"
      }
    },
    "framework_specific": {
      "version": "2.20.0",
      "built_with_cuda": true,
      "gpu_available": true,
      "eager_execution": true
    }
  },
  {
    "timestamp": "2026-03-01T12:31:36.025409",
    "gpu": {
      "utilization": {
        "0": 0
      },
      "memory": {
        "0": {
          "used_mb": 9662,
          "total_mb": 10240,
          "percentage": 94.35546875
        }
      },
      "temperature": {
        "0": 45
      },
      "power": {
        "0": {
          "draw_watts": 121.24,
          "limit_watts": 370.0,
          "percentage": 32.76756756756757
        }
      },
      "clock_speeds": {
        "0": {
          "graphics_mhz": 1905,
          "memory_mhz": 9251
        }
      },
      "pcie_throughput": {
        "0": {
          "link_gen": "4",
          "link_width": "8",
          "max_bandwidth_GBps": 15.76,
          "mem_controller_util": 1.0,
          "estimated_usage_GBps": 0.1576
        }
      },
      "idle_time": 226.0360233783722,
      "is_currently_idle": true
    },
    "cpu": {
      "utilization": {
        "overall": 4.5,
        "per_core": [
          0.0,
          0.0,
          9.1,
          0.0,
          9.1,
          0.0,
          9.1,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          18.2,
          0.0,
          0.0,
          0.0
        ],
        "logical_cores": 20,
        "physical_cores": 14
      },
      "unused_cores": {
        "unused_core_count": 19,
        "unused_core_indices": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19
        ],
        "threshold": 10
      },
      "memory": {
        "total_gb": 31.130718231201172,
        "used_gb": 12.862598419189453,
        "available_gb": 18.26811981201172,
        "percent_used": 41.3,
        "swap_total_gb": 3.9999961853027344,
        "swap_used_gb": 0.0,
        "swap_percent": 0.0
      }
    },
    "latency": {
      "inference": {
        "batch_size": 1,
        "num_runs": 10,
        "avg_latency_ms": 21.698451042175293,
        "throughput_samples_per_sec": 46.086238969606605
      },
      "training_step": {
        "error": "in user code:\n\n    File \"/home/pwn/mloptimizer/app/common/GpuMetrics.py\", line 588, in train_step  *\n        loss = model.loss(y, y_pred)\n\n    TypeError: 'str' object is not callable\n"
      },
      "data_pipeline": {
        "status": "no dataset provided"
      }
    },
    "framework_specific": {
      "version": "2.20.0",
      "built_with_cuda": true,
      "gpu_available": true,
      "eager_execution": true
    }
  },
  {
    "timestamp": "2026-03-01T12:32:41.697023",
    "gpu": {
      "utilization": {
        "0": 1
      },
      "memory": {
        "0": {
          "used_mb": 9625,
          "total_mb": 10240,
          "percentage": 93.994140625
        }
      },
      "temperature": {
        "0": 46
      },
      "power": {
        "0": {
          "draw_watts": 134.04,
          "limit_watts": 370.0,
          "percentage": 36.22702702702703
        }
      },
      "clock_speeds": {
        "0": {
          "graphics_mhz": 1905,
          "memory_mhz": 9251
        }
      },
      "pcie_throughput": {
        "0": {
          "link_gen": "4",
          "link_width": "8",
          "max_bandwidth_GBps": 15.76,
          "mem_controller_util": 1.0,
          "estimated_usage_GBps": 0.1576
        }
      },
      "idle_time": 291.7057993412018,
      "is_currently_idle": true
    },
    "cpu": {
      "utilization": {
        "overall": 0.5,
        "per_core": [
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          9.1,
          0.0,
          0.0,
          0.0,
          0.0
        ],
        "logical_cores": 20,
        "physical_cores": 14
      },
      "unused_cores": {
        "unused_core_count": 20,
        "unused_core_indices": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19
        ],
        "threshold": 10
      },
      "memory": {
        "total_gb": 31.130718231201172,
        "used_gb": 13.019058227539062,
        "available_gb": 18.11166000366211,
        "percent_used": 41.8,
        "swap_total_gb": 3.9999961853027344,
        "swap_used_gb": 0.0,
        "swap_percent": 0.0
      }
    },
    "latency": {
      "inference": {
        "batch_size": 1,
        "num_runs": 10,
        "avg_latency_ms": 20.599079132080078,
        "throughput_samples_per_sec": 48.54585943323287
      },
      "training_step": {
        "error": "in user code:\n\n    File \"/home/pwn/mloptimizer/app/common/GpuMetrics.py\", line 588, in train_step  *\n        loss = model.loss(y, y_pred)\n\n    TypeError: 'str' object is not callable\n"
      },
      "data_pipeline": {
        "status": "no dataset provided"
      }
    },
    "framework_specific": {
      "version": "2.20.0",
      "built_with_cuda": true,
      "gpu_available": true,
      "eager_execution": true
    }
  },
  {
    "timestamp": "2026-03-01T12:32:44.521754",
    "gpu": {
      "utilization": {
        "0": 0
      },
      "memory": {
        "0": {
          "used_mb": 9625,
          "total_mb": 10240,
          "percentage": 93.994140625
        }
      },
      "temperature": {
        "0": 46
      },
      "power": {
        "0": {
          "draw_watts": 119.76,
          "limit_watts": 370.0,
          "percentage": 32.36756756756757
        }
      },
      "clock_speeds": {
        "0": {
          "graphics_mhz": 1905,
          "memory_mhz": 9251
        }
      },
      "pcie_throughput": {
        "0": {
          "link_gen": "4",
          "link_width": "8",
          "max_bandwidth_GBps": 15.76,
          "mem_controller_util": 1.0,
          "estimated_usage_GBps": 0.1576
        }
      },
      "idle_time": 294.531690120697,
      "is_currently_idle": true
    },
    "cpu": {
      "utilization": {
        "overall": 1.0,
        "per_core": [
          9.1,
          0.0,
          0.0,
          0.0,
          9.1,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          10.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0
        ],
        "logical_cores": 20,
        "physical_cores": 14
      },
      "unused_cores": {
        "unused_core_count": 20,
        "unused_core_indices": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19
        ],
        "threshold": 10
      },
      "memory": {
        "total_gb": 31.130718231201172,
        "used_gb": 13.113845825195312,
        "available_gb": 18.01687240600586,
        "percent_used": 42.1,
        "swap_total_gb": 3.9999961853027344,
        "swap_used_gb": 0.0,
        "swap_percent": 0.0
      }
    },
    "latency": {
      "inference": {
        "batch_size": 1,
        "num_runs": 10,
        "avg_latency_ms": 20.510149002075195,
        "throughput_samples_per_sec": 48.756349839234275
      },
      "training_step": {
        "error": "in user code:\n\n    File \"/home/pwn/mloptimizer/app/common/GpuMetrics.py\", line 588, in train_step  *\n        loss = model.loss(y, y_pred)\n\n    TypeError: 'str' object is not callable\n"
      },
      "data_pipeline": {
        "status": "no dataset provided"
      }
    },
    "framework_specific": {
      "version": "2.20.0",
      "built_with_cuda": true,
      "gpu_available": true,
      "eager_execution": true
    }
  },
  {
    "timestamp": "2026-03-01T12:33:48.594950",
    "gpu": {
      "utilization": {
        "0": 1
      },
      "memory": {
        "0": {
          "used_mb": 9664,
          "total_mb": 10240,
          "percentage": 94.375
        }
      },
      "temperature": {
        "0": 46
      },
      "power": {
        "0": {
          "draw_watts": 134.13,
          "limit_watts": 370.0,
          "percentage": 36.25135135135135
        }
      },
      "clock_speeds": {
        "0": {
          "graphics_mhz": 1905,
          "memory_mhz": 9251
        }
      },
      "pcie_throughput": {
        "0": {
          "link_gen": "4",
          "link_width": "8",
          "max_bandwidth_GBps": 15.76,
          "mem_controller_util": 0.6666666666666666,
          "estimated_usage_GBps": 0.10506666666666666
        }
      },
      "idle_time": 358.60396218299866,
      "is_currently_idle": true
    },
    "cpu": {
      "utilization": {
        "overall": 2.5,
        "per_core": [
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          9.1,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0
        ],
        "logical_cores": 20,
        "physical_cores": 14
      },
      "unused_cores": {
        "unused_core_count": 18,
        "unused_core_indices": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          10,
          11,
          12,
          14,
          15,
          16,
          17,
          18,
          19
        ],
        "threshold": 10
      },
      "memory": {
        "total_gb": 31.130718231201172,
        "used_gb": 13.08349609375,
        "available_gb": 18.047222137451172,
        "percent_used": 42.0,
        "swap_total_gb": 3.9999961853027344,
        "swap_used_gb": 0.0,
        "swap_percent": 0.0
      }
    },
    "latency": {
      "inference": {
        "batch_size": 1,
        "num_runs": 10,
        "avg_latency_ms": 21.147871017456055,
        "throughput_samples_per_sec": 47.286083746896864
      },
      "training_step": {
        "error": "in user code:\n\n    File \"/home/pwn/mloptimizer/app/common/GpuMetrics.py\", line 588, in train_step  *\n        loss = model.loss(y, y_pred)\n\n    TypeError: 'str' object is not callable\n"
      },
      "data_pipeline": {
        "status": "no dataset provided"
      }
    },
    "framework_specific": {
      "version": "2.20.0",
      "built_with_cuda": true,
      "gpu_available": true,
      "eager_execution": true
    }
  }
]