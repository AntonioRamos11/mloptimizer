[
  {
    "timestamp": "2025-12-02T12:28:59.603734",
    "gpu": {
      "utilization": {
        "0": 16
      },
      "memory": {
        "0": {
          "used_mb": 9607,
          "total_mb": 10240,
          "percentage": 93.818359375
        }
      },
      "temperature": {
        "0": 43
      },
      "power": {
        "0": {
          "draw_watts": 136.34,
          "limit_watts": 370.0,
          "percentage": 36.84864864864865
        }
      },
      "clock_speeds": {
        "0": {
          "graphics_mhz": 1905,
          "memory_mhz": 9251
        }
      },
      "pcie_throughput": {
        "0": {
          "link_gen": "4",
          "link_width": "8",
          "max_bandwidth_GBps": 15.76,
          "mem_controller_util": 3.6666666666666665,
          "estimated_usage_GBps": 0.5778666666666666
        }
      },
      "idle_time": 0,
      "is_currently_idle": false
    },
    "cpu": {
      "utilization": {
        "overall": 6.5,
        "per_core": [
          10.0,
          16.7,
          27.3,
          0.0,
          10.0,
          0.0,
          0.0,
          0.0,
          88.9,
          0.0,
          11.1,
          0.0,
          10.0,
          18.2,
          9.1,
          10.0,
          16.7,
          9.1,
          10.0,
          10.0
        ],
        "logical_cores": 20,
        "physical_cores": 14
      },
      "unused_cores": {
        "unused_core_count": 10,
        "unused_core_indices": [
          0,
          1,
          3,
          5,
          7,
          9,
          11,
          13,
          18,
          19
        ],
        "threshold": 10
      },
      "memory": {
        "total_gb": 31.136207580566406,
        "used_gb": 10.146903991699219,
        "available_gb": 20.29815673828125,
        "percent_used": 34.8,
        "swap_total_gb": 0.9540977478027344,
        "swap_used_gb": 0.0,
        "swap_percent": 0.0
      }
    },
    "latency": {
      "inference": {
        "status": "no model registered"
      },
      "training_step": {
        "status": "no model available"
      },
      "data_pipeline": {
        "status": "no dataset provided"
      }
    },
    "framework_specific": {
      "version": "2.17.0",
      "built_with_cuda": true,
      "gpu_available": true,
      "eager_execution": true
    }
  },
  {
    "timestamp": "2025-12-02T12:29:04.258456",
    "gpu": {
      "utilization": {
        "0": 10
      },
      "memory": {
        "0": {
          "used_mb": 9615,
          "total_mb": 10240,
          "percentage": 93.896484375
        }
      },
      "temperature": {
        "0": 43
      },
      "power": {
        "0": {
          "draw_watts": 127.7,
          "limit_watts": 370.0,
          "percentage": 34.513513513513516
        }
      },
      "clock_speeds": {
        "0": {
          "graphics_mhz": 1905,
          "memory_mhz": 9251
        }
      },
      "pcie_throughput": {
        "0": {
          "link_gen": "4",
          "link_width": "8",
          "max_bandwidth_GBps": 15.76,
          "mem_controller_util": 2.6666666666666665,
          "estimated_usage_GBps": 0.4202666666666666
        }
      },
      "idle_time": 0,
      "is_currently_idle": false
    },
    "cpu": {
      "utilization": {
        "overall": 6.5,
        "per_core": [
          10.0,
          9.1,
          0.0,
          0.0,
          10.0,
          0.0,
          0.0,
          0.0,
          10.0,
          0.0,
          27.3,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0
        ],
        "logical_cores": 20,
        "physical_cores": 14
      },
      "unused_cores": {
        "unused_core_count": 14,
        "unused_core_indices": [
          1,
          3,
          5,
          7,
          9,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19
        ],
        "threshold": 10
      },
      "memory": {
        "total_gb": 31.136207580566406,
        "used_gb": 10.106563568115234,
        "available_gb": 20.336978912353516,
        "percent_used": 34.7,
        "swap_total_gb": 0.9540977478027344,
        "swap_used_gb": 0.0,
        "swap_percent": 0.0
      }
    },
    "latency": {
      "inference": {
        "batch_size": 1,
        "num_runs": 10,
        "avg_latency_ms": 22.37064838409424,
        "throughput_samples_per_sec": 44.70143121604872
      },
      "training_step": {
        "error": "in user code:\n\n    File \"/home/p0wden/Documents/mloptimizer/app/common/GpuMetrics.py\", line 588, in train_step  *\n        loss = model.loss(y, y_pred)\n\n    TypeError: 'str' object is not callable\n"
      },
      "data_pipeline": {
        "status": "no dataset provided"
      }
    },
    "framework_specific": {
      "version": "2.17.0",
      "built_with_cuda": true,
      "gpu_available": true,
      "eager_execution": true
    }
  },
  {
    "timestamp": "2025-12-02T12:32:04.655470",
    "gpu": {
      "utilization": {
        "0": 36
      },
      "memory": {
        "0": {
          "used_mb": 9719,
          "total_mb": 10240,
          "percentage": 94.912109375
        }
      },
      "temperature": {
        "0": 45
      },
      "power": {
        "0": {
          "draw_watts": 133.3,
          "limit_watts": 370.0,
          "percentage": 36.02702702702703
        }
      },
      "clock_speeds": {
        "0": {
          "graphics_mhz": 1965,
          "memory_mhz": 9251
        }
      },
      "pcie_throughput": {
        "0": {
          "link_gen": "4",
          "link_width": "8",
          "max_bandwidth_GBps": 15.76,
          "mem_controller_util": 3.0,
          "estimated_usage_GBps": 0.4728
        }
      },
      "idle_time": 0,
      "is_currently_idle": false
    },
    "cpu": {
      "utilization": {
        "overall": 22.5,
        "per_core": [
          33.3,
          9.1,
          22.2,
          0.0,
          33.3,
          0.0,
          44.4,
          0.0,
          90.9,
          0.0,
          80.0,
          0.0,
          22.2,
          22.2,
          18.2,
          0.0,
          10.0,
          0.0,
          0.0,
          0.0
        ],
        "logical_cores": 20,
        "physical_cores": 14
      },
      "unused_cores": {
        "unused_core_count": 3,
        "unused_core_indices": [
          5,
          11,
          18
        ],
        "threshold": 10
      },
      "memory": {
        "total_gb": 31.136207580566406,
        "used_gb": 11.634174346923828,
        "available_gb": 18.798648834228516,
        "percent_used": 39.6,
        "swap_total_gb": 0.9540977478027344,
        "swap_used_gb": 0.0,
        "swap_percent": 0.0
      }
    },
    "latency": {
      "inference": {
        "batch_size": 1,
        "num_runs": 10,
        "avg_latency_ms": 23.804664611816406,
        "throughput_samples_per_sec": 42.00857337446416
      },
      "training_step": {
        "error": "in user code:\n\n    File \"/home/p0wden/Documents/mloptimizer/app/common/GpuMetrics.py\", line 588, in train_step  *\n        loss = model.loss(y, y_pred)\n\n    TypeError: 'str' object is not callable\n"
      },
      "data_pipeline": {
        "status": "no dataset provided"
      }
    },
    "framework_specific": {
      "version": "2.17.0",
      "built_with_cuda": true,
      "gpu_available": true,
      "eager_execution": true
    }
  },
  {
    "timestamp": "2025-12-02T12:32:07.588209",
    "gpu": {
      "utilization": {
        "0": 8
      },
      "memory": {
        "0": {
          "used_mb": 9788,
          "total_mb": 10240,
          "percentage": 95.5859375
        }
      },
      "temperature": {
        "0": 44
      },
      "power": {
        "0": {
          "draw_watts": 124.45,
          "limit_watts": 370.0,
          "percentage": 33.63513513513514
        }
      },
      "clock_speeds": {
        "0": {
          "graphics_mhz": 1905,
          "memory_mhz": 9251
        }
      },
      "pcie_throughput": {
        "0": {
          "link_gen": "4",
          "link_width": "8",
          "max_bandwidth_GBps": 15.76,
          "mem_controller_util": 2.0,
          "estimated_usage_GBps": 0.3152
        }
      },
      "idle_time": 0,
      "is_currently_idle": false
    },
    "cpu": {
      "utilization": {
        "overall": 1.5,
        "per_core": [
          10.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0
        ],
        "logical_cores": 20,
        "physical_cores": 14
      },
      "unused_cores": {
        "unused_core_count": 16,
        "unused_core_indices": [
          0,
          1,
          3,
          4,
          5,
          7,
          9,
          10,
          11,
          12,
          13,
          15,
          16,
          17,
          18,
          19
        ],
        "threshold": 10
      },
      "memory": {
        "total_gb": 31.136207580566406,
        "used_gb": 11.609752655029297,
        "available_gb": 18.82372283935547,
        "percent_used": 39.5,
        "swap_total_gb": 0.9540977478027344,
        "swap_used_gb": 0.0,
        "swap_percent": 0.0
      }
    },
    "latency": {
      "inference": {
        "batch_size": 1,
        "num_runs": 10,
        "avg_latency_ms": 19.990944862365723,
        "throughput_samples_per_sec": 50.022648098168
      },
      "training_step": {
        "error": "in user code:\n\n    File \"/home/p0wden/Documents/mloptimizer/app/common/GpuMetrics.py\", line 588, in train_step  *\n        loss = model.loss(y, y_pred)\n\n    TypeError: 'str' object is not callable\n"
      },
      "data_pipeline": {
        "status": "no dataset provided"
      }
    },
    "framework_specific": {
      "version": "2.17.0",
      "built_with_cuda": true,
      "gpu_available": true,
      "eager_execution": true
    }
  },
  {
    "timestamp": "2025-12-02T12:34:57.453597",
    "gpu": {
      "utilization": {
        "0": 37
      },
      "memory": {
        "0": {
          "used_mb": 9735,
          "total_mb": 10240,
          "percentage": 95.068359375
        }
      },
      "temperature": {
        "0": 44
      },
      "power": {
        "0": {
          "draw_watts": 124.7,
          "limit_watts": 370.0,
          "percentage": 33.7027027027027
        }
      },
      "clock_speeds": {
        "0": {
          "graphics_mhz": 1905,
          "memory_mhz": 9251
        }
      },
      "pcie_throughput": {
        "0": {
          "link_gen": "4",
          "link_width": "8",
          "max_bandwidth_GBps": 15.76,
          "mem_controller_util": 1.0,
          "estimated_usage_GBps": 0.1576
        }
      },
      "idle_time": 0,
      "is_currently_idle": false
    },
    "cpu": {
      "utilization": {
        "overall": 3.0,
        "per_core": [
          20.0,
          0.0,
          40.0,
          0.0,
          33.3,
          0.0,
          36.4,
          0.0,
          55.6,
          0.0,
          33.3,
          0.0,
          36.4,
          10.0,
          0.0,
          10.0,
          9.1,
          30.0,
          10.0,
          10.0
        ],
        "logical_cores": 20,
        "physical_cores": 14
      },
      "unused_cores": {
        "unused_core_count": 20,
        "unused_core_indices": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19
        ],
        "threshold": 10
      },
      "memory": {
        "total_gb": 31.136207580566406,
        "used_gb": 11.408096313476562,
        "available_gb": 19.023658752441406,
        "percent_used": 38.9,
        "swap_total_gb": 0.9540977478027344,
        "swap_used_gb": 0.0,
        "swap_percent": 0.0
      }
    },
    "latency": {
      "inference": {
        "batch_size": 1,
        "num_runs": 10,
        "avg_latency_ms": 19.02782917022705,
        "throughput_samples_per_sec": 52.5546025799257
      },
      "training_step": {
        "error": "in user code:\n\n    File \"/home/p0wden/Documents/mloptimizer/app/common/GpuMetrics.py\", line 588, in train_step  *\n        loss = model.loss(y, y_pred)\n\n    TypeError: 'str' object is not callable\n"
      },
      "data_pipeline": {
        "status": "no dataset provided"
      }
    },
    "framework_specific": {
      "version": "2.17.0",
      "built_with_cuda": true,
      "gpu_available": true,
      "eager_execution": true
    }
  }
]