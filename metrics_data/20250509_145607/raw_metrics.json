[
  {
    "timestamp": "2025-05-09T14:50:27.785619",
    "gpu": {
      "utilization": {
        "0": 17
      },
      "memory": {
        "0": {
          "used_mb": 9769,
          "total_mb": 10240,
          "percentage": 95.400390625
        }
      },
      "temperature": {
        "0": 51
      },
      "power": {
        "0": {
          "draw_watts": 149.84,
          "limit_watts": 370.0,
          "percentage": 40.497297297297294
        }
      },
      "clock_speeds": {
        "0": {
          "graphics_mhz": 1950,
          "memory_mhz": 9251
        }
      },
      "pcie_throughput": {
        "0": {
          "link_gen": "4",
          "link_width": "8",
          "max_bandwidth_GBps": 15.76,
          "mem_controller_util": 2.3333333333333335,
          "estimated_usage_GBps": 0.36773333333333336
        }
      },
      "idle_time": 0,
      "is_currently_idle": false
    },
    "cpu": {
      "utilization": {
        "overall": 14.2,
        "per_core": [
          18.2,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          10.0,
          0.0,
          100.0,
          0.0,
          11.1,
          0.0,
          10.0,
          10.0,
          9.1,
          10.0,
          9.1,
          10.0,
          0.0,
          0.0
        ],
        "logical_cores": 20,
        "physical_cores": 14
      },
      "unused_cores": {
        "unused_core_count": 18,
        "unused_core_indices": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          9,
          10,
          11,
          12,
          13,
          15,
          16,
          17,
          18,
          19
        ],
        "threshold": 10
      },
      "memory": {
        "total_gb": 31.13628387451172,
        "used_gb": 10.507862091064453,
        "available_gb": 19.726768493652344,
        "percent_used": 36.6,
        "swap_total_gb": 0.9540977478027344,
        "swap_used_gb": 0.5591354370117188,
        "swap_percent": 58.6
      }
    },
    "latency": {
      "inference": {
        "status": "no model registered"
      },
      "training_step": {
        "status": "no model available"
      },
      "data_pipeline": {
        "status": "no dataset provided"
      }
    },
    "framework_specific": {
      "version": "2.19.0",
      "built_with_cuda": true,
      "gpu_available": true,
      "eager_execution": true
    }
  },
  {
    "timestamp": "2025-05-09T14:50:32.008570",
    "gpu": {
      "utilization": {
        "0": 66
      },
      "memory": {
        "0": {
          "used_mb": 9794,
          "total_mb": 10240,
          "percentage": 95.64453125
        }
      },
      "temperature": {
        "0": 51
      },
      "power": {
        "0": {
          "draw_watts": 139.13,
          "limit_watts": 370.0,
          "percentage": 37.6027027027027
        }
      },
      "clock_speeds": {
        "0": {
          "graphics_mhz": 1950,
          "memory_mhz": 9251
        }
      },
      "pcie_throughput": {
        "0": {
          "link_gen": "4",
          "link_width": "8",
          "max_bandwidth_GBps": 15.76,
          "mem_controller_util": 2.3333333333333335,
          "estimated_usage_GBps": 0.36773333333333336
        }
      },
      "idle_time": 0,
      "is_currently_idle": false
    },
    "cpu": {
      "utilization": {
        "overall": 7.4,
        "per_core": [
          10.0,
          0.0,
          10.0,
          0.0,
          0.0,
          0.0,
          10.0,
          0.0,
          100.0,
          0.0,
          18.2,
          0.0,
          18.2,
          0.0,
          9.1,
          0.0,
          0.0,
          0.0,
          0.0,
          9.1
        ],
        "logical_cores": 20,
        "physical_cores": 14
      },
      "unused_cores": {
        "unused_core_count": 15,
        "unused_core_indices": [
          0,
          1,
          3,
          5,
          7,
          9,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19
        ],
        "threshold": 10
      },
      "memory": {
        "total_gb": 31.13628387451172,
        "used_gb": 10.524276733398438,
        "available_gb": 19.705764770507812,
        "percent_used": 36.7,
        "swap_total_gb": 0.9540977478027344,
        "swap_used_gb": 0.5591354370117188,
        "swap_percent": 58.6
      }
    },
    "latency": {
      "inference": {
        "batch_size": 1,
        "num_runs": 10,
        "avg_latency_ms": 19.89290714263916,
        "throughput_samples_per_sec": 50.26917347120998
      },
      "training_step": {
        "error": "in user code:\n\n    File \"/home/p0wden/Downloads/mloptimizer/app/common/GpuMetrics.py\", line 588, in train_step  *\n        loss = model.loss(y, y_pred)\n\n    TypeError: 'str' object is not callable\n"
      },
      "data_pipeline": {
        "status": "no dataset provided"
      }
    },
    "framework_specific": {
      "version": "2.19.0",
      "built_with_cuda": true,
      "gpu_available": true,
      "eager_execution": true
    }
  },
  {
    "timestamp": "2025-05-09T14:51:13.510606",
    "gpu": {
      "utilization": {
        "0": 31
      },
      "memory": {
        "0": {
          "used_mb": 9921,
          "total_mb": 10240,
          "percentage": 96.884765625
        }
      },
      "temperature": {
        "0": 51
      },
      "power": {
        "0": {
          "draw_watts": 189.62,
          "limit_watts": 370.0,
          "percentage": 51.248648648648654
        }
      },
      "clock_speeds": {
        "0": {
          "graphics_mhz": 1950,
          "memory_mhz": 9251
        }
      },
      "pcie_throughput": {
        "0": {
          "link_gen": "4",
          "link_width": "8",
          "max_bandwidth_GBps": 15.76,
          "mem_controller_util": 1.0,
          "estimated_usage_GBps": 0.1576
        }
      },
      "idle_time": 0,
      "is_currently_idle": false
    },
    "cpu": {
      "utilization": {
        "overall": 7.6,
        "per_core": [
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          100.0,
          0.0,
          33.3,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          10.0,
          0.0,
          0.0
        ],
        "logical_cores": 20,
        "physical_cores": 14
      },
      "unused_cores": {
        "unused_core_count": 12,
        "unused_core_indices": [
          0,
          1,
          3,
          5,
          7,
          9,
          11,
          13,
          14,
          16,
          17,
          18
        ],
        "threshold": 10
      },
      "memory": {
        "total_gb": 31.13628387451172,
        "used_gb": 11.812171936035156,
        "available_gb": 18.430622100830078,
        "percent_used": 40.8,
        "swap_total_gb": 0.9540977478027344,
        "swap_used_gb": 0.5591278076171875,
        "swap_percent": 58.6
      }
    },
    "latency": {
      "inference": {
        "batch_size": 1,
        "num_runs": 10,
        "avg_latency_ms": 20.522475242614746,
        "throughput_samples_per_sec": 48.72706572565421
      },
      "training_step": {
        "error": "in user code:\n\n    File \"/home/p0wden/Downloads/mloptimizer/app/common/GpuMetrics.py\", line 588, in train_step  *\n        loss = model.loss(y, y_pred)\n\n    TypeError: 'str' object is not callable\n"
      },
      "data_pipeline": {
        "status": "no dataset provided"
      }
    },
    "framework_specific": {
      "version": "2.19.0",
      "built_with_cuda": true,
      "gpu_available": true,
      "eager_execution": true
    }
  },
  {
    "timestamp": "2025-05-09T14:51:16.411092",
    "gpu": {
      "utilization": {
        "0": 17
      },
      "memory": {
        "0": {
          "used_mb": 9925,
          "total_mb": 10240,
          "percentage": 96.923828125
        }
      },
      "temperature": {
        "0": 50
      },
      "power": {
        "0": {
          "draw_watts": 126.77,
          "limit_watts": 370.0,
          "percentage": 34.26216216216216
        }
      },
      "clock_speeds": {
        "0": {
          "graphics_mhz": 1905,
          "memory_mhz": 9251
        }
      },
      "pcie_throughput": {
        "0": {
          "link_gen": "4",
          "link_width": "8",
          "max_bandwidth_GBps": 15.76,
          "mem_controller_util": 1.6666666666666667,
          "estimated_usage_GBps": 0.26266666666666666
        }
      },
      "idle_time": 0,
      "is_currently_idle": false
    },
    "cpu": {
      "utilization": {
        "overall": 10.7,
        "per_core": [
          0.0,
          0.0,
          10.0,
          0.0,
          27.3,
          0.0,
          10.0,
          0.0,
          100.0,
          0.0,
          9.1,
          0.0,
          0.0,
          0.0,
          0.0,
          9.1,
          20.0,
          10.0,
          0.0,
          0.0
        ],
        "logical_cores": 20,
        "physical_cores": 14
      },
      "unused_cores": {
        "unused_core_count": 16,
        "unused_core_indices": [
          0,
          1,
          2,
          3,
          5,
          6,
          7,
          9,
          11,
          12,
          13,
          14,
          16,
          17,
          18,
          19
        ],
        "threshold": 10
      },
      "memory": {
        "total_gb": 31.13628387451172,
        "used_gb": 11.777427673339844,
        "available_gb": 18.465370178222656,
        "percent_used": 40.7,
        "swap_total_gb": 0.9540977478027344,
        "swap_used_gb": 0.5591278076171875,
        "swap_percent": 58.6
      }
    },
    "latency": {
      "inference": {
        "batch_size": 1,
        "num_runs": 10,
        "avg_latency_ms": 21.15011215209961,
        "throughput_samples_per_sec": 47.281073159733964
      },
      "training_step": {
        "error": "in user code:\n\n    File \"/home/p0wden/Downloads/mloptimizer/app/common/GpuMetrics.py\", line 588, in train_step  *\n        loss = model.loss(y, y_pred)\n\n    TypeError: 'str' object is not callable\n"
      },
      "data_pipeline": {
        "status": "no dataset provided"
      }
    },
    "framework_specific": {
      "version": "2.19.0",
      "built_with_cuda": true,
      "gpu_available": true,
      "eager_execution": true
    }
  },
  {
    "timestamp": "2025-05-09T14:51:52.766764",
    "gpu": {
      "utilization": {
        "0": 5
      },
      "memory": {
        "0": {
          "used_mb": 9921,
          "total_mb": 10240,
          "percentage": 96.884765625
        }
      },
      "temperature": {
        "0": 51
      },
      "power": {
        "0": {
          "draw_watts": 200.7,
          "limit_watts": 370.0,
          "percentage": 54.24324324324324
        }
      },
      "clock_speeds": {
        "0": {
          "graphics_mhz": 1950,
          "memory_mhz": 9251
        }
      },
      "pcie_throughput": {
        "0": {
          "link_gen": "4",
          "link_width": "8",
          "max_bandwidth_GBps": 15.76,
          "mem_controller_util": 0.3333333333333333,
          "estimated_usage_GBps": 0.05253333333333333
        }
      },
      "idle_time": 0,
      "is_currently_idle": false
    },
    "cpu": {
      "utilization": {
        "overall": 6.5,
        "per_core": [
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          100.0,
          0.0,
          20.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0
        ],
        "logical_cores": 20,
        "physical_cores": 14
      },
      "unused_cores": {
        "unused_core_count": 19,
        "unused_core_indices": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19
        ],
        "threshold": 10
      },
      "memory": {
        "total_gb": 31.13628387451172,
        "used_gb": 12.180225372314453,
        "available_gb": 18.068992614746094,
        "percent_used": 42.0,
        "swap_total_gb": 0.9540977478027344,
        "swap_used_gb": 0.5591163635253906,
        "swap_percent": 58.6
      }
    },
    "latency": {
      "inference": {
        "batch_size": 1,
        "num_runs": 10,
        "avg_latency_ms": 19.269227981567383,
        "throughput_samples_per_sec": 51.89621509261207
      },
      "training_step": {
        "error": "in user code:\n\n    File \"/home/p0wden/Downloads/mloptimizer/app/common/GpuMetrics.py\", line 588, in train_step  *\n        loss = model.loss(y, y_pred)\n\n    TypeError: 'str' object is not callable\n"
      },
      "data_pipeline": {
        "status": "no dataset provided"
      }
    },
    "framework_specific": {
      "version": "2.19.0",
      "built_with_cuda": true,
      "gpu_available": true,
      "eager_execution": true
    }
  },
  {
    "timestamp": "2025-05-09T14:51:55.530141",
    "gpu": {
      "utilization": {
        "0": 3
      },
      "memory": {
        "0": {
          "used_mb": 9917,
          "total_mb": 10240,
          "percentage": 96.845703125
        }
      },
      "temperature": {
        "0": 50
      },
      "power": {
        "0": {
          "draw_watts": 127.59,
          "limit_watts": 370.0,
          "percentage": 34.483783783783785
        }
      },
      "clock_speeds": {
        "0": {
          "graphics_mhz": 1905,
          "memory_mhz": 9251
        }
      },
      "pcie_throughput": {
        "0": {
          "link_gen": "4",
          "link_width": "8",
          "max_bandwidth_GBps": 15.76,
          "mem_controller_util": 0.6666666666666666,
          "estimated_usage_GBps": 0.10506666666666666
        }
      },
      "idle_time": 0,
      "is_currently_idle": true
    },
    "cpu": {
      "utilization": {
        "overall": 6.0,
        "per_core": [
          9.1,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          16.7,
          0.0,
          100.0,
          0.0,
          10.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          10.0,
          0.0,
          9.1,
          0.0
        ],
        "logical_cores": 20,
        "physical_cores": 14
      },
      "unused_cores": {
        "unused_core_count": 11,
        "unused_core_indices": [
          1,
          3,
          5,
          7,
          9,
          11,
          12,
          13,
          16,
          18,
          19
        ],
        "threshold": 10
      },
      "memory": {
        "total_gb": 31.13628387451172,
        "used_gb": 12.208610534667969,
        "available_gb": 18.040607452392578,
        "percent_used": 42.1,
        "swap_total_gb": 0.9540977478027344,
        "swap_used_gb": 0.5591163635253906,
        "swap_percent": 58.6
      }
    },
    "latency": {
      "inference": {
        "batch_size": 1,
        "num_runs": 10,
        "avg_latency_ms": 19.872021675109863,
        "throughput_samples_per_sec": 50.32200630359223
      },
      "training_step": {
        "error": "in user code:\n\n    File \"/home/p0wden/Downloads/mloptimizer/app/common/GpuMetrics.py\", line 588, in train_step  *\n        loss = model.loss(y, y_pred)\n\n    TypeError: 'str' object is not callable\n"
      },
      "data_pipeline": {
        "status": "no dataset provided"
      }
    },
    "framework_specific": {
      "version": "2.19.0",
      "built_with_cuda": true,
      "gpu_available": true,
      "eager_execution": true
    }
  },
  {
    "timestamp": "2025-05-09T14:52:33.030990",
    "gpu": {
      "utilization": {
        "0": 68
      },
      "memory": {
        "0": {
          "used_mb": 9905,
          "total_mb": 10240,
          "percentage": 96.728515625
        }
      },
      "temperature": {
        "0": 52
      },
      "power": {
        "0": {
          "draw_watts": 180.38,
          "limit_watts": 370.0,
          "percentage": 48.75135135135135
        }
      },
      "clock_speeds": {
        "0": {
          "graphics_mhz": 1950,
          "memory_mhz": 9251
        }
      },
      "pcie_throughput": {
        "0": {
          "link_gen": "4",
          "link_width": "8",
          "max_bandwidth_GBps": 15.76,
          "mem_controller_util": 1.6666666666666667,
          "estimated_usage_GBps": 0.26266666666666666
        }
      },
      "idle_time": 37.49937295913696,
      "is_currently_idle": false
    },
    "cpu": {
      "utilization": {
        "overall": 5.5,
        "per_core": [
          10.0,
          0.0,
          0.0,
          0.0,
          9.1,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          100.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0
        ],
        "logical_cores": 20,
        "physical_cores": 14
      },
      "unused_cores": {
        "unused_core_count": 15,
        "unused_core_indices": [
          1,
          2,
          3,
          5,
          6,
          7,
          9,
          11,
          12,
          13,
          14,
          15,
          16,
          18,
          19
        ],
        "threshold": 10
      },
      "memory": {
        "total_gb": 31.13628387451172,
        "used_gb": 12.155670166015625,
        "available_gb": 18.06704330444336,
        "percent_used": 42.0,
        "swap_total_gb": 0.9540977478027344,
        "swap_used_gb": 0.5591011047363281,
        "swap_percent": 58.6
      }
    },
    "latency": {
      "inference": {
        "batch_size": 1,
        "num_runs": 10,
        "avg_latency_ms": 19.77839469909668,
        "throughput_samples_per_sec": 50.56022064549415
      },
      "training_step": {
        "error": "in user code:\n\n    File \"/home/p0wden/Downloads/mloptimizer/app/common/GpuMetrics.py\", line 588, in train_step  *\n        loss = model.loss(y, y_pred)\n\n    TypeError: 'str' object is not callable\n"
      },
      "data_pipeline": {
        "status": "no dataset provided"
      }
    },
    "framework_specific": {
      "version": "2.19.0",
      "built_with_cuda": true,
      "gpu_available": true,
      "eager_execution": true
    }
  },
  {
    "timestamp": "2025-05-09T14:52:35.812662",
    "gpu": {
      "utilization": {
        "0": 40
      },
      "memory": {
        "0": {
          "used_mb": 9889,
          "total_mb": 10240,
          "percentage": 96.572265625
        }
      },
      "temperature": {
        "0": 51
      },
      "power": {
        "0": {
          "draw_watts": 147.36,
          "limit_watts": 370.0,
          "percentage": 39.82702702702703
        }
      },
      "clock_speeds": {
        "0": {
          "graphics_mhz": 1950,
          "memory_mhz": 9251
        }
      },
      "pcie_throughput": {
        "0": {
          "link_gen": "4",
          "link_width": "8",
          "max_bandwidth_GBps": 15.76,
          "mem_controller_util": 2.3333333333333335,
          "estimated_usage_GBps": 0.36773333333333336
        }
      },
      "idle_time": 0,
      "is_currently_idle": false
    },
    "cpu": {
      "utilization": {
        "overall": 8.5,
        "per_core": [
          16.7,
          9.1,
          0.0,
          0.0,
          18.2,
          0.0,
          0.0,
          0.0,
          10.0,
          0.0,
          100.0,
          0.0,
          9.1,
          9.1,
          9.1,
          0.0,
          0.0,
          10.0,
          0.0,
          0.0
        ],
        "logical_cores": 20,
        "physical_cores": 14
      },
      "unused_cores": {
        "unused_core_count": 15,
        "unused_core_indices": [
          1,
          3,
          4,
          5,
          7,
          8,
          9,
          11,
          12,
          13,
          14,
          15,
          16,
          18,
          19
        ],
        "threshold": 10
      },
      "memory": {
        "total_gb": 31.13628387451172,
        "used_gb": 12.119430541992188,
        "available_gb": 18.104286193847656,
        "percent_used": 41.9,
        "swap_total_gb": 0.9540977478027344,
        "swap_used_gb": 0.5591011047363281,
        "swap_percent": 58.6
      }
    },
    "latency": {
      "inference": {
        "batch_size": 1,
        "num_runs": 10,
        "avg_latency_ms": 20.691299438476562,
        "throughput_samples_per_sec": 48.329492450360426
      },
      "training_step": {
        "error": "in user code:\n\n    File \"/home/p0wden/Downloads/mloptimizer/app/common/GpuMetrics.py\", line 588, in train_step  *\n        loss = model.loss(y, y_pred)\n\n    TypeError: 'str' object is not callable\n"
      },
      "data_pipeline": {
        "status": "no dataset provided"
      }
    },
    "framework_specific": {
      "version": "2.19.0",
      "built_with_cuda": true,
      "gpu_available": true,
      "eager_execution": true
    }
  },
  {
    "timestamp": "2025-05-09T14:53:18.610029",
    "gpu": {
      "utilization": {
        "0": 92
      },
      "memory": {
        "0": {
          "used_mb": 9870,
          "total_mb": 10240,
          "percentage": 96.38671875
        }
      },
      "temperature": {
        "0": 52
      },
      "power": {
        "0": {
          "draw_watts": 181.45,
          "limit_watts": 370.0,
          "percentage": 49.04054054054054
        }
      },
      "clock_speeds": {
        "0": {
          "graphics_mhz": 1950,
          "memory_mhz": 9251
        }
      },
      "pcie_throughput": {
        "0": {
          "link_gen": "4",
          "link_width": "8",
          "max_bandwidth_GBps": 15.76,
          "mem_controller_util": 1.6666666666666667,
          "estimated_usage_GBps": 0.26266666666666666
        }
      },
      "idle_time": 0,
      "is_currently_idle": false
    },
    "cpu": {
      "utilization": {
        "overall": 9.1,
        "per_core": [
          10.0,
          0.0,
          9.1,
          0.0,
          0.0,
          0.0,
          10.0,
          0.0,
          100.0,
          0.0,
          0.0,
          9.1,
          0.0,
          0.0,
          0.0,
          9.1,
          0.0,
          18.2,
          0.0,
          0.0
        ],
        "logical_cores": 20,
        "physical_cores": 14
      },
      "unused_cores": {
        "unused_core_count": 16,
        "unused_core_indices": [
          0,
          1,
          2,
          3,
          4,
          5,
          7,
          9,
          10,
          11,
          12,
          15,
          16,
          17,
          18,
          19
        ],
        "threshold": 10
      },
      "memory": {
        "total_gb": 31.13628387451172,
        "used_gb": 12.430709838867188,
        "available_gb": 17.793750762939453,
        "percent_used": 42.9,
        "swap_total_gb": 0.9540977478027344,
        "swap_used_gb": 0.5590934753417969,
        "swap_percent": 58.6
      }
    },
    "latency": {
      "inference": {
        "batch_size": 1,
        "num_runs": 10,
        "avg_latency_ms": 19.690966606140137,
        "throughput_samples_per_sec": 50.78470854184349
      },
      "training_step": {
        "error": "in user code:\n\n    File \"/home/p0wden/Downloads/mloptimizer/app/common/GpuMetrics.py\", line 588, in train_step  *\n        loss = model.loss(y, y_pred)\n\n    TypeError: 'str' object is not callable\n"
      },
      "data_pipeline": {
        "status": "no dataset provided"
      }
    },
    "framework_specific": {
      "version": "2.19.0",
      "built_with_cuda": true,
      "gpu_available": true,
      "eager_execution": true
    }
  },
  {
    "timestamp": "2025-05-09T14:53:21.388146",
    "gpu": {
      "utilization": {
        "0": 9
      },
      "memory": {
        "0": {
          "used_mb": 9883,
          "total_mb": 10240,
          "percentage": 96.513671875
        }
      },
      "temperature": {
        "0": 51
      },
      "power": {
        "0": {
          "draw_watts": 143.41,
          "limit_watts": 370.0,
          "percentage": 38.759459459459464
        }
      },
      "clock_speeds": {
        "0": {
          "graphics_mhz": 1950,
          "memory_mhz": 9251
        }
      },
      "pcie_throughput": {
        "0": {
          "link_gen": "4",
          "link_width": "8",
          "max_bandwidth_GBps": 15.76,
          "mem_controller_util": 0.3333333333333333,
          "estimated_usage_GBps": 0.05253333333333333
        }
      },
      "idle_time": 0,
      "is_currently_idle": false
    },
    "cpu": {
      "utilization": {
        "overall": 5.5,
        "per_core": [
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          100.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0
        ],
        "logical_cores": 20,
        "physical_cores": 14
      },
      "unused_cores": {
        "unused_core_count": 11,
        "unused_core_indices": [
          1,
          3,
          5,
          7,
          9,
          11,
          14,
          16,
          17,
          18,
          19
        ],
        "threshold": 10
      },
      "memory": {
        "total_gb": 31.13628387451172,
        "used_gb": 12.424247741699219,
        "available_gb": 17.800132751464844,
        "percent_used": 42.8,
        "swap_total_gb": 0.9540977478027344,
        "swap_used_gb": 0.5590934753417969,
        "swap_percent": 58.6
      }
    },
    "latency": {
      "inference": {
        "batch_size": 1,
        "num_runs": 10,
        "avg_latency_ms": 19.493889808654785,
        "throughput_samples_per_sec": 51.29812519798002
      },
      "training_step": {
        "error": "in user code:\n\n    File \"/home/p0wden/Downloads/mloptimizer/app/common/GpuMetrics.py\", line 588, in train_step  *\n        loss = model.loss(y, y_pred)\n\n    TypeError: 'str' object is not callable\n"
      },
      "data_pipeline": {
        "status": "no dataset provided"
      }
    },
    "framework_specific": {
      "version": "2.19.0",
      "built_with_cuda": true,
      "gpu_available": true,
      "eager_execution": true
    }
  },
  {
    "timestamp": "2025-05-09T14:53:59.586077",
    "gpu": {
      "utilization": {
        "0": 29
      },
      "memory": {
        "0": {
          "used_mb": 9865,
          "total_mb": 10240,
          "percentage": 96.337890625
        }
      },
      "temperature": {
        "0": 52
      },
      "power": {
        "0": {
          "draw_watts": 185.18,
          "limit_watts": 370.0,
          "percentage": 50.04864864864865
        }
      },
      "clock_speeds": {
        "0": {
          "graphics_mhz": 1950,
          "memory_mhz": 9251
        }
      },
      "pcie_throughput": {
        "0": {
          "link_gen": "4",
          "link_width": "8",
          "max_bandwidth_GBps": 15.76,
          "mem_controller_util": 2.0,
          "estimated_usage_GBps": 0.3152
        }
      },
      "idle_time": 0,
      "is_currently_idle": false
    },
    "cpu": {
      "utilization": {
        "overall": 8.5,
        "per_core": [
          0.0,
          0.0,
          9.1,
          0.0,
          11.1,
          0.0,
          0.0,
          0.0,
          100.0,
          0.0,
          60.0,
          0.0,
          10.0,
          0.0,
          10.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0
        ],
        "logical_cores": 20,
        "physical_cores": 14
      },
      "unused_cores": {
        "unused_core_count": 3,
        "unused_core_indices": [
          3,
          5,
          7
        ],
        "threshold": 10
      },
      "memory": {
        "total_gb": 31.13628387451172,
        "used_gb": 12.65469741821289,
        "available_gb": 17.56890106201172,
        "percent_used": 43.6,
        "swap_total_gb": 0.9540977478027344,
        "swap_used_gb": 0.558868408203125,
        "swap_percent": 58.6
      }
    },
    "latency": {
      "inference": {
        "batch_size": 1,
        "num_runs": 10,
        "avg_latency_ms": 20.095300674438477,
        "throughput_samples_per_sec": 49.7628782072425
      },
      "training_step": {
        "error": "in user code:\n\n    File \"/home/p0wden/Downloads/mloptimizer/app/common/GpuMetrics.py\", line 588, in train_step  *\n        loss = model.loss(y, y_pred)\n\n    TypeError: 'str' object is not callable\n"
      },
      "data_pipeline": {
        "status": "no dataset provided"
      }
    },
    "framework_specific": {
      "version": "2.19.0",
      "built_with_cuda": true,
      "gpu_available": true,
      "eager_execution": true
    }
  },
  {
    "timestamp": "2025-05-09T14:54:02.367081",
    "gpu": {
      "utilization": {
        "0": 16
      },
      "memory": {
        "0": {
          "used_mb": 9862,
          "total_mb": 10240,
          "percentage": 96.30859375
        }
      },
      "temperature": {
        "0": 51
      },
      "power": {
        "0": {
          "draw_watts": 140.3,
          "limit_watts": 370.0,
          "percentage": 37.91891891891892
        }
      },
      "clock_speeds": {
        "0": {
          "graphics_mhz": 1950,
          "memory_mhz": 9251
        }
      },
      "pcie_throughput": {
        "0": {
          "link_gen": "4",
          "link_width": "8",
          "max_bandwidth_GBps": 15.76,
          "mem_controller_util": 1.6666666666666667,
          "estimated_usage_GBps": 0.26266666666666666
        }
      },
      "idle_time": 0,
      "is_currently_idle": false
    },
    "cpu": {
      "utilization": {
        "overall": 7.6,
        "per_core": [
          10.0,
          0.0,
          27.3,
          0.0,
          11.1,
          0.0,
          0.0,
          0.0,
          100.0,
          0.0,
          22.2,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0
        ],
        "logical_cores": 20,
        "physical_cores": 14
      },
      "unused_cores": {
        "unused_core_count": 18,
        "unused_core_indices": [
          0,
          1,
          3,
          4,
          5,
          6,
          7,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19
        ],
        "threshold": 10
      },
      "memory": {
        "total_gb": 31.13628387451172,
        "used_gb": 12.704181671142578,
        "available_gb": 17.519763946533203,
        "percent_used": 43.7,
        "swap_total_gb": 0.9540977478027344,
        "swap_used_gb": 0.558868408203125,
        "swap_percent": 58.6
      }
    },
    "latency": {
      "inference": {
        "batch_size": 1,
        "num_runs": 10,
        "avg_latency_ms": 21.813368797302246,
        "throughput_samples_per_sec": 45.8434462504331
      },
      "training_step": {
        "error": "in user code:\n\n    File \"/home/p0wden/Downloads/mloptimizer/app/common/GpuMetrics.py\", line 588, in train_step  *\n        loss = model.loss(y, y_pred)\n\n    TypeError: 'str' object is not callable\n"
      },
      "data_pipeline": {
        "status": "no dataset provided"
      }
    },
    "framework_specific": {
      "version": "2.19.0",
      "built_with_cuda": true,
      "gpu_available": true,
      "eager_execution": true
    }
  },
  {
    "timestamp": "2025-05-09T14:54:43.779153",
    "gpu": {
      "utilization": {
        "0": 14
      },
      "memory": {
        "0": {
          "used_mb": 9813,
          "total_mb": 10240,
          "percentage": 95.830078125
        }
      },
      "temperature": {
        "0": 51
      },
      "power": {
        "0": {
          "draw_watts": 195.24,
          "limit_watts": 370.0,
          "percentage": 52.767567567567575
        }
      },
      "clock_speeds": {
        "0": {
          "graphics_mhz": 1950,
          "memory_mhz": 9251
        }
      },
      "pcie_throughput": {
        "0": {
          "link_gen": "4",
          "link_width": "8",
          "max_bandwidth_GBps": 15.76,
          "mem_controller_util": 3.0,
          "estimated_usage_GBps": 0.4728
        }
      },
      "idle_time": 0,
      "is_currently_idle": false
    },
    "cpu": {
      "utilization": {
        "overall": 15.6,
        "per_core": [
          0.0,
          0.0,
          10.0,
          0.0,
          9.1,
          0.0,
          0.0,
          0.0,
          100.0,
          10.0,
          100.0,
          0.0,
          0.0,
          0.0,
          9.1,
          10.0,
          0.0,
          10.0,
          0.0,
          0.0
        ],
        "logical_cores": 20,
        "physical_cores": 14
      },
      "unused_cores": {
        "unused_core_count": 16,
        "unused_core_indices": [
          0,
          1,
          3,
          4,
          5,
          6,
          7,
          9,
          11,
          12,
          13,
          14,
          16,
          17,
          18,
          19
        ],
        "threshold": 10
      },
      "memory": {
        "total_gb": 31.13628387451172,
        "used_gb": 13.113937377929688,
        "available_gb": 17.12490463256836,
        "percent_used": 45.0,
        "swap_total_gb": 0.9540977478027344,
        "swap_used_gb": 0.5587959289550781,
        "swap_percent": 58.6
      }
    },
    "latency": {
      "inference": {
        "batch_size": 1,
        "num_runs": 10,
        "avg_latency_ms": 21.721839904785156,
        "throughput_samples_per_sec": 46.036615884444835
      },
      "training_step": {
        "error": "in user code:\n\n    File \"/home/p0wden/Downloads/mloptimizer/app/common/GpuMetrics.py\", line 588, in train_step  *\n        loss = model.loss(y, y_pred)\n\n    TypeError: 'str' object is not callable\n"
      },
      "data_pipeline": {
        "status": "no dataset provided"
      }
    },
    "framework_specific": {
      "version": "2.19.0",
      "built_with_cuda": true,
      "gpu_available": true,
      "eager_execution": true
    }
  },
  {
    "timestamp": "2025-05-09T14:54:46.582114",
    "gpu": {
      "utilization": {
        "0": 39
      },
      "memory": {
        "0": {
          "used_mb": 9814,
          "total_mb": 10240,
          "percentage": 95.83984375
        }
      },
      "temperature": {
        "0": 50
      },
      "power": {
        "0": {
          "draw_watts": 146.78,
          "limit_watts": 370.0,
          "percentage": 39.67027027027027
        }
      },
      "clock_speeds": {
        "0": {
          "graphics_mhz": 1950,
          "memory_mhz": 9251
        }
      },
      "pcie_throughput": {
        "0": {
          "link_gen": "4",
          "link_width": "8",
          "max_bandwidth_GBps": 15.76,
          "mem_controller_util": 1.0,
          "estimated_usage_GBps": 0.1576
        }
      },
      "idle_time": 0,
      "is_currently_idle": false
    },
    "cpu": {
      "utilization": {
        "overall": 5.0,
        "per_core": [
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          100.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0
        ],
        "logical_cores": 20,
        "physical_cores": 14
      },
      "unused_cores": {
        "unused_core_count": 15,
        "unused_core_indices": [
          0,
          1,
          2,
          3,
          7,
          9,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19
        ],
        "threshold": 10
      },
      "memory": {
        "total_gb": 31.13628387451172,
        "used_gb": 13.063285827636719,
        "available_gb": 17.17566680908203,
        "percent_used": 44.8,
        "swap_total_gb": 0.9540977478027344,
        "swap_used_gb": 0.5587959289550781,
        "swap_percent": 58.6
      }
    },
    "latency": {
      "inference": {
        "batch_size": 1,
        "num_runs": 10,
        "avg_latency_ms": 18.620967864990234,
        "throughput_samples_per_sec": 53.70290133415278
      },
      "training_step": {
        "error": "in user code:\n\n    File \"/home/p0wden/Downloads/mloptimizer/app/common/GpuMetrics.py\", line 588, in train_step  *\n        loss = model.loss(y, y_pred)\n\n    TypeError: 'str' object is not callable\n"
      },
      "data_pipeline": {
        "status": "no dataset provided"
      }
    },
    "framework_specific": {
      "version": "2.19.0",
      "built_with_cuda": true,
      "gpu_available": true,
      "eager_execution": true
    }
  },
  {
    "timestamp": "2025-05-09T14:55:27.211181",
    "gpu": {
      "utilization": {
        "0": 30
      },
      "memory": {
        "0": {
          "used_mb": 9731,
          "total_mb": 10240,
          "percentage": 95.029296875
        }
      },
      "temperature": {
        "0": 51
      },
      "power": {
        "0": {
          "draw_watts": 184.34,
          "limit_watts": 370.0,
          "percentage": 49.82162162162162
        }
      },
      "clock_speeds": {
        "0": {
          "graphics_mhz": 1950,
          "memory_mhz": 9251
        }
      },
      "pcie_throughput": {
        "0": {
          "link_gen": "4",
          "link_width": "8",
          "max_bandwidth_GBps": 15.76,
          "mem_controller_util": 1.3333333333333333,
          "estimated_usage_GBps": 0.2101333333333333
        }
      },
      "idle_time": 0,
      "is_currently_idle": false
    },
    "cpu": {
      "utilization": {
        "overall": 7.0,
        "per_core": [
          0.0,
          0.0,
          10.0,
          0.0,
          0.0,
          0.0,
          10.0,
          0.0,
          100.0,
          0.0,
          0.0,
          0.0,
          9.1,
          9.1,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0
        ],
        "logical_cores": 20,
        "physical_cores": 14
      },
      "unused_cores": {
        "unused_core_count": 16,
        "unused_core_indices": [
          0,
          1,
          3,
          5,
          7,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19
        ],
        "threshold": 10
      },
      "memory": {
        "total_gb": 31.13628387451172,
        "used_gb": 7.85821533203125,
        "available_gb": 22.75442886352539,
        "percent_used": 26.9,
        "swap_total_gb": 0.9540977478027344,
        "swap_used_gb": 0.5587539672851562,
        "swap_percent": 58.6
      }
    },
    "latency": {
      "inference": {
        "batch_size": 1,
        "num_runs": 10,
        "avg_latency_ms": 19.913601875305176,
        "throughput_samples_per_sec": 50.21693243953513
      },
      "training_step": {
        "error": "in user code:\n\n    File \"/home/p0wden/Downloads/mloptimizer/app/common/GpuMetrics.py\", line 588, in train_step  *\n        loss = model.loss(y, y_pred)\n\n    TypeError: 'str' object is not callable\n"
      },
      "data_pipeline": {
        "status": "no dataset provided"
      }
    },
    "framework_specific": {
      "version": "2.19.0",
      "built_with_cuda": true,
      "gpu_available": true,
      "eager_execution": true
    }
  },
  {
    "timestamp": "2025-05-09T14:55:29.986146",
    "gpu": {
      "utilization": {
        "0": 78
      },
      "memory": {
        "0": {
          "used_mb": 9582,
          "total_mb": 10240,
          "percentage": 93.57421875
        }
      },
      "temperature": {
        "0": 51
      },
      "power": {
        "0": {
          "draw_watts": 154.08,
          "limit_watts": 370.0,
          "percentage": 41.64324324324325
        }
      },
      "clock_speeds": {
        "0": {
          "graphics_mhz": 1950,
          "memory_mhz": 9251
        }
      },
      "pcie_throughput": {
        "0": {
          "link_gen": "4",
          "link_width": "8",
          "max_bandwidth_GBps": 15.76,
          "mem_controller_util": 1.6666666666666667,
          "estimated_usage_GBps": 0.26266666666666666
        }
      },
      "idle_time": 0,
      "is_currently_idle": false
    },
    "cpu": {
      "utilization": {
        "overall": 6.5,
        "per_core": [
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          100.0,
          0.0,
          10.0,
          0.0,
          0.0,
          9.1,
          0.0,
          0.0,
          0.0,
          10.0,
          0.0,
          0.0
        ],
        "logical_cores": 20,
        "physical_cores": 14
      },
      "unused_cores": {
        "unused_core_count": 19,
        "unused_core_indices": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19
        ],
        "threshold": 10
      },
      "memory": {
        "total_gb": 31.13628387451172,
        "used_gb": 7.861534118652344,
        "available_gb": 22.751110076904297,
        "percent_used": 26.9,
        "swap_total_gb": 0.9540977478027344,
        "swap_used_gb": 0.5587501525878906,
        "swap_percent": 58.6
      }
    },
    "latency": {
      "inference": {
        "batch_size": 1,
        "num_runs": 10,
        "avg_latency_ms": 18.12744140625,
        "throughput_samples_per_sec": 55.16498316498316
      },
      "training_step": {
        "error": "in user code:\n\n    File \"/home/p0wden/Downloads/mloptimizer/app/common/GpuMetrics.py\", line 588, in train_step  *\n        loss = model.loss(y, y_pred)\n\n    TypeError: 'str' object is not callable\n"
      },
      "data_pipeline": {
        "status": "no dataset provided"
      }
    },
    "framework_specific": {
      "version": "2.19.0",
      "built_with_cuda": true,
      "gpu_available": true,
      "eager_execution": true
    }
  },
  {
    "timestamp": "2025-05-09T14:56:04.456534",
    "gpu": {
      "utilization": {
        "0": 27
      },
      "memory": {
        "0": {
          "used_mb": 9741,
          "total_mb": 10240,
          "percentage": 95.126953125
        }
      },
      "temperature": {
        "0": 52
      },
      "power": {
        "0": {
          "draw_watts": 194.94,
          "limit_watts": 370.0,
          "percentage": 52.68648648648649
        }
      },
      "clock_speeds": {
        "0": {
          "graphics_mhz": 1950,
          "memory_mhz": 9251
        }
      },
      "pcie_throughput": {
        "0": {
          "link_gen": "4",
          "link_width": "8",
          "max_bandwidth_GBps": 15.76,
          "mem_controller_util": 1.0,
          "estimated_usage_GBps": 0.1576
        }
      },
      "idle_time": 0,
      "is_currently_idle": false
    },
    "cpu": {
      "utilization": {
        "overall": 25.3,
        "per_core": [
          33.3,
          0.0,
          70.0,
          10.0,
          11.1,
          0.0,
          90.0,
          0.0,
          88.9,
          0.0,
          100.0,
          0.0,
          40.0,
          20.0,
          25.0,
          20.0,
          11.1,
          27.3,
          27.3,
          11.1
        ],
        "logical_cores": 20,
        "physical_cores": 14
      },
      "unused_cores": {
        "unused_core_count": 5,
        "unused_core_indices": [
          1,
          5,
          7,
          9,
          11
        ],
        "threshold": 10
      },
      "memory": {
        "total_gb": 31.13628387451172,
        "used_gb": 8.964775085449219,
        "available_gb": 21.642223358154297,
        "percent_used": 30.5,
        "swap_total_gb": 0.9540977478027344,
        "swap_used_gb": 0.5587234497070312,
        "swap_percent": 58.6
      }
    },
    "latency": {
      "inference": {
        "batch_size": 1,
        "num_runs": 10,
        "avg_latency_ms": 25.243782997131348,
        "throughput_samples_per_sec": 39.61371400291462
      },
      "training_step": {
        "error": "in user code:\n\n    File \"/home/p0wden/Downloads/mloptimizer/app/common/GpuMetrics.py\", line 588, in train_step  *\n        loss = model.loss(y, y_pred)\n\n    TypeError: 'str' object is not callable\n"
      },
      "data_pipeline": {
        "status": "no dataset provided"
      }
    },
    "framework_specific": {
      "version": "2.19.0",
      "built_with_cuda": true,
      "gpu_available": true,
      "eager_execution": true
    }
  }
]